{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jacob\\Desktop\\nbavy\\mava_research.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/mava_research.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39m#Wireless sensor networm combined with autonomous drone swarm and communication reduction\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/mava_research.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39m#https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7391193&casa_token=wZ2spLDNZroAAAAA:YDmwxnfhCvPGV002JGv_1lSta5d7yBgcY3P0YYrw24wKr7-hJWuTdR5tTvuWe1Z4vZgFr-pgs8Y\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/mava_research.ipynb#ch0000000?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mrand\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/mava_research.ipynb#ch0000000?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/mava_research.ipynb#ch0000000?line=5'>6</a>\u001b[0m \u001b[39m#rand.seed(1)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/mava_research.ipynb#ch0000000?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "#Wireless sensor networm combined with autonomous drone swarm and communication reduction\n",
    "#https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7391193&casa_token=wZ2spLDNZroAAAAA:YDmwxnfhCvPGV002JGv_1lSta5d7yBgcY3P0YYrw24wKr7-hJWuTdR5tTvuWe1Z4vZgFr-pgs8Y\n",
    "\n",
    "import random as rand\n",
    "import numpy as np\n",
    "#rand.seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import math\n",
    "import gym\n",
    "from copy import deepcopy\n",
    "\n",
    "from dm_env import TimeStep\n",
    "import dm_env\n",
    "from mava.utils.wrapper_utils import parameterized_restart\n",
    "from dm_env.specs import BoundedArray\n",
    "ViewRange = 2\n",
    "CommRange = 5#5\n",
    "AgentAmmount = 5\n",
    "NUM_ITERS = 200\n",
    "\n",
    "\n",
    "#double distance = 2/3 as efficient transfer\n",
    "class Task:\n",
    "    def __init__(self):\n",
    "        self.priority = rand.randint(1, 10)\n",
    "        self.size = rand.randint(100, 1000)\n",
    "\n",
    "\n",
    "\n",
    "#Vessel\n",
    "#Constraints: Bandwidth - Num of Chanels - communication distance\n",
    "#Objective: Energy Reduction - Task priority \n",
    "class Drone:\n",
    "    def __init__(self, x, y, viewRange, commRange, width, height, index, Sea):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.task = None\n",
    "        self.viewRange = viewRange\n",
    "        self.commRange = commRange\n",
    "        self.observation = [[0]*width]*height\n",
    "        self.id = index\n",
    "        #self.seen = np.array([[0]*Sea.width]*Sea.height)\n",
    "        self.obs = np.array([[0]*Sea.width]*Sea.height)\n",
    "        self.punish = 0\n",
    "    def getView(self):\n",
    "        return None\n",
    "\n",
    "    def getObservation(self, Sea):\n",
    "        #Get view\n",
    "        #obs = np.array([[0]*Sea.width]*Sea.height)\n",
    "        reward = 0 \n",
    "        for i in range(self.y-self.viewRange, self.y+self.viewRange):\n",
    "            for j in range(self.x-self.viewRange, self.x+self.viewRange):\n",
    "                if i < 50 and i >= 0  and j < 50 and j >= 0:\n",
    "                    if Sea.board[i][j] == 0:\n",
    "                        self.obs[i][j] = 1\n",
    "                    else:\n",
    "                        self.obs[i][j] = Sea.board[i][j]\n",
    "\n",
    "                    if Sea.seen[i][j] == 0:\n",
    "                        Sea.seen[i][j] = 1\n",
    "                        reward += 1\n",
    "        reward += self.punish\n",
    "        res = deepcopy(self.obs)\n",
    "        #make them seperate\n",
    "        res[self.y][self.x] = 3 + self.id\n",
    "        return res, reward\n",
    "\n",
    "    def move(self,x, y, see):\n",
    "        x = x + self.x\n",
    "        y = y + self.y\n",
    "\n",
    "        self.punish = 0\n",
    "\n",
    "        if (x < 50 and x >= 0 and y < 50 and y >= 0) and (see.board[y][x] == 0 or see.board[y][x] == 2 or see.board[y][x] == -2) :\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "        else:\n",
    "            #punishment\n",
    "            self.punish -= 4\n",
    "\n",
    "    \n",
    "    def addData(self, drone):\n",
    "        pass\n",
    "    def setData(self, obs):\n",
    "        self.observation = abs\n",
    "#Constraints: Bandwidth, Num of Chanels\n",
    "#Objective Explore the sea\n",
    "class Ship:\n",
    "    def __init__(self, x, y, bandwidth):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.bandwidth = bandwidth\n",
    "\n",
    "\n",
    "#Actions move up down left right \n",
    "class Sea(dm_env.Environment):\n",
    "\n",
    "    def __init__(self):#, width, height):\n",
    "        self.width = 50#width\n",
    "        self.height =50# height\n",
    "\n",
    "        self.observe_dim = 50*50#env.observation_space[0].shape[0]\n",
    "        self.action_num = 4\n",
    "        self.max_step = 200\n",
    "        self.state_dim = 50*50\n",
    "        self.action_dim = 4\n",
    "        self.target_return = 50*50\n",
    "        self.env_num = 500\n",
    "        self.if_discrete = True\n",
    "        self.agents_arr = [str(r) for r in range(5)]\n",
    "        self.current_agent = str(0)\n",
    "        self.env_name = \"Sea\"\n",
    "        self.reward_range = (-200*4, 50*50)\n",
    "        #self.objects = objects\n",
    "        #int array -2 = dead zone (ie no communication) -1 = object 0 = sea 1 = ship 2 = drone\n",
    "        self.board = np.array( [ [0]*self.width]*self.height )\n",
    "        #for obj in objects:\n",
    "        #    self.board[obj.y][obj.x] = -1\n",
    "        self.dicount = {str(i): 0.99 for i in range(5)}\n",
    "        #for i in range(self.height):\n",
    "        #    for j in range(self.width):\n",
    "        #        rock = rand.randint(0, 30)\n",
    "        #        if(rock == 0):\n",
    "        #            self.board[i][j] = -1\n",
    "\n",
    "        self.cmap = ListedColormap([ 'k', 'b'])\n",
    "\n",
    "    def AddShip(self, ship):\n",
    "        self.ship = ship\n",
    "        self.board[ship.y][ship.x] = 2\n",
    "        for i in range(ship.y - 2, ship.y+2):\n",
    "            for j in range(ship.x - 2, ship.x + 2):\n",
    "                if i >= 0 and j >= 0 and i < self.height and j < self.width and self.board[i][j] == -1:\n",
    "                    self.board[i][j] = 0\n",
    "\n",
    "    def display(self):\n",
    "        newBoard = np.copy(self.board)\n",
    "        if ( hasattr(self, 'ship')):\n",
    "            newBoard[self.ship.y][self.ship.x] = 2\n",
    "            #self.calculateDeadZone2(newBoard)\n",
    "            self.cmap = ListedColormap([ 'k',  'b', 'g', 'y', 'r'])\n",
    "\n",
    "        for drone in self.drones:\n",
    "            newBoard[drone.y][drone.x] = 3\n",
    "\n",
    "        plt.matshow(newBoard, cmap=self.cmap)\n",
    "\n",
    "    def interestMap(self):\n",
    "        interest = [[0]*self.width]*self.height\n",
    "        samples = np.random.multivariate_normal([-0.5, -0.5], [[1, 0],[0, 1]], 50)\n",
    "        huh  = np.reshape(samples, (10,10))\n",
    "        print(huh)\n",
    "        plt.close()\n",
    "        plt.matshow(huh)\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.array( [ [0]*self.width]*self.height )\n",
    "        #for obj in objects:\n",
    "        #    self.board[obj.y][obj.x] = -1\n",
    "\n",
    "        #for i in range(self.height):\n",
    "        #    for j in range(self.width):\n",
    "        #        rock = rand.randint(0, 30)\n",
    "        #        if(rock == 0):\n",
    "        #            self.board[i][j] = -1\n",
    "        self.curr_step = 0\n",
    "        shipx = rand.randint(0, 49)\n",
    "        shipy = rand.randint(1, 49)\n",
    "        ship = Ship(shipx, shipy, 100)\n",
    "        self.AddShip(ship)\n",
    "        self.seen = np.array([[0]*50]*50)\n",
    "        self.drones = []\n",
    "\n",
    "        for i in range(AgentAmmount):\n",
    "            self.drones.append(Drone(shipx, shipy-1,ViewRange, CommRange, self.width, self.height, i, self))\n",
    "        observations, rewards = self.getObservation()\n",
    "\n",
    "        return parameterized_restart(reward=rewards, discount=self.dicount, observation=observations)\n",
    "\n",
    "    def step(self, actions):\n",
    "\n",
    "        self.curr_step += 1\n",
    "        for key in actions:\n",
    "            act = actions[key]\n",
    "            print(act)\n",
    "            match act:\n",
    "                case 0:\n",
    "                    self.drones[int(key)].move(1,0, self)\n",
    "                case 1:\n",
    "                    self.drones[int(key)].move(-1,0, self)\n",
    "                case 2:\n",
    "                    self.drones[int(key)].move(0,1, self)\n",
    "                case 3:\n",
    "                    self.drones[int(key)].move(0, -1, self)\n",
    "                case 4:\n",
    "                    print(\"Im not meantr to thbe there\")\n",
    "                \n",
    "        #count  = [0] * AgentAmmount\n",
    "        #for i in range(self.height):\n",
    "        #    for j in range(self.width):\n",
    "        #        for drone in self.drones:\n",
    "        #            if drone.seen[i][j] == 1:\n",
    "        #                count[drone.id] += 1\n",
    "                        \n",
    "        #reward = count / float(self.width*self.height)\n",
    "        #reward = [t/float(self.width*self.height) for t in count]\n",
    "        env_done = self.curr_step >= self.max_step\n",
    "        dones = {str(i): env_done for i in range(5)}\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        self.step_type = dm_env.StepType.MID\n",
    "        if(env_done == True):\n",
    "            self.step_type = dm_env.StepType.LAST\n",
    "        if(self.curr_step == 1 ):\n",
    "            self.step_type = dm_env.StepType.FIRST\n",
    "        \n",
    "        info = {str(i): {} for i in range(5)}\n",
    "        observations, rewards = self.getObservation()\n",
    "\n",
    "\n",
    "\n",
    "        timestep = TimeStep(self.step_type, reward=rewards, discount=self.dicount, observation=observations)\n",
    "\n",
    "        return timestep#observations, rewards, dones, None\n",
    "\n",
    "    def getObservation(self):\n",
    "        currentIndex = 1\n",
    "        droneConnection = [0]*AgentAmmount\n",
    "\n",
    "        for drone in self.drones:\n",
    "            \n",
    "            for connectDrone in self.drones:\n",
    "                if drone.id == connectDrone.id:\n",
    "                    continue\n",
    "                if (droneConnection[drone.id] == 0 or droneConnection[drone.id] != droneConnection[connectDrone.id]) \\\n",
    "                            and math.sqrt( (drone.x - connectDrone.x)**2 + (drone.y - connectDrone.y)**2 ) < CommRange:\n",
    "                    #do stuff\n",
    "                    if droneConnection[drone.id] == 0 and droneConnection[connectDrone.id] == 0:\n",
    "                        droneConnection[drone.id] = currentIndex\n",
    "                        droneConnection[connectDrone.id] = currentIndex\n",
    "                        currentIndex += 1\n",
    "                    elif droneConnection[drone.id] != 0 and droneConnection[connectDrone.id] != 0:\n",
    "                        swap = droneConnection[connectDrone.id]\n",
    "                        for i in droneConnection:\n",
    "                            if i == swap:\n",
    "                                i = droneConnection[drone.id]\n",
    "                    else:\n",
    "                        if(droneConnection[drone.id] == 0):\n",
    "                            droneConnection[drone.id] = droneConnection[connectDrone.id]\n",
    "                        else:\n",
    "                            droneConnection[connectDrone.id] = droneConnection[drone.id]\n",
    "\n",
    "        for t in range(len(droneConnection)):\n",
    "            if droneConnection[t] == 0:\n",
    "                droneConnection[t] = currentIndex\n",
    "                currentIndex += 1\n",
    "\n",
    "        obsDict = {}\n",
    "        rewardList = [0] * AgentAmmount\n",
    "        rewardDict = {}\n",
    "        index = 0\n",
    "        for i in droneConnection:\n",
    "\n",
    "            values, reward = self.drones[index].getObservation(self)\n",
    "\n",
    "            if str(i) in obsDict:\n",
    "                values = np.array(values).flatten()\n",
    "                curr = obsDict[str(i)]\n",
    "                \n",
    "                for i in range(len(curr)):\n",
    "                    \n",
    "                    if(curr[i] == 1 and values[i] != 0):\n",
    "                        curr[i] = values[i]\n",
    "                    if(curr[i] == 0):\n",
    "                        curr[i] = values[i]\n",
    "\n",
    "            else:\n",
    "                obsDict[str(i)] = np.array(values).flatten()\n",
    "            \n",
    "            rewardList[index]= reward\n",
    "            rewardDict[str(index)] = reward\n",
    "            index += 1\n",
    "\n",
    "        observations = []\n",
    "        finalObs ={}\n",
    "\n",
    "        for i in droneConnection:\n",
    "            observations.append(obsDict[str(i)])\n",
    "            \n",
    "\n",
    "        for index, i in enumerate(observations):\n",
    "            finalObs[str(index)] = i\n",
    "            t = deepcopy(i)\n",
    "            t[t == 3] = 1\n",
    "            t[ t == 4] = 1\n",
    "            t[t == 5 ] = 1\n",
    "            t[t == 6 ] = 1\n",
    "            t[ t == 7 ] = 1\n",
    "            t[ t == 8 ] = 1\n",
    "            self.drones[index].obs = np.reshape(t, (50,50))\n",
    "\n",
    "\n",
    "        return finalObs, rewardDict\n",
    "\n",
    "    def env_done(self):\n",
    "        \"\"\"Returns a bool indicating if env is done\"\"\"\n",
    "        if self.curr_step >= self.max_step:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def agents(self):\n",
    "        \"\"\"\n",
    "        Returns the active agents in the env.\n",
    "        \"\"\"\n",
    "        return self.agents_arr\n",
    "\n",
    "    @property\n",
    "    def possible_agents(self):\n",
    "        \"\"\"\n",
    "        Returns all the possible agents in the env.\n",
    "        \"\"\"\n",
    "        return self.agents_arr\n",
    "\n",
    "    def action_spec(self):\n",
    "        return BoundedArray((5), dtype=np.int32, minimum=0, maximum=4)\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return BoundedArray((50*50), dtype=np.int32, minimum=-5, maximum=9)\n",
    "\n",
    "class Object:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y \n",
    "\n",
    "see = Sea()#50, 50)\n",
    "\n",
    "see.reset()\n",
    "#obs, reward, _, _ = see.step([0, 1])\n",
    "#plt.matshow( np.reshape(obs[0], (50,50)) )\n",
    "#plt.matshow( np.reshape(obs[1], (50,50)) )\n",
    "see.display()\n",
    "#obs, reward, _, _ = see.step({ \"0\": 0, \"2\": 3})\n",
    "#obs, reward, _, _ = see.step([0, 4])\n",
    "#obs, reward, _, _ = see.step([0, 4])\n",
    "#obs, reward, _, _ = see.step([0, 4])\n",
    "#print(obs)\n",
    "#plt.matshow( np.reshape(obs[\"0\"], (50,50)) )\n",
    "#plt.matshow( np.reshape(obs[\"2\"], (50,50)) )\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "#obs, reward, _, _ = see.step([0, 1])\n",
    "#plt.matshow( np.reshape(obs[0], (50,50)) )\n",
    "#plt.matshow( np.reshape(obs[1], (50,50)) )\n",
    "#see.display()\n",
    "\n",
    "#print(reward)\n",
    "\n",
    "def make_env():\n",
    "    return Sea()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mava'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jacob\\Desktop\\nbavy\\mava_research.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/mava_research.ipynb#ch0000001?line=0'>1</a>\u001b[0m \u001b[39m# Mava imports\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/mava_research.ipynb#ch0000001?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmava\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msystems\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf\u001b[39;00m \u001b[39mimport\u001b[39;00m mappo\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/mava_research.ipynb#ch0000001?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmava\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m lp_utils\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/mava_research.ipynb#ch0000001?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmava\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marchitectures\u001b[39;00m \u001b[39mimport\u001b[39;00m DecentralisedPolicyActor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mava'"
     ]
    }
   ],
   "source": [
    "# Mava imports\n",
    "from mava.systems.tf import mappo\n",
    "from mava.utils import lp_utils\n",
    "from mava.components.tf.architectures import DecentralisedPolicyActor\n",
    "from . import helpers\n",
    "import functools\n",
    "# Launchpad imports\n",
    "import launchpad\n",
    "\n",
    "envFactory = functools.partial(make_env)\n",
    "from mava.utils.loggers import logger_utils\n",
    "network_factory = lp_utils.partial_kwargs(\n",
    "        mappo.make_default_networks\n",
    "    )\n",
    "# Log every [log_every] seconds.\n",
    "log_every = 10\n",
    "logger_factory = functools.partial(\n",
    "    logger_utils.make_logger,\n",
    "    directory=FLAGS.base_dir,\n",
    "    to_terminal=True,\n",
    "    to_tensorboard=True,\n",
    "    time_stamp=FLAGS.mava_id,\n",
    "    time_delta=log_every,\n",
    ")\n",
    "\n",
    "\n",
    "# Distributed program\n",
    "program = mappo.MAPPO(\n",
    "    environment_factory=envFactory,\n",
    "    network_factory=network_factory,\n",
    "    logger_factory=logger_factory,\n",
    "    architecture=DecentralisedPolicyActor,\n",
    "    checkpoint_subpath=\"ckpt\",\n",
    "    num_executors=1,\n",
    "    num_epochs=5,\n",
    "    batch_size=32,\n",
    ").build()\n",
    "\n",
    "\n",
    " # Ensure only trainer runs on gpu, while other processes run on cpu.\n",
    "local_resources = lp_utils.to_device(\n",
    "    program_nodes=program.groups.keys(), nodes_on_gpu=[\"trainer\"]\n",
    ")\n",
    "\n",
    "# Launch\n",
    "launchpad.launch(\n",
    "    program,\n",
    "    launchpad.LaunchType.LOCAL_MULTI_PROCESSING,\n",
    "    terminal=\"current_terminal\",\n",
    "    local_resources=local_resources,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('MavaEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13e92e5695f6fd3a4e6b3d2d3d19990ee97df4dbb1b9580adb9eda0eac35ae9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
