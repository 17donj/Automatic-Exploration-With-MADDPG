{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im not meantr to thbe there\n",
      "[4, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Wireless sensor networm combined with autonomous drone swarm and communication reduction\n",
    "#https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7391193&casa_token=wZ2spLDNZroAAAAA:YDmwxnfhCvPGV002JGv_1lSta5d7yBgcY3P0YYrw24wKr7-hJWuTdR5tTvuWe1Z4vZgFr-pgs8Y\n",
    "\n",
    "import random as rand\n",
    "import numpy as np\n",
    "#rand.seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import math\n",
    "import gym\n",
    "from copy import deepcopy\n",
    "\n",
    "ViewRange = 2\n",
    "CommRange = 5#5\n",
    "AgentAmmount = 5\n",
    "\n",
    "#double distance = 2/3 as efficient transfer\n",
    "class Task:\n",
    "    def __init__(self):\n",
    "        self.priority = rand.randint(1, 10)\n",
    "        self.size = rand.randint(100, 1000)\n",
    "\n",
    "\n",
    "\n",
    "#Vessel\n",
    "#Constraints: Bandwidth - Num of Chanels - communication distance\n",
    "#Objective: Energy Reduction - Task priority \n",
    "class Drone:\n",
    "    def __init__(self, x, y, viewRange, commRange, width, height, index, Sea):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.task = None\n",
    "        self.viewRange = viewRange\n",
    "        self.commRange = commRange\n",
    "        self.observation = [[0]*width]*height\n",
    "        self.id = index\n",
    "        #self.seen = np.array([[0]*Sea.width]*Sea.height)\n",
    "        self.obs = np.array([[0]*Sea.width]*Sea.height)\n",
    "        self.punish = 0\n",
    "    def getView(self):\n",
    "        return None\n",
    "\n",
    "    def getObservation(self, Sea):\n",
    "        #Get view\n",
    "        #obs = np.array([[0]*Sea.width]*Sea.height)\n",
    "        reward = 0 \n",
    "        for i in range(self.y-self.viewRange, self.y+self.viewRange):\n",
    "            for j in range(self.x-self.viewRange, self.x+self.viewRange):\n",
    "                if i < 50 and i >= 0  and j < 50 and j >= 0:\n",
    "                    if Sea.board[i][j] == 0:\n",
    "                        self.obs[i][j] = 1\n",
    "                    else:\n",
    "                        self.obs[i][j] = Sea.board[i][j]\n",
    "\n",
    "                    if Sea.seen[i][j] == 0:\n",
    "                        Sea.seen[i][j] = 1\n",
    "                        reward += 1\n",
    "        reward += self.punish\n",
    "        res = deepcopy(self.obs)\n",
    "        res[self.y][self.x] = 3\n",
    "        return res, reward\n",
    "\n",
    "    def move(self,x, y, see):\n",
    "        x = x + self.x\n",
    "        y = y + self.y\n",
    "\n",
    "        self.punish = 0\n",
    "\n",
    "        if (x < 50 and x >= 0 and y < 50 and y >= 0) and (see.board[y][x] == 0 or see.board[y][x] == 2 or see.board[y][x] == -2) :\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "        else:\n",
    "            #punishment\n",
    "            self.punish -= 4\n",
    "\n",
    "    \n",
    "    def addData(self, drone):\n",
    "        pass\n",
    "    def setData(self, obs):\n",
    "        self.observation = abs\n",
    "#Constraints: Bandwidth, Num of Chanels\n",
    "#Objective Explore the sea\n",
    "class Ship:\n",
    "    def __init__(self, x, y, bandwidth):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.bandwidth = bandwidth\n",
    "\n",
    "\n",
    "#Actions move up down left right \n",
    "class Sea:\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        #self.objects = objects\n",
    "        #int array -2 = dead zone (ie no communication) -1 = object 0 = sea 1 = ship 2 = drone\n",
    "        self.board = np.array( [ [0]*self.width]*self.height )\n",
    "        #for obj in objects:\n",
    "        #    self.board[obj.y][obj.x] = -1\n",
    "\n",
    "        #for i in range(self.height):\n",
    "        #    for j in range(self.width):\n",
    "        #        rock = rand.randint(0, 30)\n",
    "        #        if(rock == 0):\n",
    "        #            self.board[i][j] = -1\n",
    "\n",
    "        self.cmap = ListedColormap([ 'k', 'b'])\n",
    "\n",
    "    def calculateDeadZone2(self, board):\n",
    "        shipx = self.ship.x\n",
    "        shipy = self.ship.y\n",
    "\n",
    "        for y in range(0, self.height):\n",
    "            for x in range(0, self.width):\n",
    "                if board[y][x] != 0:\n",
    "                    continue\n",
    "                startx = x\n",
    "                starty = y\n",
    "                x0 = startx\n",
    "                y0 = starty\n",
    "                x1 = shipx\n",
    "                y1 = shipy\n",
    "                dx = abs(x1 - x0)\n",
    "                sx = -1\n",
    "                if x0 < x1:\n",
    "                    sx = 1\n",
    "                dy = -abs(y1 - y0)\n",
    "                sy = -1\n",
    "                if y0 < y1:\n",
    "                    sy = 1\n",
    "                error = dx + dy\n",
    "\n",
    "                while True:\n",
    "                    if(board[y0][x0] == -1):\n",
    "                        board[y][x] = -2\n",
    "                        break\n",
    "                    if x0 == x1 and y0 == y1:\n",
    "                        break\n",
    "                    e2 = 2 * error\n",
    "                    if e2 >= dy:\n",
    "                        if x0 == x1: \n",
    "                            break\n",
    "                        error = error + dy\n",
    "                        x0 = x0 + sx\n",
    "                    \n",
    "                    if e2 <= dx:\n",
    "                        if y0 == y1:\n",
    "                            break\n",
    "                        error = error + dx\n",
    "                        y0 = y0 + sy\n",
    "\n",
    "    def AddShip(self, ship):\n",
    "        self.ship = ship\n",
    "        self.board[ship.y][ship.x] = 2\n",
    "        for i in range(ship.y - 2, ship.y+2):\n",
    "            for j in range(ship.x - 2, ship.x + 2):\n",
    "                if i >= 0 and j >= 0 and i < self.height and j < self.width and self.board[i][j] == -1:\n",
    "                    self.board[i][j] = 0\n",
    "\n",
    "    def display(self):\n",
    "        newBoard = np.copy(self.board)\n",
    "        if ( hasattr(self, 'ship')):\n",
    "            newBoard[self.ship.y][self.ship.x] = 2\n",
    "            #self.calculateDeadZone2(newBoard)\n",
    "            self.cmap = ListedColormap([ 'k',  'b', 'g', 'y', 'r'])\n",
    "\n",
    "        for drone in self.drones:\n",
    "            newBoard[drone.y][drone.x] = 3\n",
    "\n",
    "        plt.matshow(newBoard, cmap=self.cmap)\n",
    "\n",
    "    def interestMap(self):\n",
    "        interest = [[0]*self.width]*self.height\n",
    "        samples = np.random.multivariate_normal([-0.5, -0.5], [[1, 0],[0, 1]], 50)\n",
    "        huh  = np.reshape(samples, (10,10))\n",
    "        print(huh)\n",
    "        plt.close()\n",
    "        plt.matshow(huh)\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.array( [ [0]*self.width]*self.height )\n",
    "        #for obj in objects:\n",
    "        #    self.board[obj.y][obj.x] = -1\n",
    "\n",
    "        #for i in range(self.height):\n",
    "        #    for j in range(self.width):\n",
    "        #        rock = rand.randint(0, 30)\n",
    "        #        if(rock == 0):\n",
    "        #            self.board[i][j] = -1\n",
    "        \n",
    "        shipx = rand.randint(0, 49)\n",
    "        shipy = rand.randint(1, 49)\n",
    "        ship = Ship(shipx, shipy, 100)\n",
    "        self.AddShip(ship)\n",
    "        self.seen = np.array([[0]*50]*50)\n",
    "        self.drones = []\n",
    "\n",
    "        for i in range(AgentAmmount):\n",
    "            self.drones.append(Drone(shipx, shipy-1,ViewRange, CommRange, self.width, self.height, i, self))\n",
    "        observations, rewards = self.getObservation()\n",
    "\n",
    "        return observations\n",
    "\n",
    "    def step(self, actions):\n",
    "        droneIdx= 0\n",
    "        for act in actions:\n",
    "            match act:\n",
    "                case 0:\n",
    "                    self.drones[droneIdx].move(1,0, self)\n",
    "                case 1:\n",
    "                    self.drones[droneIdx].move(-1,0, self)\n",
    "                case 2:\n",
    "                    self.drones[droneIdx].move(0,1, self)\n",
    "                case 3:\n",
    "                    self.drones[droneIdx].move(0, -1, self)\n",
    "                case 4:\n",
    "                    print(\"Im not meantr to thbe there\")\n",
    "            droneIdx+= 1\n",
    "                \n",
    "                \n",
    "        #count  = [0] * AgentAmmount\n",
    "        #for i in range(self.height):\n",
    "        #    for j in range(self.width):\n",
    "        #        for drone in self.drones:\n",
    "        #            if drone.seen[i][j] == 1:\n",
    "        #                count[drone.id] += 1\n",
    "                        \n",
    "        #reward = count / float(self.width*self.height)\n",
    "        #reward = [t/float(self.width*self.height) for t in count]\n",
    "\n",
    "\n",
    "        observations, rewards = self.getObservation()\n",
    "\n",
    "        return observations, rewards, [False]*AgentAmmount, None\n",
    "\n",
    "    def getObservation(self):\n",
    "        currentIndex = 1\n",
    "        droneConnection = [0]*AgentAmmount\n",
    "\n",
    "        for drone in self.drones:\n",
    "            \n",
    "            for connectDrone in self.drones:\n",
    "                if drone.id == connectDrone.id:\n",
    "                    continue\n",
    "                if (droneConnection[drone.id] == 0 or droneConnection[drone.id] != droneConnection[connectDrone.id]) \\\n",
    "                            and math.sqrt( (drone.x - connectDrone.x)**2 + (drone.y - connectDrone.y)**2 ) < CommRange:\n",
    "                    #do stuff\n",
    "                    if droneConnection[drone.id] == 0 and droneConnection[connectDrone.id] == 0:\n",
    "                        droneConnection[drone.id] = currentIndex\n",
    "                        droneConnection[connectDrone.id] = currentIndex\n",
    "                        currentIndex += 1\n",
    "                    elif droneConnection[drone.id] != 0 and droneConnection[connectDrone.id] != 0:\n",
    "                        swap = droneConnection[connectDrone.id]\n",
    "                        for i in droneConnection:\n",
    "                            if i == swap:\n",
    "                                i = droneConnection[drone.id]\n",
    "                    else:\n",
    "                        if(droneConnection[drone.id] == 0):\n",
    "                            droneConnection[drone.id] = droneConnection[connectDrone.id]\n",
    "                        else:\n",
    "                            droneConnection[connectDrone.id] = droneConnection[drone.id]\n",
    "\n",
    "        for t in range(len(droneConnection)):\n",
    "            if droneConnection[t] == 0:\n",
    "                droneConnection[t] = currentIndex\n",
    "                currentIndex += 1\n",
    "\n",
    "        obsDict = {}\n",
    "        rewardList = [0] * AgentAmmount\n",
    "        index = 0\n",
    "        for i in droneConnection:\n",
    "\n",
    "            values, reward = self.drones[index].getObservation(self)\n",
    "\n",
    "            if str(i) in obsDict:\n",
    "                values = np.array(values).flatten()\n",
    "                curr = obsDict[str(i)]\n",
    "                \n",
    "                for i in range(len(curr)):\n",
    "                    \n",
    "                    if(curr[i] == 1 and values[i] != 0):\n",
    "                        curr[i] = values[i]\n",
    "                    if(curr[i] == 0):\n",
    "                        curr[i] = values[i]\n",
    "\n",
    "            else:\n",
    "                obsDict[str(i)] = np.array(values).flatten()\n",
    "            \n",
    "            rewardList[index]= reward\n",
    "            index += 1\n",
    "\n",
    "        observations = []\n",
    "\n",
    "\n",
    "        for i in droneConnection:\n",
    "            observations.append(obsDict[str(i)])\n",
    "\n",
    "        for index, i in enumerate(observations):\n",
    "            t = deepcopy(i)\n",
    "            t[t == 3] = 1\n",
    "            self.drones[index].obs = np.reshape(t, (50,50))\n",
    "\n",
    "\n",
    "        return observations, rewardList\n",
    "class Object:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y \n",
    "\n",
    "see = Sea(50, 50)\n",
    "\n",
    "see.reset()\n",
    "#obs, reward, _, _ = see.step([0, 1])\n",
    "#plt.matshow( np.reshape(obs[0], (50,50)) )\n",
    "#plt.matshow( np.reshape(obs[1], (50,50)) )\n",
    "see.display()\n",
    "obs, reward, _, _ = see.step([0, 4])\n",
    "plt.matshow( np.reshape(obs[0], (50,50)) )\n",
    "plt.matshow( np.reshape(obs[1], (50,50)) )\n",
    "see.display()\n",
    "#plt.matshow(seen)\n",
    "print(reward)\n",
    "#obs, reward, _, _ = see.step([0, 1])\n",
    "#plt.matshow( np.reshape(obs[0], (50,50)) )\n",
    "#plt.matshow( np.reshape(obs[1], (50,50)) )\n",
    "#see.display()\n",
    "\n",
    "#print(reward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18272d7c730>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def perlin(x, y):\n",
    "    # permutation table\n",
    "    p = np.arange(256, dtype=int)\n",
    "    np.random.shuffle(p)\n",
    "    p = np.stack([p, p]).flatten()\n",
    "    # coordinates of the top-left\n",
    "    xi, yi = x.astype(int), y.astype(int)\n",
    "    # internal coordinates\n",
    "    xf, yf = x - xi, y - yi\n",
    "    # fade factors\n",
    "    u, v = fade(xf), fade(yf)\n",
    "    # noise components\n",
    "    n00 = gradient(p[p[xi] + yi], xf, yf)\n",
    "    n01 = gradient(p[p[xi] + yi + 1], xf, yf - 1)\n",
    "    n11 = gradient(p[p[xi + 1] + yi + 1], xf - 1, yf - 1)\n",
    "    n10 = gradient(p[p[xi + 1] + yi], xf - 1, yf)\n",
    "    # combine noises\n",
    "    x1 = lerp(n00, n10, u)\n",
    "    x2 = lerp(n01, n11, u)  # FIX1: I was using n10 instead of n01\n",
    "    return lerp(x1, x2, v)  # FIX2: I also had to reverse x1 and x2 here\n",
    "\n",
    "def lerp(a, b, x):\n",
    "    \"linear interpolation\"\n",
    "    return a + x * (b - a)\n",
    "\n",
    "def fade(t):\n",
    "    \"6t^5 - 15t^4 + 10t^3\"\n",
    "    return 6 * t**5 - 15 * t**4 + 10 * t**3\n",
    "\n",
    "def gradient(h, x, y):\n",
    "    \"grad converts h to the right gradient vector and return the dot product with (x,y)\"\n",
    "    vectors = np.array([[0, 1], [0, -1], [1, 0], [-1, 0]])\n",
    "    g = vectors[h % 4]\n",
    "    return g[:, :, 0] * x + g[:, :, 1] * y\n",
    "\n",
    "lin = np.linspace(0, 5, 50, endpoint=False)\n",
    "x, y = np.meshgrid(lin, lin)  # FIX3: I thought I had to invert x and y here but it was a mistake\n",
    "data = perlin(x, y)\n",
    "data = data*7\n",
    "data = np.round(data)\n",
    "data[data < 0] = 0\n",
    "print(data.max())\n",
    "print(data.min())\n",
    "plt.imshow(data, origin='upper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "4\n",
      "Parameter containing:\n",
      "tensor([[ 0.0031, -0.0040, -0.0498,  ..., -0.0005,  0.0423, -0.0463],\n",
      "        [-0.0140, -0.0389, -0.0484,  ...,  0.0314,  0.0474,  0.0259],\n",
      "        [ 0.0529, -0.0135,  0.0111,  ..., -0.0529,  0.0526,  0.0085],\n",
      "        ...,\n",
      "        [-0.0274,  0.0130, -0.0198,  ...,  0.0187,  0.0476, -0.0216],\n",
      "        [-0.0011, -0.0137, -0.0622,  ..., -0.0505, -0.0094,  0.0469],\n",
      "        [-0.0246,  0.0281,  0.0621,  ..., -0.0455, -0.0436,  0.0433]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Episode 1\n",
      "Number visited 494\n",
      "Episode 1 discount 0.99\n",
      "Episode 1 total reward=0.02\n",
      "Episode 1 reward=454.0\n",
      "Episode 1 avg reward=0.1816\n",
      "Episode 2\n",
      "Number visited 274\n",
      "Episode 2 discount 0.99\n",
      "Episode 2 total reward=0.02\n",
      "Episode 2 reward=66.0\n",
      "Episode 2 avg reward=0.0264\n",
      "Episode 3\n",
      "Number visited 734\n",
      "Episode 3 discount 0.99\n",
      "Episode 3 total reward=0.05\n",
      "Episode 3 reward=714.0\n",
      "Episode 3 avg reward=0.28559999999999997\n",
      "Episode 4\n",
      "Number visited 392\n",
      "Episode 4 discount 0.99\n",
      "Episode 4 total reward=0.05\n",
      "Episode 4 reward=196.0\n",
      "Episode 4 avg reward=0.0784\n",
      "Episode 5\n",
      "Number visited 747\n",
      "Episode 5 discount 0.99\n",
      "Episode 5 total reward=0.07\n",
      "Episode 5 reward=731.0\n",
      "Episode 5 avg reward=0.2924\n",
      "Episode 6\n",
      "Number visited 560\n",
      "Episode 6 discount 0.99\n",
      "Episode 6 total reward=0.09\n",
      "Episode 6 reward=540.0\n",
      "Episode 6 avg reward=0.21600000000000003\n",
      "Episode 7\n",
      "Number visited 393\n",
      "Episode 7 discount 0.99\n",
      "Episode 7 total reward=0.09\n",
      "Episode 7 reward=177.0\n",
      "Episode 7 avg reward=0.0708\n",
      "Episode 8\n",
      "Number visited 628\n",
      "Episode 8 discount 0.99\n",
      "Episode 8 total reward=0.10\n",
      "Episode 8 reward=612.0\n",
      "Episode 8 avg reward=0.24480000000000002\n",
      "Episode 9\n",
      "Number visited 613\n",
      "Episode 9 discount 0.99\n",
      "Episode 9 total reward=0.12\n",
      "Episode 9 reward=597.0\n",
      "Episode 9 avg reward=0.23879999999999998\n",
      "Episode 10\n",
      "Number visited 479\n",
      "Episode 10 discount 0.99\n",
      "Episode 10 total reward=0.12\n",
      "Episode 10 reward=283.0\n",
      "Episode 10 avg reward=0.11320000000000001\n",
      "Episode 11\n",
      "Number visited 570\n",
      "Episode 11 discount 0.99\n",
      "Episode 11 total reward=0.12\n",
      "Episode 11 reward=426.0\n",
      "Episode 11 avg reward=0.1704\n",
      "Episode 12\n",
      "Number visited 468\n",
      "Episode 12 discount 0.99\n",
      "Episode 12 total reward=0.12\n",
      "Episode 12 reward=348.0\n",
      "Episode 12 avg reward=0.1392\n",
      "Episode 13\n",
      "Number visited 856\n",
      "Episode 13 discount 0.99\n",
      "Episode 13 total reward=0.14\n",
      "Episode 13 reward=792.0\n",
      "Episode 13 avg reward=0.31679999999999997\n",
      "Episode 14\n",
      "Number visited 596\n",
      "Episode 14 discount 0.99\n",
      "Episode 14 total reward=0.15\n",
      "Episode 14 reward=536.0\n",
      "Episode 14 avg reward=0.2144\n",
      "Episode 15\n",
      "Number visited 530\n",
      "Episode 15 discount 0.99\n",
      "Episode 15 total reward=0.15\n",
      "Episode 15 reward=494.0\n",
      "Episode 15 avg reward=0.19760000000000003\n",
      "Episode 16\n",
      "Number visited 529\n",
      "Episode 16 discount 0.99\n",
      "Episode 16 total reward=0.15\n",
      "Episode 16 reward=349.0\n",
      "Episode 16 avg reward=0.1396\n",
      "Episode 17\n",
      "Number visited 642\n",
      "Episode 17 discount 0.99\n",
      "Episode 17 total reward=0.16\n",
      "Episode 17 reward=610.0\n",
      "Episode 17 avg reward=0.244\n",
      "Episode 18\n",
      "Number visited 271\n",
      "Episode 18 discount 0.99\n",
      "Episode 18 total reward=0.15\n",
      "Episode 18 reward=35.0\n",
      "Episode 18 avg reward=0.013999999999999999\n",
      "Episode 19\n",
      "Number visited 622\n",
      "Episode 19 discount 0.99\n",
      "Episode 19 total reward=0.15\n",
      "Episode 19 reward=470.0\n",
      "Episode 19 avg reward=0.188\n",
      "Episode 20\n",
      "Number visited 715\n",
      "Episode 20 discount 0.99\n",
      "Episode 20 total reward=0.16\n",
      "Episode 20 reward=687.0\n",
      "Episode 20 avg reward=0.2748\n",
      "Episode 21\n",
      "Number visited 432\n",
      "Episode 21 discount 0.99\n",
      "Episode 21 total reward=0.16\n",
      "Episode 21 reward=324.0\n",
      "Episode 21 avg reward=0.12960000000000002\n",
      "Episode 22\n",
      "Number visited 430\n",
      "Episode 22 discount 0.99\n",
      "Episode 22 total reward=0.16\n",
      "Episode 22 reward=382.0\n",
      "Episode 22 avg reward=0.1528\n",
      "Episode 23\n",
      "Number visited 523\n",
      "Episode 23 discount 0.99\n",
      "Episode 23 total reward=0.16\n",
      "Episode 23 reward=507.0\n",
      "Episode 23 avg reward=0.2028\n",
      "Episode 24\n",
      "Number visited 378\n",
      "Episode 24 discount 0.99\n",
      "Episode 24 total reward=0.16\n",
      "Episode 24 reward=210.0\n",
      "Episode 24 avg reward=0.084\n",
      "Episode 25\n",
      "Number visited 443\n",
      "Episode 25 discount 0.99\n",
      "Episode 25 total reward=0.16\n",
      "Episode 25 reward=411.0\n",
      "Episode 25 avg reward=0.16440000000000002\n",
      "Episode 26\n",
      "Number visited 791\n",
      "Episode 26 discount 0.99\n",
      "Episode 26 total reward=0.17\n",
      "Episode 26 reward=775.0\n",
      "Episode 26 avg reward=0.31\n",
      "Episode 27\n",
      "Number visited 649\n",
      "Episode 27 discount 0.99\n",
      "Episode 27 total reward=0.18\n",
      "Episode 27 reward=633.0\n",
      "Episode 27 avg reward=0.2532\n",
      "Episode 28\n",
      "Number visited 467\n",
      "Episode 28 discount 0.99\n",
      "Episode 28 total reward=0.18\n",
      "Episode 28 reward=367.0\n",
      "Episode 28 avg reward=0.14679999999999999\n",
      "Episode 29\n",
      "Number visited 219\n",
      "Episode 29 discount 0.99\n",
      "Episode 29 total reward=0.15\n",
      "Episode 29 reward=-165.0\n",
      "Episode 29 avg reward=-0.066\n",
      "Episode 30\n",
      "Number visited 360\n",
      "Episode 30 discount 0.99\n",
      "Episode 30 total reward=0.14\n",
      "Episode 30 reward=176.0\n",
      "Episode 30 avg reward=0.0704\n",
      "Episode 31\n",
      "Number visited 490\n",
      "Episode 31 discount 0.99\n",
      "Episode 31 total reward=0.15\n",
      "Episode 31 reward=446.0\n",
      "Episode 31 avg reward=0.1784\n",
      "Episode 32\n",
      "Number visited 530\n",
      "Episode 32 discount 0.99\n",
      "Episode 32 total reward=0.15\n",
      "Episode 32 reward=458.0\n",
      "Episode 32 avg reward=0.1832\n",
      "Episode 33\n",
      "Number visited 549\n",
      "Episode 33 discount 0.99\n",
      "Episode 33 total reward=0.16\n",
      "Episode 33 reward=497.0\n",
      "Episode 33 avg reward=0.19879999999999998\n",
      "Episode 34\n",
      "Number visited 361\n",
      "Episode 34 discount 0.99\n",
      "Episode 34 total reward=0.15\n",
      "Episode 34 reward=185.0\n",
      "Episode 34 avg reward=0.07400000000000001\n",
      "Episode 35\n",
      "Number visited 309\n",
      "Episode 35 discount 0.99\n",
      "Episode 35 total reward=0.14\n",
      "Episode 35 reward=85.0\n",
      "Episode 35 avg reward=0.034\n",
      "Episode 36\n",
      "Number visited 702\n",
      "Episode 36 discount 0.99\n",
      "Episode 36 total reward=0.15\n",
      "Episode 36 reward=678.0\n",
      "Episode 36 avg reward=0.2712\n",
      "Episode 37\n",
      "Number visited 584\n",
      "Episode 37 discount 0.99\n",
      "Episode 37 total reward=0.16\n",
      "Episode 37 reward=524.0\n",
      "Episode 37 avg reward=0.2096\n",
      "Episode 38\n",
      "Number visited 642\n",
      "Episode 38 discount 0.99\n",
      "Episode 38 total reward=0.16\n",
      "Episode 38 reward=562.0\n",
      "Episode 38 avg reward=0.2248\n",
      "Episode 39\n",
      "Number visited 508\n",
      "Episode 39 discount 0.99\n",
      "Episode 39 total reward=0.16\n",
      "Episode 39 reward=444.0\n",
      "Episode 39 avg reward=0.1776\n",
      "Episode 40\n",
      "Number visited 660\n",
      "Episode 40 discount 0.99\n",
      "Episode 40 total reward=0.17\n",
      "Episode 40 reward=616.0\n",
      "Episode 40 avg reward=0.2464\n",
      "Episode 41\n",
      "Number visited 550\n",
      "Episode 41 discount 0.99\n",
      "Episode 41 total reward=0.17\n",
      "Episode 41 reward=462.0\n",
      "Episode 41 avg reward=0.1848\n",
      "Episode 42\n",
      "Number visited 417\n",
      "Episode 42 discount 0.99\n",
      "Episode 42 total reward=0.17\n",
      "Episode 42 reward=237.0\n",
      "Episode 42 avg reward=0.09480000000000001\n",
      "Episode 43\n",
      "Number visited 490\n",
      "Episode 43 discount 0.99\n",
      "Episode 43 total reward=0.17\n",
      "Episode 43 reward=422.0\n",
      "Episode 43 avg reward=0.16879999999999998\n",
      "Episode 44\n",
      "Number visited 500\n",
      "Episode 44 discount 0.99\n",
      "Episode 44 total reward=0.17\n",
      "Episode 44 reward=468.0\n",
      "Episode 44 avg reward=0.18719999999999998\n",
      "Episode 45\n",
      "Number visited 640\n",
      "Episode 45 discount 0.99\n",
      "Episode 45 total reward=0.18\n",
      "Episode 45 reward=600.0\n",
      "Episode 45 avg reward=0.24\n",
      "Episode 46\n",
      "Number visited 527\n",
      "Episode 46 discount 0.99\n",
      "Episode 46 total reward=0.18\n",
      "Episode 46 reward=511.0\n",
      "Episode 46 avg reward=0.20440000000000003\n",
      "Episode 47\n",
      "Number visited 593\n",
      "Episode 47 discount 0.99\n",
      "Episode 47 total reward=0.18\n",
      "Episode 47 reward=545.0\n",
      "Episode 47 avg reward=0.218\n",
      "Episode 48\n",
      "Number visited 435\n",
      "Episode 48 discount 0.99\n",
      "Episode 48 total reward=0.18\n",
      "Episode 48 reward=419.0\n",
      "Episode 48 avg reward=0.16760000000000003\n",
      "Episode 49\n",
      "Number visited 477\n",
      "Episode 49 discount 0.99\n",
      "Episode 49 total reward=0.18\n",
      "Episode 49 reward=397.0\n",
      "Episode 49 avg reward=0.1588\n",
      "Episode 50\n",
      "Number visited 336\n",
      "Episode 50 discount 0.99\n",
      "Episode 50 total reward=0.17\n",
      "Episode 50 reward=196.0\n",
      "Episode 50 avg reward=0.0784\n",
      "Episode 51\n",
      "Number visited 649\n",
      "Episode 51 discount 0.99\n",
      "Episode 51 total reward=0.18\n",
      "Episode 51 reward=593.0\n",
      "Episode 51 avg reward=0.2372\n",
      "Episode 52\n",
      "Number visited 603\n",
      "Episode 52 discount 0.99\n",
      "Episode 52 total reward=0.18\n",
      "Episode 52 reward=479.0\n",
      "Episode 52 avg reward=0.1916\n",
      "Episode 53\n",
      "Number visited 514\n",
      "Episode 53 discount 0.99\n",
      "Episode 53 total reward=0.18\n",
      "Episode 53 reward=486.0\n",
      "Episode 53 avg reward=0.19440000000000002\n",
      "Episode 54\n",
      "Number visited 368\n",
      "Episode 54 discount 0.99\n",
      "Episode 54 total reward=0.17\n",
      "Episode 54 reward=236.0\n",
      "Episode 54 avg reward=0.0944\n",
      "Episode 55\n",
      "Number visited 741\n",
      "Episode 55 discount 0.99\n",
      "Episode 55 total reward=0.18\n",
      "Episode 55 reward=721.0\n",
      "Episode 55 avg reward=0.2884\n",
      "Episode 56\n",
      "Number visited 532\n",
      "Episode 56 discount 0.99\n",
      "Episode 56 total reward=0.18\n",
      "Episode 56 reward=448.0\n",
      "Episode 56 avg reward=0.17920000000000003\n",
      "Episode 57\n",
      "Number visited 561\n",
      "Episode 57 discount 0.99\n",
      "Episode 57 total reward=0.18\n",
      "Episode 57 reward=501.0\n",
      "Episode 57 avg reward=0.2004\n",
      "Episode 58\n",
      "Number visited 523\n",
      "Episode 58 discount 0.99\n",
      "Episode 58 total reward=0.19\n",
      "Episode 58 reward=503.0\n",
      "Episode 58 avg reward=0.20120000000000002\n",
      "Episode 59\n",
      "Number visited 465\n",
      "Episode 59 discount 0.99\n",
      "Episode 59 total reward=0.18\n",
      "Episode 59 reward=277.0\n",
      "Episode 59 avg reward=0.1108\n",
      "Episode 60\n",
      "Number visited 369\n",
      "Episode 60 discount 0.99\n",
      "Episode 60 total reward=0.17\n",
      "Episode 60 reward=133.0\n",
      "Episode 60 avg reward=0.053200000000000004\n",
      "Episode 61\n",
      "Number visited 580\n",
      "Episode 61 discount 0.99\n",
      "Episode 61 total reward=0.17\n",
      "Episode 61 reward=532.0\n",
      "Episode 61 avg reward=0.21280000000000002\n",
      "Episode 62\n",
      "Number visited 376\n",
      "Episode 62 discount 0.99\n",
      "Episode 62 total reward=0.16\n",
      "Episode 62 reward=288.0\n",
      "Episode 62 avg reward=0.1152\n",
      "Episode 63\n",
      "Number visited 481\n",
      "Episode 63 discount 0.99\n",
      "Episode 63 total reward=0.16\n",
      "Episode 63 reward=313.0\n",
      "Episode 63 avg reward=0.1252\n",
      "Episode 64\n",
      "Number visited 645\n",
      "Episode 64 discount 0.99\n",
      "Episode 64 total reward=0.17\n",
      "Episode 64 reward=629.0\n",
      "Episode 64 avg reward=0.2516\n",
      "Episode 65\n",
      "Number visited 753\n",
      "Episode 65 discount 0.99\n",
      "Episode 65 total reward=0.18\n",
      "Episode 65 reward=713.0\n",
      "Episode 65 avg reward=0.2852\n",
      "Episode 66\n",
      "Number visited 576\n",
      "Episode 66 discount 0.99\n",
      "Episode 66 total reward=0.18\n",
      "Episode 66 reward=456.0\n",
      "Episode 66 avg reward=0.18239999999999998\n",
      "Episode 67\n",
      "Number visited 675\n",
      "Episode 67 discount 0.99\n",
      "Episode 67 total reward=0.19\n",
      "Episode 67 reward=587.0\n",
      "Episode 67 avg reward=0.2348\n",
      "Episode 68\n",
      "Number visited 450\n",
      "Episode 68 discount 0.99\n",
      "Episode 68 total reward=0.18\n",
      "Episode 68 reward=282.0\n",
      "Episode 68 avg reward=0.1128\n",
      "Episode 69\n",
      "Number visited 428\n",
      "Episode 69 discount 0.99\n",
      "Episode 69 total reward=0.17\n",
      "Episode 69 reward=204.0\n",
      "Episode 69 avg reward=0.0816\n",
      "Episode 70\n",
      "Number visited 351\n",
      "Episode 70 discount 0.99\n",
      "Episode 70 total reward=0.16\n",
      "Episode 70 reward=83.0\n",
      "Episode 70 avg reward=0.0332\n",
      "Episode 71\n",
      "Number visited 415\n",
      "Episode 71 discount 0.99\n",
      "Episode 71 total reward=0.15\n",
      "Episode 71 reward=195.0\n",
      "Episode 71 avg reward=0.078\n",
      "Episode 72\n",
      "Number visited 298\n",
      "Episode 72 discount 0.99\n",
      "Episode 72 total reward=0.14\n",
      "Episode 72 reward=134.0\n",
      "Episode 72 avg reward=0.0536\n",
      "Episode 73\n",
      "Number visited 350\n",
      "Episode 73 discount 0.99\n",
      "Episode 73 total reward=0.13\n",
      "Episode 73 reward=230.0\n",
      "Episode 73 avg reward=0.092\n",
      "Episode 74\n",
      "Number visited 552\n",
      "Episode 74 discount 0.99\n",
      "Episode 74 total reward=0.14\n",
      "Episode 74 reward=536.0\n",
      "Episode 74 avg reward=0.2144\n",
      "Episode 75\n",
      "Number visited 491\n",
      "Episode 75 discount 0.99\n",
      "Episode 75 total reward=0.14\n",
      "Episode 75 reward=383.0\n",
      "Episode 75 avg reward=0.1532\n",
      "Episode 76\n",
      "Number visited 649\n",
      "Episode 76 discount 0.99\n",
      "Episode 76 total reward=0.15\n",
      "Episode 76 reward=633.0\n",
      "Episode 76 avg reward=0.2532\n",
      "Episode 77\n",
      "Number visited 284\n",
      "Episode 77 discount 0.99\n",
      "Episode 77 total reward=0.14\n",
      "Episode 77 reward=120.0\n",
      "Episode 77 avg reward=0.048\n",
      "Episode 78\n",
      "Number visited 307\n",
      "Episode 78 discount 0.99\n",
      "Episode 78 total reward=0.14\n",
      "Episode 78 reward=231.0\n",
      "Episode 78 avg reward=0.0924\n",
      "Episode 79\n",
      "Number visited 472\n",
      "Episode 79 discount 0.99\n",
      "Episode 79 total reward=0.14\n",
      "Episode 79 reward=328.0\n",
      "Episode 79 avg reward=0.13119999999999998\n",
      "Episode 80\n",
      "Number visited 416\n",
      "Episode 80 discount 0.99\n",
      "Episode 80 total reward=0.14\n",
      "Episode 80 reward=316.0\n",
      "Episode 80 avg reward=0.1264\n",
      "Episode 81\n",
      "Number visited 283\n",
      "Episode 81 discount 0.99\n",
      "Episode 81 total reward=0.13\n",
      "Episode 81 reward=195.0\n",
      "Episode 81 avg reward=0.078\n",
      "Episode 82\n",
      "Number visited 763\n",
      "Episode 82 discount 0.99\n",
      "Episode 82 total reward=0.15\n",
      "Episode 82 reward=747.0\n",
      "Episode 82 avg reward=0.2988\n",
      "Episode 83\n",
      "Number visited 582\n",
      "Episode 83 discount 0.99\n",
      "Episode 83 total reward=0.15\n",
      "Episode 83 reward=538.0\n",
      "Episode 83 avg reward=0.2152\n",
      "Episode 84\n",
      "Number visited 331\n",
      "Episode 84 discount 0.99\n",
      "Episode 84 total reward=0.14\n",
      "Episode 84 reward=-17.0\n",
      "Episode 84 avg reward=-0.0068000000000000005\n",
      "Episode 85\n",
      "Number visited 598\n",
      "Episode 85 discount 0.99\n",
      "Episode 85 total reward=0.15\n",
      "Episode 85 reward=582.0\n",
      "Episode 85 avg reward=0.2328\n",
      "Episode 86\n",
      "Number visited 412\n",
      "Episode 86 discount 0.99\n",
      "Episode 86 total reward=0.15\n",
      "Episode 86 reward=360.0\n",
      "Episode 86 avg reward=0.14400000000000002\n",
      "Episode 87\n",
      "Number visited 424\n",
      "Episode 87 discount 0.99\n",
      "Episode 87 total reward=0.14\n",
      "Episode 87 reward=248.0\n",
      "Episode 87 avg reward=0.0992\n",
      "Episode 88\n",
      "Number visited 496\n",
      "Episode 88 discount 0.99\n",
      "Episode 88 total reward=0.14\n",
      "Episode 88 reward=384.0\n",
      "Episode 88 avg reward=0.1536\n",
      "Episode 89\n",
      "Number visited 557\n",
      "Episode 89 discount 0.99\n",
      "Episode 89 total reward=0.15\n",
      "Episode 89 reward=429.0\n",
      "Episode 89 avg reward=0.1716\n",
      "Episode 90\n",
      "Number visited 244\n",
      "Episode 90 discount 0.99\n",
      "Episode 90 total reward=0.13\n",
      "Episode 90 reward=80.0\n",
      "Episode 90 avg reward=0.032\n",
      "Episode 91\n",
      "Number visited 281\n",
      "Episode 91 discount 0.99\n",
      "Episode 91 total reward=0.12\n",
      "Episode 91 reward=45.0\n",
      "Episode 91 avg reward=0.018000000000000002\n",
      "Episode 92\n",
      "Number visited 347\n",
      "Episode 92 discount 0.99\n",
      "Episode 92 total reward=0.12\n",
      "Episode 92 reward=151.0\n",
      "Episode 92 avg reward=0.0604\n",
      "Episode 93\n",
      "Number visited 469\n",
      "Episode 93 discount 0.99\n",
      "Episode 93 total reward=0.12\n",
      "Episode 93 reward=453.0\n",
      "Episode 93 avg reward=0.1812\n",
      "Episode 94\n",
      "Number visited 401\n",
      "Episode 94 discount 0.99\n",
      "Episode 94 total reward=0.12\n",
      "Episode 94 reward=329.0\n",
      "Episode 94 avg reward=0.1316\n",
      "Episode 95\n",
      "Number visited 653\n",
      "Episode 95 discount 0.99\n",
      "Episode 95 total reward=0.14\n",
      "Episode 95 reward=637.0\n",
      "Episode 95 avg reward=0.2548\n",
      "Episode 96\n",
      "Number visited 424\n",
      "Episode 96 discount 0.99\n",
      "Episode 96 total reward=0.13\n",
      "Episode 96 reward=204.0\n",
      "Episode 96 avg reward=0.0816\n",
      "Episode 97\n",
      "Number visited 303\n",
      "Episode 97 discount 0.99\n",
      "Episode 97 total reward=0.12\n",
      "Episode 97 reward=15.0\n",
      "Episode 97 avg reward=0.006\n",
      "Episode 98\n",
      "Number visited 601\n",
      "Episode 98 discount 0.99\n",
      "Episode 98 total reward=0.13\n",
      "Episode 98 reward=573.0\n",
      "Episode 98 avg reward=0.22920000000000001\n",
      "Episode 99\n",
      "Number visited 592\n",
      "Episode 99 discount 0.99\n",
      "Episode 99 total reward=0.14\n",
      "Episode 99 reward=484.0\n",
      "Episode 99 avg reward=0.1936\n",
      "Episode 100\n",
      "Number visited 489\n",
      "Episode 100 discount 0.99\n",
      "Episode 100 total reward=0.14\n",
      "Episode 100 reward=437.0\n",
      "Episode 100 avg reward=0.1748\n",
      "Episode 101\n",
      "Number visited 433\n",
      "Episode 101 discount 0.99\n",
      "Episode 101 total reward=0.14\n",
      "Episode 101 reward=317.0\n",
      "Episode 101 avg reward=0.1268\n",
      "Episode 102\n",
      "Number visited 384\n",
      "Episode 102 discount 0.99\n",
      "Episode 102 total reward=0.13\n",
      "Episode 102 reward=164.0\n",
      "Episode 102 avg reward=0.06559999999999999\n",
      "Episode 103\n",
      "Number visited 586\n",
      "Episode 103 discount 0.99\n",
      "Episode 103 total reward=0.14\n",
      "Episode 103 reward=550.0\n",
      "Episode 103 avg reward=0.22\n",
      "Episode 104\n",
      "Number visited 479\n",
      "Episode 104 discount 0.99\n",
      "Episode 104 total reward=0.14\n",
      "Episode 104 reward=439.0\n",
      "Episode 104 avg reward=0.17559999999999998\n",
      "Episode 105\n",
      "Number visited 392\n",
      "Episode 105 discount 0.99\n",
      "Episode 105 total reward=0.14\n",
      "Episode 105 reward=336.0\n",
      "Episode 105 avg reward=0.1344\n",
      "Episode 106\n",
      "Number visited 329\n",
      "Episode 106 discount 0.99\n",
      "Episode 106 total reward=0.14\n",
      "Episode 106 reward=213.0\n",
      "Episode 106 avg reward=0.0852\n",
      "Episode 107\n",
      "Number visited 342\n",
      "Episode 107 discount 0.99\n",
      "Episode 107 total reward=0.13\n",
      "Episode 107 reward=86.0\n",
      "Episode 107 avg reward=0.0344\n",
      "Episode 108\n",
      "Number visited 329\n",
      "Episode 108 discount 0.99\n",
      "Episode 108 total reward=0.12\n",
      "Episode 108 reward=157.0\n",
      "Episode 108 avg reward=0.06280000000000001\n",
      "Episode 109\n",
      "Number visited 335\n",
      "Episode 109 discount 0.99\n",
      "Episode 109 total reward=0.11\n",
      "Episode 109 reward=147.0\n",
      "Episode 109 avg reward=0.0588\n",
      "Episode 110\n",
      "Number visited 543\n",
      "Episode 110 discount 0.99\n",
      "Episode 110 total reward=0.12\n",
      "Episode 110 reward=459.0\n",
      "Episode 110 avg reward=0.18359999999999999\n",
      "Episode 111\n",
      "Number visited 355\n",
      "Episode 111 discount 0.99\n",
      "Episode 111 total reward=0.12\n",
      "Episode 111 reward=187.0\n",
      "Episode 111 avg reward=0.0748\n",
      "Episode 112\n",
      "Number visited 393\n",
      "Episode 112 discount 0.99\n",
      "Episode 112 total reward=0.12\n",
      "Episode 112 reward=321.0\n",
      "Episode 112 avg reward=0.1284\n",
      "Episode 113\n",
      "Number visited 756\n",
      "Episode 113 discount 0.99\n",
      "Episode 113 total reward=0.12\n",
      "Episode 113 reward=472.0\n",
      "Episode 113 avg reward=0.1888\n",
      "Episode 114\n",
      "Number visited 437\n",
      "Episode 114 discount 0.99\n",
      "Episode 114 total reward=0.10\n",
      "Episode 114 reward=-419.0\n",
      "Episode 114 avg reward=-0.16760000000000003\n",
      "Episode 115\n",
      "Number visited 547\n",
      "Episode 115 discount 0.99\n",
      "Episode 115 total reward=0.08\n",
      "Episode 115 reward=-157.0\n",
      "Episode 115 avg reward=-0.06280000000000001\n",
      "Episode 116\n",
      "Number visited 401\n",
      "Episode 116 discount 0.99\n",
      "Episode 116 total reward=0.07\n",
      "Episode 116 reward=-127.0\n",
      "Episode 116 avg reward=-0.0508\n",
      "Episode 117\n",
      "Number visited 373\n",
      "Episode 117 discount 0.99\n",
      "Episode 117 total reward=0.03\n",
      "Episode 117 reward=-807.0\n",
      "Episode 117 avg reward=-0.32280000000000003\n",
      "Episode 118\n",
      "Number visited 396\n",
      "Episode 118 discount 0.99\n",
      "Episode 118 total reward=0.02\n",
      "Episode 118 reward=-160.0\n",
      "Episode 118 avg reward=-0.064\n",
      "Episode 119\n",
      "Number visited 332\n",
      "Episode 119 discount 0.99\n",
      "Episode 119 total reward=0.00\n",
      "Episode 119 reward=-392.0\n",
      "Episode 119 avg reward=-0.1568\n",
      "Episode 120\n",
      "Number visited 538\n",
      "Episode 120 discount 0.99\n",
      "Episode 120 total reward=-0.02\n",
      "Episode 120 reward=-486.0\n",
      "Episode 120 avg reward=-0.19440000000000002\n",
      "Episode 121\n",
      "Number visited 750\n",
      "Episode 121 discount 0.99\n",
      "Episode 121 total reward=-0.02\n",
      "Episode 121 reward=-82.0\n",
      "Episode 121 avg reward=-0.032799999999999996\n",
      "Episode 122\n",
      "Number visited 665\n",
      "Episode 122 discount 0.99\n",
      "Episode 122 total reward=-0.05\n",
      "Episode 122 reward=-811.0\n",
      "Episode 122 avg reward=-0.32439999999999997\n",
      "Episode 123\n",
      "Number visited 246\n",
      "Episode 123 discount 0.99\n",
      "Episode 123 total reward=-0.10\n",
      "Episode 123 reward=-1262.0\n",
      "Episode 123 avg reward=-0.5047999999999999\n",
      "Episode 124\n",
      "Number visited 451\n",
      "Episode 124 discount 0.99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jacob\\Desktop\\nbavy\\navy research.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000002?line=229'>230</a>\u001b[0m \u001b[39mif\u001b[39;00m episode \u001b[39m>\u001b[39m \u001b[39m100\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000002?line=230'>231</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(step):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000002?line=231'>232</a>\u001b[0m         maddpg\u001b[39m.\u001b[39;49mupdate()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000002?line=233'>234</a>\u001b[0m     \u001b[39m# show reward\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000002?line=234'>235</a>\u001b[0m smoothed_total_reward \u001b[39m=\u001b[39m smoothed_total_reward \u001b[39m*\u001b[39m \u001b[39m0.9\u001b[39m \u001b[39m+\u001b[39m totalAvgReward \u001b[39m*\u001b[39m \u001b[39m0.1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\frame\\algorithms\\maddpg.py:636\u001b[0m, in \u001b[0;36mMADDPG.update\u001b[1;34m(self, update_value, update_policy, update_target, concatenate_samples)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=602'>603</a>\u001b[0m     \u001b[39mfor\u001b[39;00m a_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactors)):\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=603'>604</a>\u001b[0m         args\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=604'>605</a>\u001b[0m             (\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=605'>606</a>\u001b[0m                 batch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=633'>634</a>\u001b[0m             )\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=634'>635</a>\u001b[0m         )\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=635'>636</a>\u001b[0m all_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool\u001b[39m.\u001b[39;49mstarmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_sub_policy, args)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=636'>637</a>\u001b[0m mean_loss \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mtensor(all_loss)\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=638'>639</a>\u001b[0m \u001b[39m# returns action value and policy loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\parallel\\pool.py:1063\u001b[0m, in \u001b[0;36mPool.starmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=1060'>1061</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstarmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=1061'>1062</a>\u001b[0m     \u001b[39m# DOC INHERITED\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=1062'>1063</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mstarmap(\n\u001b[0;32m   <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=1063'>1064</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_caller,\n\u001b[0;32m   <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=1064'>1065</a>\u001b[0m         proxy_dumper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_is_recursive, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_is_copy_tensor, func, iterable),\n\u001b[0;32m   <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=1065'>1066</a>\u001b[0m         chunksize,\n\u001b[0;32m   <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=1066'>1067</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\parallel\\pool.py:459\u001b[0m, in \u001b[0;36mBasePool.starmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=439'>440</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstarmap\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=440'>441</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=441'>442</a>\u001b[0m     func: Callable[[Any], Any],\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=442'>443</a>\u001b[0m     iterable: Collection[Tuple],\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=443'>444</a>\u001b[0m     chunksize: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=444'>445</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Any]:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=445'>446</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=446'>447</a>\u001b[0m \u001b[39m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=447'>448</a>\u001b[0m \u001b[39m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=456'>457</a>\u001b[0m \u001b[39m        A list of result from applying the function on each tuple in the iterable.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=457'>458</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=458'>459</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, starmap_caller, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\parallel\\pool.py:129\u001b[0m, in \u001b[0;36mAsyncResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=112'>113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=113'>114</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=114'>115</a>\u001b[0m \u001b[39m    Return the result when it arrives.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=115'>116</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=126'>127</a>\u001b[0m \u001b[39m        The result.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=127'>128</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=128'>129</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=129'>130</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=130'>131</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\parallel\\pool.py:111\u001b[0m, in \u001b[0;36mAsyncResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=103'>104</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=104'>105</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=105'>106</a>\u001b[0m \u001b[39m    Wait until the result is available or until timeout seconds pass.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=106'>107</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=107'>108</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=108'>109</a>\u001b[0m \u001b[39m        timeout: Timeout in seconds.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=109'>110</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/parallel/pool.py?line=110'>111</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0\\lib\\threading.py:600\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0/lib/threading.py?line=597'>598</a>\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0/lib/threading.py?line=598'>599</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0/lib/threading.py?line=599'>600</a>\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0/lib/threading.py?line=600'>601</a>\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0/lib/threading.py?line=317'>318</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0/lib/threading.py?line=318'>319</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0/lib/threading.py?line=319'>320</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0/lib/threading.py?line=320'>321</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.1264.0_x64__qbz5n2kfra8p0/lib/threading.py?line=321'>322</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from machin.frame.algorithms import MADDPG \n",
    "\n",
    "from machin.frame.algorithms import MADDPG\n",
    "from machin.utils.logging import default_logger as logger\n",
    "from copy import deepcopy\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import machin.model.nets as net\n",
    "\n",
    "\n",
    "#Same, playing around with the initialization, parameters, optimizers and normalization really helped Here is the article how I fought it:\n",
    "\n",
    "#TL,DR: critic init sould match the reward distro. Minmax values should be meaningful. Delayed update for actor is good, so is gradient clipping and weight decay. \\\n",
    "# Use Adamw/RAdam/Ranger as an optimizer.\n",
    "\n",
    "#https://towardsdatascience.com/reinforcement-learning-ddpg-and-td3-for-news-recommendation-d3cddec26011?source=activity---post_recommended\n",
    "\n",
    "# Important note:\n",
    "# In order to successfully run the environment, please git clone the project\n",
    "# then run:\n",
    "#    pip install -e ./test_lib/multiagent-particle-envs/\n",
    "# in project root directory\n",
    "\n",
    "\n",
    "def create_env(env_name):\n",
    "    from multiagent.environment import MultiAgentEnv\n",
    "    import multiagent.scenarios as scenarios\n",
    "\n",
    "    # load scenario from script\n",
    "    scenario = scenarios.load(env_name + \".py\").Scenario()\n",
    "    # create world\n",
    "    world = scenario.make_world()\n",
    "    # create multiagent environment\n",
    "    env = MultiAgentEnv(\n",
    "        world,\n",
    "        scenario.reset_world,\n",
    "        scenario.reward,\n",
    "        scenario.observation,\n",
    "        info_callback=None,\n",
    "        shared_viewer=False,\n",
    "    )\n",
    "    return env\n",
    "\n",
    "\n",
    "# configurations\n",
    "#env = create_env(\"simple_spread\")\n",
    "env = Sea(50,50)\n",
    "env.discrete_action_input = True\n",
    "\n",
    "import gym.spaces as spaces\n",
    "obs = spaces.Box(low=-2, high=2, shape=(50,50), dtype=np.int32)\n",
    "action_space = spaces.Box(low=-1, high=1, shape= (2,), dtype=np.int32)\n",
    "\n",
    "observe_dim = 50*50#env.observation_space[0].shape[0]\n",
    "action_num = 4#action_space[0].n\n",
    "max_episodes = 1000\n",
    "max_steps = 200\n",
    "# number of agents in env, fixed, do not change\n",
    "agent_num = 5\n",
    "solved_reward = -15\n",
    "solved_repeat = 5\n",
    "\n",
    "print(observe_dim)\n",
    "print(action_num)\n",
    "\n",
    "\n",
    "class weightConstraint(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self,module):\n",
    "        if hasattr(module,'weight'):\n",
    "            w=module.weight.data\n",
    "            w=w.clamp(0.5,0.7)\n",
    "            module.weight.data=w\n",
    "\n",
    "# model definition\n",
    "class ActorDiscrete(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(state_dim, 1024).to(device=\"cuda\")\n",
    "        self.fc2 = nn.Linear(1024, 256).to(device=\"cuda\")\n",
    "        self.fc3 = nn.Linear(256, 128).to(device=\"cuda\")\n",
    "        self.fc4 = nn.Linear(128, 64).to(device=\"cuda\")\n",
    "        self.fc5 = nn.Linear(64, 64).to(device=\"cuda\")\n",
    "        self.fc6 = nn.Linear(64, 32).to(device=\"cuda\")\n",
    "        \n",
    "        temp = nn.Linear(32, action_dim)\n",
    "        temp.weight.data.fill_(3e-1)\n",
    "        self.fc7 =  temp.to(device=\"cuda\")\n",
    "\n",
    "    def forward(self, state):\n",
    "        #state.to(device=\"cuda\")\n",
    "        a = t.relu(self.fc1(state))\n",
    "        a = t.relu(self.fc2(a))\n",
    "        a = t.relu(self.fc3(a))\n",
    "        a = t.relu(self.fc4(a))\n",
    "        a = t.relu(self.fc5(a))\n",
    "        a = t.relu(self.fc6(a))\n",
    "        a = t.softmax(self.fc7(a), dim=1)\n",
    "        return a\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        # This critic implementation is shared by the prey(DDPG) and\n",
    "        # predators(MADDPG)\n",
    "        # Note: For MADDPG\n",
    "        #       state_dim is the dimension of all states from all agents.\n",
    "        #       action_dim is the dimension of all actions from all agents.\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(state_dim + action_dim, 1024).to(device=\"cuda\")\n",
    "        self.fc2 = nn.Linear(1024, 256).to(device=\"cuda\")\n",
    "        self.fc3 = nn.Linear(256, 128).to(device=\"cuda\")\n",
    "        self.fc4 = nn.Linear(128, 64).to(device=\"cuda\")\n",
    "        self.fc5 = nn.Linear(64, 64).to(device=\"cuda\")\n",
    "        self.fc6 = nn.Linear(64, 32).to(device=\"cuda\")\n",
    "        temp = nn.Linear(32, 1)\n",
    "        temp.weight.data.fill_(3e-5)\n",
    "        self.fc7 =  temp.to(device=\"cuda\")\n",
    "\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        state_action = t.cat([state, action], 1)\n",
    "        #state_action = state_action.cuda()\n",
    "        q = t.relu(self.fc1(state_action))\n",
    "        q = t.relu(self.fc2(q))\n",
    "        q = t.relu(self.fc3(q))\n",
    "        q = t.relu(self.fc4(q))\n",
    "        q = t.relu(self.fc5(q))\n",
    "        q = t.relu(self.fc6(q))\n",
    "        q = self.fc7(q)\n",
    "        #try clamping the reward\n",
    "        #q = t.clamp(q, -200, 200)\n",
    "        return q\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    actor = ActorDiscrete(observe_dim, action_num)\n",
    "    critic = Critic(observe_dim * agent_num, action_num * agent_num)\n",
    "\n",
    "    print(critic.fc3.weight)\n",
    "    \n",
    "    net.static_module_wrapper(actor, \"cuda\", \"cuda\")\n",
    "    net.static_module_wrapper(critic, \"cuda\", \"cuda\")\n",
    "    maddpg = MADDPG(\n",
    "        [deepcopy(actor) for _ in range(agent_num)],\n",
    "        [deepcopy(actor) for _ in range(agent_num)],\n",
    "        [deepcopy(critic) for _ in range(agent_num)],\n",
    "        [deepcopy(critic) for _ in range(agent_num)],\n",
    "        t.optim.Adam,\n",
    "        #t.optim.RAdam,\n",
    "        #t.optim.NAdam,\n",
    "        nn.MSELoss(reduction=\"mean\"),\n",
    "        critic_visible_actors=[list(range(agent_num))] * agent_num,\n",
    "        replay_device=\"cuda\",\n",
    "        discount = 0.99,\n",
    "        replay_size=20000,\n",
    "        actor_learning_rate=0.000005,\n",
    "        critic_learning_rate=0.00005,\n",
    "        update_rate=0.0005\n",
    "    )\n",
    "    \n",
    "\n",
    "    episode, step, reward_fulfilled = 0, 0, 0\n",
    "    smoothed_total_reward = 0\n",
    "\n",
    "    while episode < max_episodes:\n",
    "        episode += 1\n",
    "        total_reward = 0\n",
    "        terminal = False\n",
    "        step = 0\n",
    "        states = [\n",
    "            t.tensor(st, dtype=t.float32).view(1, observe_dim) for st in env.reset()\n",
    "        ]\n",
    "        tmp_observations_list = [[] for _ in range(agent_num)]\n",
    "\n",
    "        while not terminal and step <= max_steps:\n",
    "            step += 1\n",
    "            with t.no_grad():\n",
    "                old_states = states\n",
    "                # agent model inference\n",
    "                results = maddpg.act_discrete_with_noise(\n",
    "                    [{\"state\": st} for st in states]\n",
    "                )\n",
    "                actions = [int(r[0]) for r in results]\n",
    "                action_probs = [r[1] for r in results]\n",
    "                #print(actions)\n",
    "                states, rewards, terminals, _ = env.step(actions)\n",
    "                states = [\n",
    "                    t.tensor(st, dtype=t.float32).view(1, observe_dim) for st in states\n",
    "                ]\n",
    "                total_reward += float(sum(rewards))# / agent_num\n",
    "\n",
    "                for tmp_observations, ost, act, st, rew, term in zip(\n",
    "                    tmp_observations_list,\n",
    "                    old_states,\n",
    "                    action_probs,\n",
    "                    states,\n",
    "                    rewards,\n",
    "                    terminals,\n",
    "                ):\n",
    "                    tmp_observations.append(\n",
    "                        {\n",
    "                            \"state\": {\"state\": ost},\n",
    "                            \"action\": {\"action\": act},\n",
    "                            \"next_state\": {\"state\": st},\n",
    "                            \"reward\": float(rew),\n",
    "                            \"terminal\": term or step == max_steps,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        maddpg.store_episodes(tmp_observations_list)\n",
    "        # total reward is divided by steps here, since:\n",
    "        # \"Agents are rewarded based on minimum agent distance\n",
    "        #  to each landmark, penalized for collisions\"\n",
    "        #total_reward /= \n",
    "        totalAvgReward = total_reward / 50 / 50#step\n",
    "        totalSpaceVisited = np.sum(env.seen)\n",
    "\n",
    "        #maddpg.discount = episode / max_episodes *0.29 + 0.7\n",
    "        print(f\"Episode {episode}\")\n",
    "        print(f\"Number visited {totalSpaceVisited}\")\n",
    "        print(f\"Episode {episode} discount {maddpg.discount}\")\n",
    "        # update, update more if episode is longer, else less\n",
    "        if episode > 100:\n",
    "            for _ in range(step):\n",
    "                maddpg.update()\n",
    "\n",
    "            # show reward\n",
    "        smoothed_total_reward = smoothed_total_reward * 0.9 + totalAvgReward * 0.1\n",
    "        print(f\"Episode {episode} total reward={smoothed_total_reward:.2f}\")\n",
    "        print(f\"Episode {episode} reward={total_reward}\")\n",
    "        print(f\"Episode {episode} avg reward={totalAvgReward}\")\n",
    "        \n",
    "        #if smoothed_total_reward > solved_reward and episode > 100:\n",
    "        #    reward_fulfilled += 1\n",
    "        #    if reward_fulfilled >= solved_repeat:\n",
    "        #        logger.info(\"Environment solved!\")\n",
    "        #        exit(0)\n",
    "        #else:\n",
    "        #    reward_fulfilled = 0\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jacob\\Desktop\\nbavy\\navy research.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000003?line=16'>17</a>\u001b[0m old_states \u001b[39m=\u001b[39m states\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000003?line=17'>18</a>\u001b[0m \u001b[39m# agent model inference\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000003?line=18'>19</a>\u001b[0m results \u001b[39m=\u001b[39m maddpg\u001b[39m.\u001b[39;49mact_discrete(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000003?line=19'>20</a>\u001b[0m     [{\u001b[39m\"\u001b[39;49m\u001b[39mstate\u001b[39;49m\u001b[39m\"\u001b[39;49m: st} \u001b[39mfor\u001b[39;49;00m st \u001b[39min\u001b[39;49;00m states]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000003?line=20'>21</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000003?line=21'>22</a>\u001b[0m actions \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(r[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m results]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000003?line=22'>23</a>\u001b[0m action_probs \u001b[39m=\u001b[39m [r[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m results]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\frame\\algorithms\\maddpg.py:408\u001b[0m, in \u001b[0;36mMADDPG.act_discrete\u001b[1;34m(self, states, use_target)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=385'>386</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mact_discrete\u001b[39m(\u001b[39mself\u001b[39m, states: List[Dict[\u001b[39mstr\u001b[39m, Any]], use_target: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=386'>387</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=387'>388</a>\u001b[0m \u001b[39m    Use all actor networks to produce discrete actions for the current\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=388'>389</a>\u001b[0m \u001b[39m    state.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=405'>406</a>\u001b[0m \u001b[39m        3. Any other things returned by your actor.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=406'>407</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=407'>408</a>\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_act_api_general(states, use_target)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=408'>409</a>\u001b[0m     result \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=409'>410</a>\u001b[0m     \u001b[39mfor\u001b[39;00m action, \u001b[39m*\u001b[39mothers \u001b[39min\u001b[39;00m actions:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\frame\\algorithms\\maddpg.py:457\u001b[0m, in \u001b[0;36mMADDPG._act_api_general\u001b[1;34m(self, states, use_target)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=454'>455</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=455'>456</a>\u001b[0m     actors \u001b[39m=\u001b[39m [choice(sub_actors) \u001b[39mfor\u001b[39;00m sub_actors \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit_actors]\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=456'>457</a>\u001b[0m future \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_safe_call(ac, st) \u001b[39mfor\u001b[39;00m ac, st \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(actors, states)]\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=457'>458</a>\u001b[0m result \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_wait(fut) \u001b[39mfor\u001b[39;00m fut \u001b[39min\u001b[39;00m future]\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=458'>459</a>\u001b[0m result \u001b[39m=\u001b[39m [res \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m (res,) \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\frame\\algorithms\\maddpg.py:457\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=454'>455</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=455'>456</a>\u001b[0m     actors \u001b[39m=\u001b[39m [choice(sub_actors) \u001b[39mfor\u001b[39;00m sub_actors \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit_actors]\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=456'>457</a>\u001b[0m future \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jit_safe_call(ac, st) \u001b[39mfor\u001b[39;00m ac, st \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(actors, states)]\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=457'>458</a>\u001b[0m result \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_wait(fut) \u001b[39mfor\u001b[39;00m fut \u001b[39min\u001b[39;00m future]\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=458'>459</a>\u001b[0m result \u001b[39m=\u001b[39m [res \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m (res,) \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\frame\\algorithms\\maddpg.py:734\u001b[0m, in \u001b[0;36mMADDPG._jit_safe_call\u001b[1;34m(model, *named_args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=731'>732</a>\u001b[0m args_filled[args\u001b[39m.\u001b[39mindex(k)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=732'>733</a>\u001b[0m \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_tensor(v):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=733'>734</a>\u001b[0m     args_list[args\u001b[39m.\u001b[39mindex(k)] \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39;49mto(input_device)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=734'>735</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=735'>736</a>\u001b[0m     args_list[args\u001b[39m.\u001b[39mindex(k)] \u001b[39m=\u001b[39m v\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#MAPPO https://github.com/marlbenchmark/on-policy\n",
    "\n",
    "episode = 0\n",
    "while episode < 1:\n",
    "    episode += 1\n",
    "    total_reward = 0\n",
    "    terminal = False\n",
    "    step = 0\n",
    "    states = [\n",
    "        t.tensor(st, dtype=t.float32).view(1, observe_dim) for st in env.reset()\n",
    "    ]\n",
    "    tmp_observations_list = [[] for _ in range(agent_num)]\n",
    "\n",
    "    while not terminal and step <= max_steps:\n",
    "        step += 1\n",
    "        with t.no_grad():\n",
    "            old_states = states\n",
    "            # agent model inference\n",
    "            results = maddpg.act_discrete_with_noise(\n",
    "                [{\"state\": st} for st in states]\n",
    "            )\n",
    "            actions = [int(r[0]) for r in results]\n",
    "            action_probs = [r[1] for r in results]\n",
    "            #print(actions)\n",
    "            states, rewards, terminals, _ = env.step(actions)\n",
    "            states = [\n",
    "                t.tensor(st, dtype=t.float32).view(1, observe_dim) for st in states\n",
    "            ]\n",
    "            total_reward += float(sum(rewards))# / agent_num\n",
    "            #plt.matshow(np.reshape(states[0], (50,50)) )\n",
    "            for tmp_observations, ost, act, st, rew, term in zip(\n",
    "                tmp_observations_list,\n",
    "                old_states,\n",
    "                action_probs,\n",
    "                states,\n",
    "                rewards,\n",
    "                terminals,\n",
    "            ):\n",
    "                tmp_observations.append(\n",
    "                    {\n",
    "                        \"state\": {\"state\": ost},\n",
    "                        \"action\": {\"action\": act},\n",
    "                        \"next_state\": {\"state\": st},\n",
    "                        \"reward\": float(rew),\n",
    "                        \"terminal\": term or step == max_steps,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    #maddpg.store_episodes(tmp_observations_list)\n",
    "    env.display()\n",
    "    plt.matshow(env.seen)\n",
    "    # total reward is divided by steps here, since:\n",
    "    # \"Agents are rewarded based on minimum agent distance\n",
    "    #  to each landmark, penalized for collisions\"\n",
    "    #total_reward /= \n",
    "    totalAvgReward = total_reward / 50 / 50#step\n",
    "    maddpg.discount = 0.99#episode / max_episodes *0.7 + 0.3\n",
    "    print(f\"Episode {episode}\")\n",
    "    # update, update more if episode is longer, else less\n",
    "    #if episode > 100:\n",
    "    #    for _ in range(step):\n",
    "    #        maddpg.update()\n",
    "\n",
    "        # show reward\n",
    "    smoothed_total_reward = smoothed_total_reward * 0.9 + totalAvgReward * 0.1\n",
    "    print(f\"Episode {episode} total reward={smoothed_total_reward:.2f}\")\n",
    "    print(f\"Episode {episode} reward={total_reward}\")\n",
    "    print(f\"Episode {episode} avg reward={totalAvgReward}\")\n",
    "    \n",
    "    #if smoothed_total_reward > solved_reward and episode > 100:\n",
    "    #    reward_fulfilled += 1\n",
    "    #    if reward_fulfilled >= solved_repeat:\n",
    "    #        logger.info(\"Environment solved!\")\n",
    "    #        exit(0)\n",
    "    #else:\n",
    "    #    reward_fulfilled = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2022-05-25 16:07:40,930] <WARNING>:default_logger:Save name for module \"{r}\" is not specified, module name is used.\u001b[0m\n",
      "\u001b[33m[2022-05-25 16:07:40,999] <WARNING>:default_logger:Save name for module \"{r}\" is not specified, module name is used.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#maddpg.save(\"Rugght here\", version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAALwklEQVR4nO3db6ie9X3H8fdnSTRdOtFUCcHIdFRWfLAqC1ZxD4ZOcLbUgDJaysggEBgbWFZo7QajhT3QJ7V9MDpCleZBqXa2TJHCyNKUMiix8U87/7CZCmVKNA1taBvQetrvHpzL7ig5OXfOuf/2+37BIdef+/b6GA6f/K7f+V33SVUhqa/fmXUASbNlCUjNWQJSc5aA1JwlIDVnCUjNTb0EktyW5L+THE9yz7SvP4okDyY5meTZFce2JzmU5MXhz0tmmXGlJFckOZLk+STPJbl7OD6XmZNsTfJEku8PeT87HL8qydHhe+PhJBfMOus7JdmU5Okkjw/7c595LVMtgSSbgH8G/hy4BvhokmummWFEXwZue8exe4DDVXU1cHjYnxdLwCeq6hrgBuBvhr/Xec38BnBzVb0fuBa4LckNwH3A/VX1XuCnwL7ZRVzV3cALK/YXIfM5TXskcD1wvKpeqqpfAg8Bd0w5w5qq6jvAT95x+A7g4LB9ENgzzUznUlUnquqpYfvnLH+TXs6cZq5lvxh2twxfBdwMPDIcn5u8b0myC/gg8KVhP8x55lFMuwQuB/53xf7Lw7FFsKOqTgzbrwI7ZhlmNUmuBK4DjjLHmYdh9TPASeAQ8EPgdFUtDS+Zx++NzwOfBH497L+H+c+8JicG16GW11rP3XrrJO8Gvg58vKp+tvLcvGWuql9V1bXALpZHiO+bbaJzS/Ih4GRVPTnrLOO2ecrXewW4YsX+ruHYIngtyc6qOpFkJ8v/gs2NJFtYLoCvVNU3hsNznRmgqk4nOQLcCFycZPPwL+u8fW/cBHw4ye3AVuAi4AvMd+aRTHsk8D3g6mFG9QLgI8BjU86wXo8Be4ftvcCjM8zyNsO96QPAC1X1uRWn5jJzksuSXDxsvwu4leV5jCPAXcPL5iYvQFV9uqp2VdWVLH/ffquqPsYcZx5ZVU31C7gd+B+W7wH/YdrXHzHjV4ETwJss3+ftY/n+7zDwIvAfwPZZ51yR909YHur/AHhm+Lp9XjMDfwQ8PeR9FvjH4fgfAE8Ax4F/BS6cddZV8v8p8PgiZT7XV4b/EUlNOTEoNWcJSM1ZAlJzloDUnCUgNTeTEkiyfxbX3YhFy7xoecHMs7KhEtjAY8GL+Be3aJkXLS+YeSbWXQIL9FiwpHPYyLMDv3ksGCDJW48FP7/aGy7IhbWVbWzld7ko2xdqldKiZV60vGDmSXqdM/yy3sjZzm2kBM72WPAHzvWGrWzjA7llA5eUtB5H6/Cq5yb+FOEwcbIflltT0nzZyMTgSI8FV9WBqtpdVbu3cOEGLidpEjZSAov8WLCkwbpvB6pqKcnfAv8ObAIerKrnxpZM0lRsaE6gqr4JfHNMWSTNgMuGpeYsAak5S0BqzhKQmrMEpOYsAak5S0BqzhKQmrMEpOYsAak5S0BqzhKQmrMEpOYsAak5S0BqzhKQmrMEpOYsAak5S0BqzhKQmrMEpOYsAak5S0BqzhKQmrMEpOYsAak5S0BqzhKQmrMEpOYsAak5S0BqzhKQmrMEpOYsAak5S0BqzhKQmluzBJI8mORkkmdXHNue5FCSF4c/L5lsTEmTMspI4MvAbe84dg9wuKquBg4P+5IW0JolUFXfAX7yjsN3AAeH7YPAnvHGkjQt650T2FFVJ4btV4EdY8ojaco2PDFYVQXUaueT7E9yLMmxN3ljo5eTNGab1/m+15LsrKoTSXYCJ1d7YVUdAA4AXJTtq5bFb7tT+2+c2rUuPfDdqV1Li2+9I4HHgL3D9l7g0fHEkTRto/yI8KvAd4E/TPJykn3AvcCtSV4E/mzYl7SA1rwdqKqPrnLqljFnkTQDrhiUmlvvxODETHMCTZIjAak9S0BqzhKQmpvpnID3/9LsORKQmrMEpOYsAak5S0BqzhKQmrMEpOYsAak5S0BqbqqLhZYu3capO10gNE5+ipA2ypGA1JwlIDVnCUjNWQJSc5aA1JwlIDVnCUjNWQJSc3P3acM6P6N8OpMLinQujgSk5iwBqTlLQGrOEpCaswSk5iwBqTlLQGrOEpCaW8jFQk9+5otv2//jz/z1jJIshrMtKHIBkd7iSEBqzhKQmrMEpObWLIEkVyQ5kuT5JM8luXs4vj3JoSQvDn9eMvm4ksZtlInBJeATVfVUkt8DnkxyCPgr4HBV3ZvkHuAe4FOTi/r/nAiUxmfNkUBVnaiqp4btnwMvAJcDdwAHh5cdBPZMKKOkCTqvOYEkVwLXAUeBHVV1Yjj1KrBjvNEkTcPIJZDk3cDXgY9X1c9WnquqAmqV9+1PcizJsaXXz2worKTxG6kEkmxhuQC+UlXfGA6/lmTncH4ncPJs762qA1W1u6p2b966bRyZJY3RKD8dCPAA8EJVfW7FqceAvcP2XuDR8ceTNGmj/HTgJuAvgf9K8sxw7O+Be4GvJdkH/Aj4i4kklDRRa5ZAVf0nkFVO3zLeOJKmzRWDUnOWgNScJSA1ZwlIzVkCUnNT/WShzafOjOUTbUb51Vud+alBOh+OBKTmLAGpOUtAas4SkJqb6UeOO8G3cU4CaqMcCUjNWQJSc5aA1NxU5wSWLt3GqTudBxiV9/uaBkcCUnOWgNScJSA1t5C/mryLUdZROG+gjXIkIDVnCUjNWQJSc5aA1JwlIDVnCUjNWQJSc5aA1JyLhRbc2RYUuYBI58ORgNScJSA1ZwlIzVkCUnOWgNScJSA1ZwlIza1ZAkm2JnkiyfeTPJfks8Pxq5IcTXI8ycNJLph8XEnjNspI4A3g5qp6P3AtcFuSG4D7gPur6r3AT4F9E0spaWLWLIFa9othd8vwVcDNwCPD8YPAnkkElDRZI80JJNmU5BngJHAI+CFwuqqWhpe8DFw+kYSSJmqkEqiqX1XVtcAu4HrgfaNeIMn+JMeSHFt6/cz6UkqamPP66UBVnQaOADcCFyd56wGkXcArq7znQFXtrqrdm7du20hWSROw5lOESS4D3qyq00neBdzK8qTgEeAu4CFgL/DoJIMuui17fvy2/Tf/7bIZJZHebpRHiXcCB5NsYnnk8LWqejzJ88BDSf4JeBp4YII5JU3ImiVQVT8ArjvL8ZdYnh+QtMBcMSg1N9VPFtp86szbPvVmlF+z9dvCOQDNK0cCUnOWgNScJSA1ZwlIzU11YnDp0m2curPPZOAk+HHiGjdHAlJzloDUnCUgNWcJSM1ZAlJzloDUnCUgNWcJSM1NdbGQzo8LgzQNjgSk5iwBqTlLQGrOEpCaswSk5iwBqTlLQGrOEpCaa71YyMU4kiMBqT1LQGrOEpCaswSk5iwBqTlLQGrOEpCaswSk5qa6WGjzqTNrLtA5tX88v6bMhUDSaBwJSM1ZAlJzI5dAkk1Jnk7y+LB/VZKjSY4neTjJBZOLKWlSzmdO4G7gBeCiYf8+4P6qeijJvwD7gC9uNJD38tJ0jTQSSLIL+CDwpWE/wM3AI8NLDgJ7JpBP0oSNejvweeCTwK+H/fcAp6tqadh/Gbh8vNEkTcOaJZDkQ8DJqnpyPRdIsj/JsSTH3uSN9fwnJE3QKHMCNwEfTnI7sJXlOYEvABcn2TyMBnYBr5ztzVV1ADgAcFG211hSSxqbNUcCVfXpqtpVVVcCHwG+VVUfA44Adw0v2ws8OrGUkiZmI+sEPgX8XZLjLM8RPDCeSJKm6byWDVfVt4FvD9svAdePP5KkaXLFoNScJSA1ZwlIzVkCUnOWgNScJSA1ZwlIzVkCUnOWgNScJSA1ZwlIzVkCUnOWgNScJSA1ZwlIzVkCUnOWgNScJSA1ZwlIzVkCUnOWgNScJSA1ZwlIzVkCUnOWgNScJSA1ZwlIzVkCUnOWgNScJSA1ZwlIzVkCUnOWgNScJSA1ZwlIzVkCUnOWgNRcqmp6F0t+DPwIuBQ4NbULj8eiZV60vGDmSfr9qrrsbCemWgK/uWhyrKp2T/3CG7BomRctL5h5VrwdkJqzBKTmZlUCB2Z03Y1YtMyLlhfMPBMzmROQND+8HZCaswSk5iwBqTlLQGrOEpCa+z9/cV1Y4gF2XwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.display()\n",
    "for i in range(len(states)):\n",
    "    plt.matshow( np.reshape(states[i], (50,50)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c7f822a9fda7ffd10530ef71b8007e75e5e59461c46d04a19e3026085bccd1b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
