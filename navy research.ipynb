{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im not meantr to thbe there\n",
      "Im not meantr to thbe there\n",
      "Im not meantr to thbe there\n",
      "Im not meantr to thbe there\n",
      "[-4, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Wireless sensor networm combined with autonomous drone swarm and communication reduction\n",
    "#https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7391193&casa_token=wZ2spLDNZroAAAAA:YDmwxnfhCvPGV002JGv_1lSta5d7yBgcY3P0YYrw24wKr7-hJWuTdR5tTvuWe1Z4vZgFr-pgs8Y\n",
    "\n",
    "import random as rand\n",
    "import numpy as np\n",
    "#rand.seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import math\n",
    "import gym\n",
    "from copy import deepcopy\n",
    "\n",
    "ViewRange = 2\n",
    "CommRange = 5#5\n",
    "AgentAmmount = 5\n",
    "\n",
    "#double distance = 2/3 as efficient transfer\n",
    "class Task:\n",
    "    def __init__(self):\n",
    "        self.priority = rand.randint(1, 10)\n",
    "        self.size = rand.randint(100, 1000)\n",
    "\n",
    "\n",
    "\n",
    "#Vessel\n",
    "#Constraints: Bandwidth - Num of Chanels - communication distance\n",
    "#Objective: Energy Reduction - Task priority \n",
    "class Drone:\n",
    "    def __init__(self, x, y, viewRange, commRange, width, height, index, Sea):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.task = None\n",
    "        self.viewRange = viewRange\n",
    "        self.commRange = commRange\n",
    "        self.observation = [[0]*width]*height\n",
    "        self.id = index\n",
    "        #self.seen = np.array([[0]*Sea.width]*Sea.height)\n",
    "        self.obs = np.array([[0]*Sea.width]*Sea.height)\n",
    "        self.punish = 0\n",
    "    def getView(self):\n",
    "        return None\n",
    "\n",
    "    def getObservation(self, Sea):\n",
    "        #Get view\n",
    "        #obs = np.array([[0]*Sea.width]*Sea.height)\n",
    "        reward = 0 \n",
    "        for i in range(self.y-self.viewRange, self.y+self.viewRange):\n",
    "            for j in range(self.x-self.viewRange, self.x+self.viewRange):\n",
    "                if i < 50 and i >= 0  and j < 50 and j >= 0:\n",
    "                    if Sea.board[i][j] == 0:\n",
    "                        self.obs[i][j] = 1\n",
    "                    else:\n",
    "                        self.obs[i][j] = Sea.board[i][j]\n",
    "\n",
    "                    if Sea.seen[i][j] == 0:\n",
    "                        Sea.seen[i][j] = 1\n",
    "                        reward += 1\n",
    "        reward += self.punish\n",
    "        res = deepcopy(self.obs)\n",
    "        #make them seperate\n",
    "        res[self.y][self.x] = 3 + self.id\n",
    "        return res, reward\n",
    "\n",
    "    def move(self,x, y, see):\n",
    "        x = x + self.x\n",
    "        y = y + self.y\n",
    "\n",
    "        self.punish = 0\n",
    "\n",
    "        if (x < 50 and x >= 0 and y < 50 and y >= 0) and (see.board[y][x] == 0 or see.board[y][x] == 2 or see.board[y][x] == -2) :\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "        else:\n",
    "            #punishment\n",
    "            self.punish -= 4\n",
    "\n",
    "    \n",
    "    def addData(self, drone):\n",
    "        pass\n",
    "    def setData(self, obs):\n",
    "        self.observation = abs\n",
    "#Constraints: Bandwidth, Num of Chanels\n",
    "#Objective Explore the sea\n",
    "class Ship:\n",
    "    def __init__(self, x, y, bandwidth):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.bandwidth = bandwidth\n",
    "\n",
    "\n",
    "#Actions move up down left right \n",
    "class Sea:\n",
    "\n",
    "    def __init__(self):#, width, height):\n",
    "        self.width = 50#width\n",
    "        self.height =50# height\n",
    "\n",
    "        self.observe_dim = 50*50#env.observation_space[0].shape[0]\n",
    "        self.action_num = 4\n",
    "        self.max_step = 200\n",
    "        self.state_dim = 50*50\n",
    "        self.action_dim = 4\n",
    "        self.target_return = 50*50\n",
    "        self.env_num = 500\n",
    "        self.if_discrete = True\n",
    "        self.env_name = \"Sea\"\n",
    "        self.reward_range = (-200*4, 50*50)\n",
    "        #self.objects = objects\n",
    "        #int array -2 = dead zone (ie no communication) -1 = object 0 = sea 1 = ship 2 = drone\n",
    "        self.board = np.array( [ [0]*self.width]*self.height )\n",
    "        #for obj in objects:\n",
    "        #    self.board[obj.y][obj.x] = -1\n",
    "\n",
    "        #for i in range(self.height):\n",
    "        #    for j in range(self.width):\n",
    "        #        rock = rand.randint(0, 30)\n",
    "        #        if(rock == 0):\n",
    "        #            self.board[i][j] = -1\n",
    "\n",
    "        self.cmap = ListedColormap([ 'k', 'b'])\n",
    "\n",
    "    def calculateDeadZone2(self, board):\n",
    "        shipx = self.ship.x\n",
    "        shipy = self.ship.y\n",
    "\n",
    "        for y in range(0, self.height):\n",
    "            for x in range(0, self.width):\n",
    "                if board[y][x] != 0:\n",
    "                    continue\n",
    "                startx = x\n",
    "                starty = y\n",
    "                x0 = startx\n",
    "                y0 = starty\n",
    "                x1 = shipx\n",
    "                y1 = shipy\n",
    "                dx = abs(x1 - x0)\n",
    "                sx = -1\n",
    "                if x0 < x1:\n",
    "                    sx = 1\n",
    "                dy = -abs(y1 - y0)\n",
    "                sy = -1\n",
    "                if y0 < y1:\n",
    "                    sy = 1\n",
    "                error = dx + dy\n",
    "\n",
    "                while True:\n",
    "                    if(board[y0][x0] == -1):\n",
    "                        board[y][x] = -2\n",
    "                        break\n",
    "                    if x0 == x1 and y0 == y1:\n",
    "                        break\n",
    "                    e2 = 2 * error\n",
    "                    if e2 >= dy:\n",
    "                        if x0 == x1: \n",
    "                            break\n",
    "                        error = error + dy\n",
    "                        x0 = x0 + sx\n",
    "                    \n",
    "                    if e2 <= dx:\n",
    "                        if y0 == y1:\n",
    "                            break\n",
    "                        error = error + dx\n",
    "                        y0 = y0 + sy\n",
    "\n",
    "    def AddShip(self, ship):\n",
    "        self.ship = ship\n",
    "        self.board[ship.y][ship.x] = 2\n",
    "        for i in range(ship.y - 2, ship.y+2):\n",
    "            for j in range(ship.x - 2, ship.x + 2):\n",
    "                if i >= 0 and j >= 0 and i < self.height and j < self.width and self.board[i][j] == -1:\n",
    "                    self.board[i][j] = 0\n",
    "\n",
    "    def display(self):\n",
    "        newBoard = np.copy(self.board)\n",
    "        if ( hasattr(self, 'ship')):\n",
    "            newBoard[self.ship.y][self.ship.x] = 2\n",
    "            #self.calculateDeadZone2(newBoard)\n",
    "            self.cmap = ListedColormap([ 'k',  'b', 'g', 'y', 'r'])\n",
    "\n",
    "        for drone in self.drones:\n",
    "            newBoard[drone.y][drone.x] = 3\n",
    "\n",
    "        plt.matshow(newBoard, cmap=self.cmap)\n",
    "\n",
    "    def interestMap(self):\n",
    "        interest = [[0]*self.width]*self.height\n",
    "        samples = np.random.multivariate_normal([-0.5, -0.5], [[1, 0],[0, 1]], 50)\n",
    "        huh  = np.reshape(samples, (10,10))\n",
    "        print(huh)\n",
    "        plt.close()\n",
    "        plt.matshow(huh)\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.array( [ [0]*self.width]*self.height )\n",
    "        #for obj in objects:\n",
    "        #    self.board[obj.y][obj.x] = -1\n",
    "\n",
    "        #for i in range(self.height):\n",
    "        #    for j in range(self.width):\n",
    "        #        rock = rand.randint(0, 30)\n",
    "        #        if(rock == 0):\n",
    "        #            self.board[i][j] = -1\n",
    "        \n",
    "        shipx = rand.randint(0, 49)\n",
    "        shipy = rand.randint(1, 49)\n",
    "        ship = Ship(shipx, shipy, 100)\n",
    "        self.AddShip(ship)\n",
    "        self.seen = np.array([[0]*50]*50)\n",
    "        self.drones = []\n",
    "\n",
    "        for i in range(AgentAmmount):\n",
    "            self.drones.append(Drone(shipx, shipy-1,ViewRange, CommRange, self.width, self.height, i, self))\n",
    "        observations, rewards = self.getObservation()\n",
    "\n",
    "        return observations\n",
    "\n",
    "    def step(self, actions):\n",
    "        droneIdx= 0\n",
    "        for act in actions:\n",
    "            match act:\n",
    "                case 0:\n",
    "                    self.drones[droneIdx].move(1,0, self)\n",
    "                case 1:\n",
    "                    self.drones[droneIdx].move(-1,0, self)\n",
    "                case 2:\n",
    "                    self.drones[droneIdx].move(0,1, self)\n",
    "                case 3:\n",
    "                    self.drones[droneIdx].move(0, -1, self)\n",
    "                case 4:\n",
    "                    print(\"Im not meantr to thbe there\")\n",
    "            droneIdx+= 1\n",
    "                \n",
    "                \n",
    "        #count  = [0] * AgentAmmount\n",
    "        #for i in range(self.height):\n",
    "        #    for j in range(self.width):\n",
    "        #        for drone in self.drones:\n",
    "        #            if drone.seen[i][j] == 1:\n",
    "        #                count[drone.id] += 1\n",
    "                        \n",
    "        #reward = count / float(self.width*self.height)\n",
    "        #reward = [t/float(self.width*self.height) for t in count]\n",
    "\n",
    "\n",
    "        observations, rewards = self.getObservation()\n",
    "\n",
    "        return observations, rewards, [False]*AgentAmmount, None\n",
    "\n",
    "    def getObservation(self):\n",
    "        currentIndex = 1\n",
    "        droneConnection = [0]*AgentAmmount\n",
    "\n",
    "        for drone in self.drones:\n",
    "            \n",
    "            for connectDrone in self.drones:\n",
    "                if drone.id == connectDrone.id:\n",
    "                    continue\n",
    "                if (droneConnection[drone.id] == 0 or droneConnection[drone.id] != droneConnection[connectDrone.id]) \\\n",
    "                            and math.sqrt( (drone.x - connectDrone.x)**2 + (drone.y - connectDrone.y)**2 ) < CommRange:\n",
    "                    #do stuff\n",
    "                    if droneConnection[drone.id] == 0 and droneConnection[connectDrone.id] == 0:\n",
    "                        droneConnection[drone.id] = currentIndex\n",
    "                        droneConnection[connectDrone.id] = currentIndex\n",
    "                        currentIndex += 1\n",
    "                    elif droneConnection[drone.id] != 0 and droneConnection[connectDrone.id] != 0:\n",
    "                        swap = droneConnection[connectDrone.id]\n",
    "                        for i in droneConnection:\n",
    "                            if i == swap:\n",
    "                                i = droneConnection[drone.id]\n",
    "                    else:\n",
    "                        if(droneConnection[drone.id] == 0):\n",
    "                            droneConnection[drone.id] = droneConnection[connectDrone.id]\n",
    "                        else:\n",
    "                            droneConnection[connectDrone.id] = droneConnection[drone.id]\n",
    "\n",
    "        for t in range(len(droneConnection)):\n",
    "            if droneConnection[t] == 0:\n",
    "                droneConnection[t] = currentIndex\n",
    "                currentIndex += 1\n",
    "\n",
    "        obsDict = {}\n",
    "        rewardList = [0] * AgentAmmount\n",
    "        index = 0\n",
    "        for i in droneConnection:\n",
    "\n",
    "            values, reward = self.drones[index].getObservation(self)\n",
    "\n",
    "            if str(i) in obsDict:\n",
    "                values = np.array(values).flatten()\n",
    "                curr = obsDict[str(i)]\n",
    "                \n",
    "                for i in range(len(curr)):\n",
    "                    \n",
    "                    if(curr[i] == 1 and values[i] != 0):\n",
    "                        curr[i] = values[i]\n",
    "                    if(curr[i] == 0):\n",
    "                        curr[i] = values[i]\n",
    "\n",
    "            else:\n",
    "                obsDict[str(i)] = np.array(values).flatten()\n",
    "            \n",
    "            rewardList[index]= reward\n",
    "            index += 1\n",
    "\n",
    "        observations = []\n",
    "\n",
    "\n",
    "        for i in droneConnection:\n",
    "            observations.append(obsDict[str(i)])\n",
    "\n",
    "        for index, i in enumerate(observations):\n",
    "            t = deepcopy(i)\n",
    "            t[t == 3] = 1\n",
    "            t[ t == 4] = 1\n",
    "            t[t == 5 ] = 1\n",
    "            t[t == 6 ] = 1\n",
    "            t[ t == 7 ] = 1\n",
    "            t[ t == 8 ] = 1\n",
    "            self.drones[index].obs = np.reshape(t, (50,50))\n",
    "\n",
    "\n",
    "        return observations, rewardList\n",
    "class Object:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y \n",
    "\n",
    "see = Sea()#50, 50)\n",
    "\n",
    "see.reset()\n",
    "#obs, reward, _, _ = see.step([0, 1])\n",
    "#plt.matshow( np.reshape(obs[0], (50,50)) )\n",
    "#plt.matshow( np.reshape(obs[1], (50,50)) )\n",
    "see.display()\n",
    "obs, reward, _, _ = see.step([0, 4])\n",
    "obs, reward, _, _ = see.step([0, 4])\n",
    "obs, reward, _, _ = see.step([0, 4])\n",
    "obs, reward, _, _ = see.step([0, 4])\n",
    "plt.matshow( np.reshape(obs[0], (50,50)) )\n",
    "plt.matshow( np.reshape(obs[1], (50,50)) )\n",
    "see.display()\n",
    "#plt.matshow(seen)\n",
    "print(reward)\n",
    "#obs, reward, _, _ = see.step([0, 1])\n",
    "#plt.matshow( np.reshape(obs[0], (50,50)) )\n",
    "#plt.matshow( np.reshape(obs[1], (50,50)) )\n",
    "#see.display()\n",
    "\n",
    "#print(reward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e7e997c6d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def perlin(x, y):\n",
    "    # permutation table\n",
    "    p = np.arange(256, dtype=int)\n",
    "    np.random.shuffle(p)\n",
    "    p = np.stack([p, p]).flatten()\n",
    "    # coordinates of the top-left\n",
    "    xi, yi = x.astype(int), y.astype(int)\n",
    "    # internal coordinates\n",
    "    xf, yf = x - xi, y - yi\n",
    "    # fade factors\n",
    "    u, v = fade(xf), fade(yf)\n",
    "    # noise components\n",
    "    n00 = gradient(p[p[xi] + yi], xf, yf)\n",
    "    n01 = gradient(p[p[xi] + yi + 1], xf, yf - 1)\n",
    "    n11 = gradient(p[p[xi + 1] + yi + 1], xf - 1, yf - 1)\n",
    "    n10 = gradient(p[p[xi + 1] + yi], xf - 1, yf)\n",
    "    # combine noises\n",
    "    x1 = lerp(n00, n10, u)\n",
    "    x2 = lerp(n01, n11, u)  # FIX1: I was using n10 instead of n01\n",
    "    return lerp(x1, x2, v)  # FIX2: I also had to reverse x1 and x2 here\n",
    "\n",
    "def lerp(a, b, x):\n",
    "    \"linear interpolation\"\n",
    "    return a + x * (b - a)\n",
    "\n",
    "def fade(t):\n",
    "    \"6t^5 - 15t^4 + 10t^3\"\n",
    "    return 6 * t**5 - 15 * t**4 + 10 * t**3\n",
    "\n",
    "def gradient(h, x, y):\n",
    "    \"grad converts h to the right gradient vector and return the dot product with (x,y)\"\n",
    "    vectors = np.array([[0, 1], [0, -1], [1, 0], [-1, 0]])\n",
    "    g = vectors[h % 4]\n",
    "    return g[:, :, 0] * x + g[:, :, 1] * y\n",
    "\n",
    "lin = np.linspace(0, 5, 50, endpoint=False)\n",
    "x, y = np.meshgrid(lin, lin)  # FIX3: I thought I had to invert x and y here but it was a mistake\n",
    "data = perlin(x, y)\n",
    "data = data*7\n",
    "data = np.round(data)\n",
    "data[data < 0] = 0\n",
    "print(data.max())\n",
    "print(data.min())\n",
    "plt.imshow(data, origin='upper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "4\n",
      "Parameter containing:\n",
      "tensor([[ 0.0249, -0.0147,  0.0078,  ...,  0.0064, -0.0192,  0.0003],\n",
      "        [ 0.0091, -0.0252,  0.0282,  ...,  0.0024,  0.0013,  0.0221],\n",
      "        [ 0.0227, -0.0075,  0.0239,  ..., -0.0106,  0.0297,  0.0179],\n",
      "        ...,\n",
      "        [ 0.0298, -0.0121, -0.0037,  ...,  0.0016, -0.0172, -0.0232],\n",
      "        [ 0.0219, -0.0258, -0.0278,  ..., -0.0131, -0.0007,  0.0130],\n",
      "        [-0.0104, -0.0001, -0.0109,  ...,  0.0076, -0.0043, -0.0134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Episode 1\n",
      "Number visited 843\n",
      "Episode 1 exploratrion 0.19986666666666666\n",
      "Episode 1 total reward=0.03\n",
      "Episode 1 reward=799.0\n",
      "Episode 1 avg reward=0.3196\n",
      "Episode 2\n",
      "Number visited 267\n",
      "Episode 2 exploratrion 0.19973333333333335\n",
      "Episode 2 total reward=0.02\n",
      "Episode 2 reward=-253.0\n",
      "Episode 2 avg reward=-0.1012\n",
      "Episode 3\n",
      "Number visited 905\n",
      "Episode 3 exploratrion 0.1996\n",
      "Episode 3 total reward=0.05\n",
      "Episode 3 reward=865.0\n",
      "Episode 3 avg reward=0.34600000000000003\n",
      "Episode 4\n",
      "Number visited 199\n",
      "Episode 4 exploratrion 0.19946666666666668\n",
      "Episode 4 total reward=0.03\n",
      "Episode 4 reward=-449.0\n",
      "Episode 4 avg reward=-0.1796\n",
      "Episode 5\n",
      "Number visited 536\n",
      "Episode 5 exploratrion 0.19933333333333333\n",
      "Episode 5 total reward=0.04\n",
      "Episode 5 reward=256.0\n",
      "Episode 5 avg reward=0.1024\n",
      "Episode 6\n",
      "Number visited 584\n",
      "Episode 6 exploratrion 0.19920000000000002\n",
      "Episode 6 total reward=0.05\n",
      "Episode 6 reward=568.0\n",
      "Episode 6 avg reward=0.22719999999999999\n",
      "Episode 7\n",
      "Number visited 170\n",
      "Episode 7 exploratrion 0.19906666666666667\n",
      "Episode 7 total reward=0.03\n",
      "Episode 7 reward=-562.0\n",
      "Episode 7 avg reward=-0.2248\n",
      "Episode 8\n",
      "Number visited 351\n",
      "Episode 8 exploratrion 0.19893333333333335\n",
      "Episode 8 total reward=0.03\n",
      "Episode 8 reward=95.0\n",
      "Episode 8 avg reward=0.038\n",
      "Episode 9\n",
      "Number visited 420\n",
      "Episode 9 exploratrion 0.1988\n",
      "Episode 9 total reward=0.03\n",
      "Episode 9 reward=124.0\n",
      "Episode 9 avg reward=0.0496\n",
      "Episode 10\n",
      "Number visited 822\n",
      "Episode 10 exploratrion 0.19866666666666669\n",
      "Episode 10 total reward=0.06\n",
      "Episode 10 reward=786.0\n",
      "Episode 10 avg reward=0.3144\n",
      "Episode 11\n",
      "Number visited 595\n",
      "Episode 11 exploratrion 0.19853333333333334\n",
      "Episode 11 total reward=0.06\n",
      "Episode 11 reward=307.0\n",
      "Episode 11 avg reward=0.12279999999999999\n",
      "Episode 12\n",
      "Number visited 353\n",
      "Episode 12 exploratrion 0.19840000000000002\n",
      "Episode 12 total reward=0.05\n",
      "Episode 12 reward=-127.0\n",
      "Episode 12 avg reward=-0.0508\n",
      "Episode 13\n",
      "Number visited 662\n",
      "Episode 13 exploratrion 0.19826666666666667\n",
      "Episode 13 total reward=0.07\n",
      "Episode 13 reward=634.0\n",
      "Episode 13 avg reward=0.2536\n",
      "Episode 14\n",
      "Number visited 1017\n",
      "Episode 14 exploratrion 0.19813333333333336\n",
      "Episode 14 total reward=0.10\n",
      "Episode 14 reward=917.0\n",
      "Episode 14 avg reward=0.3668\n",
      "Episode 15\n",
      "Number visited 254\n",
      "Episode 15 exploratrion 0.198\n",
      "Episode 15 total reward=0.09\n",
      "Episode 15 reward=-114.0\n",
      "Episode 15 avg reward=-0.045599999999999995\n",
      "Episode 16\n",
      "Number visited 655\n",
      "Episode 16 exploratrion 0.1978666666666667\n",
      "Episode 16 total reward=0.10\n",
      "Episode 16 reward=631.0\n",
      "Episode 16 avg reward=0.25239999999999996\n",
      "Episode 17\n",
      "Number visited 347\n",
      "Episode 17 exploratrion 0.19773333333333334\n",
      "Episode 17 total reward=0.09\n",
      "Episode 17 reward=-93.0\n",
      "Episode 17 avg reward=-0.037200000000000004\n",
      "Episode 18\n",
      "Number visited 322\n",
      "Episode 18 exploratrion 0.1976\n",
      "Episode 18 total reward=0.08\n",
      "Episode 18 reward=-130.0\n",
      "Episode 18 avg reward=-0.052000000000000005\n",
      "Episode 19\n",
      "Number visited 87\n",
      "Episode 19 exploratrion 0.19746666666666668\n",
      "Episode 19 total reward=0.04\n",
      "Episode 19 reward=-621.0\n",
      "Episode 19 avg reward=-0.2484\n",
      "Episode 20\n",
      "Number visited 575\n",
      "Episode 20 exploratrion 0.19733333333333333\n",
      "Episode 20 total reward=0.06\n",
      "Episode 20 reward=415.0\n",
      "Episode 20 avg reward=0.166\n",
      "Episode 21\n",
      "Number visited 421\n",
      "Episode 21 exploratrion 0.19720000000000001\n",
      "Episode 21 total reward=0.05\n",
      "Episode 21 reward=85.0\n",
      "Episode 21 avg reward=0.034\n",
      "Episode 22\n",
      "Number visited 1002\n",
      "Episode 22 exploratrion 0.19706666666666667\n",
      "Episode 22 total reward=0.09\n",
      "Episode 22 reward=954.0\n",
      "Episode 22 avg reward=0.38159999999999994\n",
      "Episode 23\n",
      "Number visited 342\n",
      "Episode 23 exploratrion 0.19693333333333335\n",
      "Episode 23 total reward=0.07\n",
      "Episode 23 reward=-142.0\n",
      "Episode 23 avg reward=-0.056799999999999996\n",
      "Episode 24\n",
      "Number visited 814\n",
      "Episode 24 exploratrion 0.1968\n",
      "Episode 24 total reward=0.10\n",
      "Episode 24 reward=774.0\n",
      "Episode 24 avg reward=0.3096\n",
      "Episode 25\n",
      "Number visited 851\n",
      "Episode 25 exploratrion 0.19666666666666668\n",
      "Episode 25 total reward=0.12\n",
      "Episode 25 reward=795.0\n",
      "Episode 25 avg reward=0.318\n",
      "Episode 26\n",
      "Number visited 614\n",
      "Episode 26 exploratrion 0.19653333333333334\n",
      "Episode 26 total reward=0.13\n",
      "Episode 26 reward=474.0\n",
      "Episode 26 avg reward=0.18960000000000002\n",
      "Episode 27\n",
      "Number visited 808\n",
      "Episode 27 exploratrion 0.19640000000000002\n",
      "Episode 27 total reward=0.14\n",
      "Episode 27 reward=788.0\n",
      "Episode 27 avg reward=0.3152\n",
      "Episode 28\n",
      "Number visited 799\n",
      "Episode 28 exploratrion 0.19626666666666667\n",
      "Episode 28 total reward=0.16\n",
      "Episode 28 reward=723.0\n",
      "Episode 28 avg reward=0.2892\n",
      "Episode 29\n",
      "Number visited 834\n",
      "Episode 29 exploratrion 0.19613333333333335\n",
      "Episode 29 total reward=0.18\n",
      "Episode 29 reward=810.0\n",
      "Episode 29 avg reward=0.324\n",
      "Episode 30\n",
      "Number visited 649\n",
      "Episode 30 exploratrion 0.196\n",
      "Episode 30 total reward=0.18\n",
      "Episode 30 reward=477.0\n",
      "Episode 30 avg reward=0.19079999999999997\n",
      "Episode 31\n",
      "Number visited 724\n",
      "Episode 31 exploratrion 0.1958666666666667\n",
      "Episode 31 total reward=0.19\n",
      "Episode 31 reward=660.0\n",
      "Episode 31 avg reward=0.264\n",
      "Episode 32\n",
      "Number visited 527\n",
      "Episode 32 exploratrion 0.19573333333333334\n",
      "Episode 32 total reward=0.18\n",
      "Episode 32 reward=203.0\n",
      "Episode 32 avg reward=0.0812\n",
      "Episode 33\n",
      "Number visited 247\n",
      "Episode 33 exploratrion 0.19560000000000002\n",
      "Episode 33 total reward=0.14\n",
      "Episode 33 reward=-317.0\n",
      "Episode 33 avg reward=-0.1268\n",
      "Episode 34\n",
      "Number visited 295\n",
      "Episode 34 exploratrion 0.19546666666666668\n",
      "Episode 34 total reward=0.13\n",
      "Episode 34 reward=-89.0\n",
      "Episode 34 avg reward=-0.0356\n",
      "Episode 35\n",
      "Number visited 454\n",
      "Episode 35 exploratrion 0.19533333333333333\n",
      "Episode 35 total reward=0.12\n",
      "Episode 35 reward=178.0\n",
      "Episode 35 avg reward=0.0712\n",
      "Episode 36\n",
      "Number visited 647\n",
      "Episode 36 exploratrion 0.1952\n",
      "Episode 36 total reward=0.13\n",
      "Episode 36 reward=547.0\n",
      "Episode 36 avg reward=0.2188\n",
      "Episode 37\n",
      "Number visited 353\n",
      "Episode 37 exploratrion 0.19506666666666667\n",
      "Episode 37 total reward=0.12\n",
      "Episode 37 reward=29.0\n",
      "Episode 37 avg reward=0.0116\n",
      "Episode 38\n",
      "Number visited 270\n",
      "Episode 38 exploratrion 0.19493333333333335\n",
      "Episode 38 total reward=0.10\n",
      "Episode 38 reward=-234.0\n",
      "Episode 38 avg reward=-0.09359999999999999\n",
      "Episode 39\n",
      "Number visited 334\n",
      "Episode 39 exploratrion 0.1948\n",
      "Episode 39 total reward=0.09\n",
      "Episode 39 reward=66.0\n",
      "Episode 39 avg reward=0.0264\n",
      "Episode 40\n",
      "Number visited 503\n",
      "Episode 40 exploratrion 0.19466666666666668\n",
      "Episode 40 total reward=0.09\n",
      "Episode 40 reward=303.0\n",
      "Episode 40 avg reward=0.12119999999999999\n",
      "Episode 41\n",
      "Number visited 292\n",
      "Episode 41 exploratrion 0.19453333333333334\n",
      "Episode 41 total reward=0.08\n",
      "Episode 41 reward=-132.0\n",
      "Episode 41 avg reward=-0.0528\n",
      "Episode 42\n",
      "Number visited 183\n",
      "Episode 42 exploratrion 0.19440000000000002\n",
      "Episode 42 total reward=0.06\n",
      "Episode 42 reward=-321.0\n",
      "Episode 42 avg reward=-0.1284\n",
      "Episode 43\n",
      "Number visited 216\n",
      "Episode 43 exploratrion 0.19426666666666667\n",
      "Episode 43 total reward=0.04\n",
      "Episode 43 reward=-396.0\n",
      "Episode 43 avg reward=-0.15839999999999999\n",
      "Episode 44\n",
      "Number visited 344\n",
      "Episode 44 exploratrion 0.19413333333333335\n",
      "Episode 44 total reward=0.04\n",
      "Episode 44 reward=176.0\n",
      "Episode 44 avg reward=0.0704\n",
      "Episode 45\n",
      "Number visited 418\n",
      "Episode 45 exploratrion 0.194\n",
      "Episode 45 total reward=0.04\n",
      "Episode 45 reward=190.0\n",
      "Episode 45 avg reward=0.076\n",
      "Episode 46\n",
      "Number visited 412\n",
      "Episode 46 exploratrion 0.1938666666666667\n",
      "Episode 46 total reward=0.04\n",
      "Episode 46 reward=-16.0\n",
      "Episode 46 avg reward=-0.0064\n",
      "Episode 47\n",
      "Number visited 901\n",
      "Episode 47 exploratrion 0.19373333333333334\n",
      "Episode 47 total reward=0.07\n",
      "Episode 47 reward=881.0\n",
      "Episode 47 avg reward=0.35240000000000005\n",
      "Episode 48\n",
      "Number visited 910\n",
      "Episode 48 exploratrion 0.19360000000000002\n",
      "Episode 48 total reward=0.10\n",
      "Episode 48 reward=802.0\n",
      "Episode 48 avg reward=0.3208\n",
      "Episode 49\n",
      "Number visited 123\n",
      "Episode 49 exploratrion 0.19346666666666668\n",
      "Episode 49 total reward=0.06\n",
      "Episode 49 reward=-525.0\n",
      "Episode 49 avg reward=-0.21\n",
      "Episode 50\n",
      "Number visited 462\n",
      "Episode 50 exploratrion 0.19333333333333336\n",
      "Episode 50 total reward=0.06\n",
      "Episode 50 reward=38.0\n",
      "Episode 50 avg reward=0.0152\n",
      "Episode 51\n",
      "Number visited 418\n",
      "Episode 51 exploratrion 0.1932\n",
      "Episode 51 total reward=0.06\n",
      "Episode 51 reward=142.0\n",
      "Episode 51 avg reward=0.056799999999999996\n",
      "Episode 52\n",
      "Number visited 556\n",
      "Episode 52 exploratrion 0.19306666666666666\n",
      "Episode 52 total reward=0.06\n",
      "Episode 52 reward=280.0\n",
      "Episode 52 avg reward=0.11199999999999999\n",
      "Episode 53\n",
      "Number visited 900\n",
      "Episode 53 exploratrion 0.19293333333333335\n",
      "Episode 53 total reward=0.09\n",
      "Episode 53 reward=880.0\n",
      "Episode 53 avg reward=0.35200000000000004\n",
      "Episode 54\n",
      "Number visited 756\n",
      "Episode 54 exploratrion 0.1928\n",
      "Episode 54 total reward=0.11\n",
      "Episode 54 reward=644.0\n",
      "Episode 54 avg reward=0.2576\n",
      "Episode 55\n",
      "Number visited 454\n",
      "Episode 55 exploratrion 0.19266666666666668\n",
      "Episode 55 total reward=0.10\n",
      "Episode 55 reward=102.0\n",
      "Episode 55 avg reward=0.0408\n",
      "Episode 56\n",
      "Number visited 341\n",
      "Episode 56 exploratrion 0.19253333333333333\n",
      "Episode 56 total reward=0.09\n",
      "Episode 56 reward=-115.0\n",
      "Episode 56 avg reward=-0.046\n",
      "Episode 57\n",
      "Number visited 266\n",
      "Episode 57 exploratrion 0.19240000000000002\n",
      "Episode 57 total reward=0.07\n",
      "Episode 57 reward=-322.0\n",
      "Episode 57 avg reward=-0.1288\n",
      "Episode 58\n",
      "Number visited 410\n",
      "Episode 58 exploratrion 0.19226666666666667\n",
      "Episode 58 total reward=0.07\n",
      "Episode 58 reward=142.0\n",
      "Episode 58 avg reward=0.056799999999999996\n",
      "Episode 59\n",
      "Number visited 546\n",
      "Episode 59 exploratrion 0.19213333333333335\n",
      "Episode 59 total reward=0.07\n",
      "Episode 59 reward=274.0\n",
      "Episode 59 avg reward=0.1096\n",
      "Episode 60\n",
      "Number visited 152\n",
      "Episode 60 exploratrion 0.192\n",
      "Episode 60 total reward=0.04\n",
      "Episode 60 reward=-680.0\n",
      "Episode 60 avg reward=-0.272\n",
      "Episode 61\n",
      "Number visited 958\n",
      "Episode 61 exploratrion 0.19186666666666669\n",
      "Episode 61 total reward=0.07\n",
      "Episode 61 reward=910.0\n",
      "Episode 61 avg reward=0.364\n",
      "Episode 62\n",
      "Number visited 547\n",
      "Episode 62 exploratrion 0.19173333333333334\n",
      "Episode 62 total reward=0.08\n",
      "Episode 62 reward=515.0\n",
      "Episode 62 avg reward=0.20600000000000002\n",
      "Episode 63\n",
      "Number visited 855\n",
      "Episode 63 exploratrion 0.19160000000000002\n",
      "Episode 63 total reward=0.11\n",
      "Episode 63 reward=787.0\n",
      "Episode 63 avg reward=0.3148\n",
      "Episode 64\n",
      "Number visited 746\n",
      "Episode 64 exploratrion 0.19146666666666667\n",
      "Episode 64 total reward=0.12\n",
      "Episode 64 reward=726.0\n",
      "Episode 64 avg reward=0.2904\n",
      "Episode 65\n",
      "Number visited 731\n",
      "Episode 65 exploratrion 0.19133333333333336\n",
      "Episode 65 total reward=0.14\n",
      "Episode 65 reward=647.0\n",
      "Episode 65 avg reward=0.2588\n",
      "Episode 66\n",
      "Number visited 397\n",
      "Episode 66 exploratrion 0.1912\n",
      "Episode 66 total reward=0.12\n",
      "Episode 66 reward=-79.0\n",
      "Episode 66 avg reward=-0.0316\n",
      "Episode 67\n",
      "Number visited 583\n",
      "Episode 67 exploratrion 0.1910666666666667\n",
      "Episode 67 total reward=0.12\n",
      "Episode 67 reward=383.0\n",
      "Episode 67 avg reward=0.1532\n",
      "Episode 68\n",
      "Number visited 904\n",
      "Episode 68 exploratrion 0.19093333333333334\n",
      "Episode 68 total reward=0.15\n",
      "Episode 68 reward=888.0\n",
      "Episode 68 avg reward=0.3552\n",
      "Episode 69\n",
      "Number visited 228\n",
      "Episode 69 exploratrion 0.19080000000000003\n",
      "Episode 69 total reward=0.12\n",
      "Episode 69 reward=-256.0\n",
      "Episode 69 avg reward=-0.1024\n",
      "Episode 70\n",
      "Number visited 477\n",
      "Episode 70 exploratrion 0.19066666666666668\n",
      "Episode 70 total reward=0.12\n",
      "Episode 70 reward=241.0\n",
      "Episode 70 avg reward=0.0964\n",
      "Episode 71\n",
      "Number visited 663\n",
      "Episode 71 exploratrion 0.19053333333333333\n",
      "Episode 71 total reward=0.13\n",
      "Episode 71 reward=567.0\n",
      "Episode 71 avg reward=0.2268\n",
      "Episode 72\n",
      "Number visited 276\n",
      "Episode 72 exploratrion 0.1904\n",
      "Episode 72 total reward=0.11\n",
      "Episode 72 reward=-224.0\n",
      "Episode 72 avg reward=-0.08960000000000001\n",
      "Episode 73\n",
      "Number visited 289\n",
      "Episode 73 exploratrion 0.19026666666666667\n",
      "Episode 73 total reward=0.09\n",
      "Episode 73 reward=-291.0\n",
      "Episode 73 avg reward=-0.1164\n",
      "Episode 74\n",
      "Number visited 655\n",
      "Episode 74 exploratrion 0.19013333333333335\n",
      "Episode 74 total reward=0.10\n",
      "Episode 74 reward=595.0\n",
      "Episode 74 avg reward=0.23800000000000002\n",
      "Episode 75\n",
      "Number visited 414\n",
      "Episode 75 exploratrion 0.19\n",
      "Episode 75 total reward=0.09\n",
      "Episode 75 reward=66.0\n",
      "Episode 75 avg reward=0.0264\n",
      "Episode 76\n",
      "Number visited 629\n",
      "Episode 76 exploratrion 0.18986666666666668\n",
      "Episode 76 total reward=0.10\n",
      "Episode 76 reward=457.0\n",
      "Episode 76 avg reward=0.18280000000000002\n",
      "Episode 77\n",
      "Number visited 816\n",
      "Episode 77 exploratrion 0.18973333333333334\n",
      "Episode 77 total reward=0.12\n",
      "Episode 77 reward=784.0\n",
      "Episode 77 avg reward=0.3136\n",
      "Episode 78\n",
      "Number visited 361\n",
      "Episode 78 exploratrion 0.18960000000000002\n",
      "Episode 78 total reward=0.11\n",
      "Episode 78 reward=-75.0\n",
      "Episode 78 avg reward=-0.03\n",
      "Episode 79\n",
      "Number visited 655\n",
      "Episode 79 exploratrion 0.18946666666666667\n",
      "Episode 79 total reward=0.12\n",
      "Episode 79 reward=631.0\n",
      "Episode 79 avg reward=0.25239999999999996\n",
      "Episode 80\n",
      "Number visited 824\n",
      "Episode 80 exploratrion 0.18933333333333335\n",
      "Episode 80 total reward=0.14\n",
      "Episode 80 reward=756.0\n",
      "Episode 80 avg reward=0.3024\n",
      "Episode 81\n",
      "Number visited 515\n",
      "Episode 81 exploratrion 0.1892\n",
      "Episode 81 total reward=0.14\n",
      "Episode 81 reward=407.0\n",
      "Episode 81 avg reward=0.1628\n",
      "Episode 82\n",
      "Number visited 395\n",
      "Episode 82 exploratrion 0.1890666666666667\n",
      "Episode 82 total reward=0.12\n",
      "Episode 82 reward=-121.0\n",
      "Episode 82 avg reward=-0.0484\n",
      "Episode 83\n",
      "Number visited 863\n",
      "Episode 83 exploratrion 0.18893333333333334\n",
      "Episode 83 total reward=0.14\n",
      "Episode 83 reward=735.0\n",
      "Episode 83 avg reward=0.294\n",
      "Episode 84\n",
      "Number visited 331\n",
      "Episode 84 exploratrion 0.18880000000000002\n",
      "Episode 84 total reward=0.12\n",
      "Episode 84 reward=-193.0\n",
      "Episode 84 avg reward=-0.07719999999999999\n",
      "Episode 85\n",
      "Number visited 397\n",
      "Episode 85 exploratrion 0.18866666666666668\n",
      "Episode 85 total reward=0.11\n",
      "Episode 85 reward=-47.0\n",
      "Episode 85 avg reward=-0.018799999999999997\n",
      "Episode 86\n",
      "Number visited 750\n",
      "Episode 86 exploratrion 0.18853333333333333\n",
      "Episode 86 total reward=0.12\n",
      "Episode 86 reward=718.0\n",
      "Episode 86 avg reward=0.2872\n",
      "Episode 87\n",
      "Number visited 328\n",
      "Episode 87 exploratrion 0.1884\n",
      "Episode 87 total reward=0.11\n",
      "Episode 87 reward=-4.0\n",
      "Episode 87 avg reward=-0.0016\n",
      "Episode 88\n",
      "Number visited 226\n",
      "Episode 88 exploratrion 0.18826666666666667\n",
      "Episode 88 total reward=0.09\n",
      "Episode 88 reward=-302.0\n",
      "Episode 88 avg reward=-0.1208\n",
      "Episode 89\n",
      "Number visited 633\n",
      "Episode 89 exploratrion 0.18813333333333335\n",
      "Episode 89 total reward=0.10\n",
      "Episode 89 reward=553.0\n",
      "Episode 89 avg reward=0.2212\n",
      "Episode 90\n",
      "Number visited 583\n",
      "Episode 90 exploratrion 0.188\n",
      "Episode 90 total reward=0.10\n",
      "Episode 90 reward=343.0\n",
      "Episode 90 avg reward=0.13720000000000002\n",
      "Episode 91\n",
      "Number visited 632\n",
      "Episode 91 exploratrion 0.18786666666666668\n",
      "Episode 91 total reward=0.12\n",
      "Episode 91 reward=616.0\n",
      "Episode 91 avg reward=0.2464\n",
      "Episode 92\n",
      "Number visited 703\n",
      "Episode 92 exploratrion 0.18773333333333334\n",
      "Episode 92 total reward=0.13\n",
      "Episode 92 reward=675.0\n",
      "Episode 92 avg reward=0.27\n",
      "Episode 93\n",
      "Number visited 646\n",
      "Episode 93 exploratrion 0.18760000000000002\n",
      "Episode 93 total reward=0.14\n",
      "Episode 93 reward=518.0\n",
      "Episode 93 avg reward=0.2072\n",
      "Episode 94\n",
      "Number visited 561\n",
      "Episode 94 exploratrion 0.18746666666666667\n",
      "Episode 94 total reward=0.15\n",
      "Episode 94 reward=453.0\n",
      "Episode 94 avg reward=0.1812\n",
      "Episode 95\n",
      "Number visited 516\n",
      "Episode 95 exploratrion 0.18733333333333335\n",
      "Episode 95 total reward=0.14\n",
      "Episode 95 reward=268.0\n",
      "Episode 95 avg reward=0.1072\n",
      "Episode 96\n",
      "Number visited 427\n",
      "Episode 96 exploratrion 0.1872\n",
      "Episode 96 total reward=0.13\n",
      "Episode 96 reward=95.0\n",
      "Episode 96 avg reward=0.038\n",
      "Episode 97\n",
      "Number visited 421\n",
      "Episode 97 exploratrion 0.1870666666666667\n",
      "Episode 97 total reward=0.12\n",
      "Episode 97 reward=165.0\n",
      "Episode 97 avg reward=0.066\n",
      "Episode 98\n",
      "Number visited 1035\n",
      "Episode 98 exploratrion 0.18693333333333334\n",
      "Episode 98 total reward=0.15\n",
      "Episode 98 reward=931.0\n",
      "Episode 98 avg reward=0.3724\n",
      "Episode 99\n",
      "Number visited 430\n",
      "Episode 99 exploratrion 0.18680000000000002\n",
      "Episode 99 total reward=0.14\n",
      "Episode 99 reward=110.0\n",
      "Episode 99 avg reward=0.044000000000000004\n",
      "Episode 100\n",
      "Number visited 608\n",
      "Episode 100 exploratrion 0.18666666666666668\n",
      "Episode 100 total reward=0.15\n",
      "Episode 100 reward=572.0\n",
      "Episode 100 avg reward=0.2288\n",
      "Episode 101\n",
      "Number visited 730\n",
      "Episode 101 exploratrion 0.18653333333333336\n",
      "Episode 101 total reward=0.16\n",
      "Episode 101 reward=650.0\n",
      "Episode 101 avg reward=0.26\n",
      "Episode 102\n",
      "Number visited 608\n",
      "Episode 102 exploratrion 0.1864\n",
      "Episode 102 total reward=0.10\n",
      "Episode 102 reward=-1080.0\n",
      "Episode 102 avg reward=-0.43200000000000005\n",
      "Episode 103\n",
      "Number visited 368\n",
      "Episode 103 exploratrion 0.1862666666666667\n",
      "Episode 103 total reward=-0.03\n",
      "Episode 103 reward=-2956.0\n",
      "Episode 103 avg reward=-1.1824\n",
      "Episode 104\n",
      "Number visited 514\n",
      "Episode 104 exploratrion 0.18613333333333335\n",
      "Episode 104 total reward=-0.14\n",
      "Episode 104 reward=-2810.0\n",
      "Episode 104 avg reward=-1.124\n",
      "Episode 105\n",
      "Number visited 528\n",
      "Episode 105 exploratrion 0.186\n",
      "Episode 105 total reward=-0.24\n",
      "Episode 105 reward=-2928.0\n",
      "Episode 105 avg reward=-1.1712\n",
      "Episode 106\n",
      "Number visited 520\n",
      "Episode 106 exploratrion 0.18586666666666668\n",
      "Episode 106 total reward=-0.34\n",
      "Episode 106 reward=-2952.0\n",
      "Episode 106 avg reward=-1.1808\n",
      "Episode 107\n",
      "Number visited 396\n",
      "Episode 107 exploratrion 0.18573333333333333\n",
      "Episode 107 total reward=-0.42\n",
      "Episode 107 reward=-2984.0\n",
      "Episode 107 avg reward=-1.1936\n",
      "Episode 108\n",
      "Number visited 260\n",
      "Episode 108 exploratrion 0.18560000000000001\n",
      "Episode 108 total reward=-0.51\n",
      "Episode 108 reward=-3340.0\n",
      "Episode 108 avg reward=-1.3359999999999999\n",
      "Episode 109\n",
      "Number visited 440\n",
      "Episode 109 exploratrion 0.18546666666666667\n",
      "Episode 109 total reward=-0.58\n",
      "Episode 109 reward=-3004.0\n",
      "Episode 109 avg reward=-1.2016\n",
      "Episode 110\n",
      "Number visited 512\n",
      "Episode 110 exploratrion 0.18533333333333335\n",
      "Episode 110 total reward=-0.64\n",
      "Episode 110 reward=-2920.0\n",
      "Episode 110 avg reward=-1.168\n",
      "Episode 111\n",
      "Number visited 544\n",
      "Episode 111 exploratrion 0.1852\n",
      "Episode 111 total reward=-0.69\n",
      "Episode 111 reward=-2768.0\n",
      "Episode 111 avg reward=-1.1072\n",
      "Episode 112\n",
      "Number visited 312\n",
      "Episode 112 exploratrion 0.18506666666666668\n",
      "Episode 112 total reward=-0.75\n",
      "Episode 112 reward=-3212.0\n",
      "Episode 112 avg reward=-1.2848\n",
      "Episode 113\n",
      "Number visited 280\n",
      "Episode 113 exploratrion 0.18493333333333334\n",
      "Episode 113 total reward=-0.80\n",
      "Episode 113 reward=-3292.0\n",
      "Episode 113 avg reward=-1.3168\n",
      "Episode 114\n",
      "Number visited 215\n",
      "Episode 114 exploratrion 0.18480000000000002\n",
      "Episode 114 total reward=-0.85\n",
      "Episode 114 reward=-3277.0\n",
      "Episode 114 avg reward=-1.3108000000000002\n",
      "Episode 115\n",
      "Number visited 336\n",
      "Episode 115 exploratrion 0.18466666666666667\n",
      "Episode 115 total reward=-0.89\n",
      "Episode 115 reward=-3004.0\n",
      "Episode 115 avg reward=-1.2016\n",
      "Episode 116\n",
      "Number visited 348\n",
      "Episode 116 exploratrion 0.18453333333333335\n",
      "Episode 116 total reward=-0.92\n",
      "Episode 116 reward=-3024.0\n",
      "Episode 116 avg reward=-1.2096\n",
      "Episode 117\n",
      "Number visited 470\n",
      "Episode 117 exploratrion 0.1844\n",
      "Episode 117 total reward=-0.95\n",
      "Episode 117 reward=-2998.0\n",
      "Episode 117 avg reward=-1.1992\n",
      "Episode 118\n",
      "Number visited 520\n",
      "Episode 118 exploratrion 0.1842666666666667\n",
      "Episode 118 total reward=-0.97\n",
      "Episode 118 reward=-2940.0\n",
      "Episode 118 avg reward=-1.176\n",
      "Episode 119\n",
      "Number visited 380\n",
      "Episode 119 exploratrion 0.18413333333333334\n",
      "Episode 119 total reward=-0.99\n",
      "Episode 119 reward=-2908.0\n",
      "Episode 119 avg reward=-1.1632\n",
      "Episode 120\n",
      "Number visited 384\n",
      "Episode 120 exploratrion 0.184\n",
      "Episode 120 total reward=-1.01\n",
      "Episode 120 reward=-3028.0\n",
      "Episode 120 avg reward=-1.2112\n",
      "Episode 121\n",
      "Number visited 440\n",
      "Episode 121 exploratrion 0.18386666666666668\n",
      "Episode 121 total reward=-1.03\n",
      "Episode 121 reward=-2956.0\n",
      "Episode 121 avg reward=-1.1824\n",
      "Episode 122\n",
      "Number visited 380\n",
      "Episode 122 exploratrion 0.18373333333333336\n",
      "Episode 122 total reward=-1.05\n",
      "Episode 122 reward=-3044.0\n",
      "Episode 122 avg reward=-1.2176\n",
      "Episode 123\n",
      "Number visited 415\n",
      "Episode 123 exploratrion 0.1836\n",
      "Episode 123 total reward=-1.07\n",
      "Episode 123 reward=-3101.0\n",
      "Episode 123 avg reward=-1.2404000000000002\n",
      "Episode 124\n",
      "Number visited 490\n",
      "Episode 124 exploratrion 0.18346666666666667\n",
      "Episode 124 total reward=-1.08\n",
      "Episode 124 reward=-2870.0\n",
      "Episode 124 avg reward=-1.148\n",
      "Episode 125\n",
      "Number visited 384\n",
      "Episode 125 exploratrion 0.18333333333333335\n",
      "Episode 125 total reward=-1.08\n",
      "Episode 125 reward=-2916.0\n",
      "Episode 125 avg reward=-1.1664\n",
      "Episode 126\n",
      "Number visited 500\n",
      "Episode 126 exploratrion 0.1832\n",
      "Episode 126 total reward=-1.09\n",
      "Episode 126 reward=-2844.0\n",
      "Episode 126 avg reward=-1.1376\n",
      "Episode 127\n",
      "Number visited 384\n",
      "Episode 127 exploratrion 0.18306666666666668\n",
      "Episode 127 total reward=-1.10\n",
      "Episode 127 reward=-2960.0\n",
      "Episode 127 avg reward=-1.1840000000000002\n",
      "Episode 128\n",
      "Number visited 440\n",
      "Episode 128 exploratrion 0.18293333333333334\n",
      "Episode 128 total reward=-1.11\n",
      "Episode 128 reward=-3064.0\n",
      "Episode 128 avg reward=-1.2256\n",
      "Episode 129\n",
      "Number visited 415\n",
      "Episode 129 exploratrion 0.18280000000000002\n",
      "Episode 129 total reward=-1.12\n",
      "Episode 129 reward=-3009.0\n",
      "Episode 129 avg reward=-1.2036\n",
      "Episode 130\n",
      "Number visited 484\n",
      "Episode 130 exploratrion 0.18266666666666667\n",
      "Episode 130 total reward=-1.12\n",
      "Episode 130 reward=-2864.0\n",
      "Episode 130 avg reward=-1.1456\n",
      "Episode 131\n",
      "Number visited 338\n",
      "Episode 131 exploratrion 0.18253333333333335\n",
      "Episode 131 total reward=-1.14\n",
      "Episode 131 reward=-3106.0\n",
      "Episode 131 avg reward=-1.2424\n",
      "Episode 132\n",
      "Number visited 520\n",
      "Episode 132 exploratrion 0.1824\n",
      "Episode 132 total reward=-1.13\n",
      "Episode 132 reward=-2824.0\n",
      "Episode 132 avg reward=-1.1296\n",
      "Episode 133\n",
      "Number visited 308\n",
      "Episode 133 exploratrion 0.1822666666666667\n",
      "Episode 133 total reward=-1.15\n",
      "Episode 133 reward=-3212.0\n",
      "Episode 133 avg reward=-1.2848\n",
      "Episode 134\n",
      "Number visited 384\n",
      "Episode 134 exploratrion 0.18213333333333334\n",
      "Episode 134 total reward=-1.16\n",
      "Episode 134 reward=-3032.0\n",
      "Episode 134 avg reward=-1.2128\n",
      "Episode 135\n",
      "Number visited 384\n",
      "Episode 135 exploratrion 0.18200000000000002\n",
      "Episode 135 total reward=-1.17\n",
      "Episode 135 reward=-3136.0\n",
      "Episode 135 avg reward=-1.2544\n",
      "Episode 136\n",
      "Number visited 356\n",
      "Episode 136 exploratrion 0.18186666666666668\n",
      "Episode 136 total reward=-1.17\n",
      "Episode 136 reward=-3116.0\n",
      "Episode 136 avg reward=-1.2464\n",
      "Episode 137\n",
      "Number visited 420\n",
      "Episode 137 exploratrion 0.18173333333333336\n",
      "Episode 137 total reward=-1.18\n",
      "Episode 137 reward=-3044.0\n",
      "Episode 137 avg reward=-1.2176\n",
      "Episode 138\n",
      "Number visited 380\n",
      "Episode 138 exploratrion 0.1816\n",
      "Episode 138 total reward=-1.18\n",
      "Episode 138 reward=-3076.0\n",
      "Episode 138 avg reward=-1.2304000000000002\n",
      "Episode 139\n",
      "Number visited 384\n",
      "Episode 139 exploratrion 0.18146666666666667\n",
      "Episode 139 total reward=-1.19\n",
      "Episode 139 reward=-3200.0\n",
      "Episode 139 avg reward=-1.28\n",
      "Episode 140\n",
      "Number visited 384\n",
      "Episode 140 exploratrion 0.18133333333333335\n",
      "Episode 140 total reward=-1.20\n",
      "Episode 140 reward=-3080.0\n",
      "Episode 140 avg reward=-1.232\n",
      "Episode 141\n",
      "Number visited 384\n",
      "Episode 141 exploratrion 0.1812\n",
      "Episode 141 total reward=-1.21\n",
      "Episode 141 reward=-3212.0\n",
      "Episode 141 avg reward=-1.2848\n",
      "Episode 142\n",
      "Number visited 536\n",
      "Episode 142 exploratrion 0.18106666666666668\n",
      "Episode 142 total reward=-1.20\n",
      "Episode 142 reward=-2932.0\n",
      "Episode 142 avg reward=-1.1728\n",
      "Episode 143\n",
      "Number visited 380\n",
      "Episode 143 exploratrion 0.18093333333333333\n",
      "Episode 143 total reward=-1.21\n",
      "Episode 143 reward=-3076.0\n",
      "Episode 143 avg reward=-1.2304000000000002\n",
      "Episode 144\n",
      "Number visited 384\n",
      "Episode 144 exploratrion 0.18080000000000002\n",
      "Episode 144 total reward=-1.21\n",
      "Episode 144 reward=-3068.0\n",
      "Episode 144 avg reward=-1.2272\n",
      "Episode 145\n",
      "Number visited 384\n",
      "Episode 145 exploratrion 0.18066666666666667\n",
      "Episode 145 total reward=-1.21\n",
      "Episode 145 reward=-3084.0\n",
      "Episode 145 avg reward=-1.2336\n",
      "Episode 146\n",
      "Number visited 500\n",
      "Episode 146 exploratrion 0.18053333333333335\n",
      "Episode 146 total reward=-1.20\n",
      "Episode 146 reward=-2896.0\n",
      "Episode 146 avg reward=-1.1584\n",
      "Episode 147\n",
      "Number visited 466\n",
      "Episode 147 exploratrion 0.1804\n",
      "Episode 147 total reward=-1.20\n",
      "Episode 147 reward=-2954.0\n",
      "Episode 147 avg reward=-1.1816\n",
      "Episode 148\n",
      "Number visited 376\n",
      "Episode 148 exploratrion 0.1802666666666667\n",
      "Episode 148 total reward=-1.21\n",
      "Episode 148 reward=-3084.0\n",
      "Episode 148 avg reward=-1.2336\n",
      "Episode 149\n",
      "Number visited 424\n",
      "Episode 149 exploratrion 0.18013333333333334\n",
      "Episode 149 total reward=-1.21\n",
      "Episode 149 reward=-3032.0\n",
      "Episode 149 avg reward=-1.2128\n",
      "Episode 150\n",
      "Number visited 420\n",
      "Episode 150 exploratrion 0.18\n",
      "Episode 150 total reward=-1.21\n",
      "Episode 150 reward=-3040.0\n",
      "Episode 150 avg reward=-1.216\n",
      "Episode 151\n",
      "Number visited 493\n",
      "Episode 151 exploratrion 0.17986666666666667\n",
      "Episode 151 total reward=-1.21\n",
      "Episode 151 reward=-2979.0\n",
      "Episode 151 avg reward=-1.1916\n",
      "Episode 152\n",
      "Number visited 384\n",
      "Episode 152 exploratrion 0.17973333333333336\n",
      "Episode 152 total reward=-1.21\n",
      "Episode 152 reward=-3128.0\n",
      "Episode 152 avg reward=-1.2512\n",
      "Episode 153\n",
      "Number visited 536\n",
      "Episode 153 exploratrion 0.1796\n",
      "Episode 153 total reward=-1.21\n",
      "Episode 153 reward=-2928.0\n",
      "Episode 153 avg reward=-1.1712\n",
      "Episode 154\n",
      "Number visited 384\n",
      "Episode 154 exploratrion 0.17946666666666666\n",
      "Episode 154 total reward=-1.22\n",
      "Episode 154 reward=-3252.0\n",
      "Episode 154 avg reward=-1.3008000000000002\n",
      "Episode 155\n",
      "Number visited 528\n",
      "Episode 155 exploratrion 0.17933333333333334\n",
      "Episode 155 total reward=-1.21\n",
      "Episode 155 reward=-2928.0\n",
      "Episode 155 avg reward=-1.1712\n",
      "Episode 156\n",
      "Number visited 524\n",
      "Episode 156 exploratrion 0.17920000000000003\n",
      "Episode 156 total reward=-1.21\n",
      "Episode 156 reward=-2932.0\n",
      "Episode 156 avg reward=-1.1728\n",
      "Episode 157\n",
      "Number visited 516\n",
      "Episode 157 exploratrion 0.17906666666666668\n",
      "Episode 157 total reward=-1.20\n",
      "Episode 157 reward=-2936.0\n",
      "Episode 157 avg reward=-1.1743999999999999\n",
      "Episode 158\n",
      "Number visited 384\n",
      "Episode 158 exploratrion 0.17893333333333333\n",
      "Episode 158 total reward=-1.21\n",
      "Episode 158 reward=-3068.0\n",
      "Episode 158 avg reward=-1.2272\n",
      "Episode 159\n",
      "Number visited 520\n",
      "Episode 159 exploratrion 0.17880000000000001\n",
      "Episode 159 total reward=-1.20\n",
      "Episode 159 reward=-2956.0\n",
      "Episode 159 avg reward=-1.1824\n",
      "Episode 160\n",
      "Number visited 308\n",
      "Episode 160 exploratrion 0.17866666666666667\n",
      "Episode 160 total reward=-1.21\n",
      "Episode 160 reward=-3236.0\n",
      "Episode 160 avg reward=-1.2944\n",
      "Episode 161\n",
      "Number visited 520\n",
      "Episode 161 exploratrion 0.17853333333333335\n",
      "Episode 161 total reward=-1.21\n",
      "Episode 161 reward=-2948.0\n",
      "Episode 161 avg reward=-1.1792\n",
      "Episode 162\n",
      "Number visited 384\n",
      "Episode 162 exploratrion 0.1784\n",
      "Episode 162 total reward=-1.22\n",
      "Episode 162 reward=-3248.0\n",
      "Episode 162 avg reward=-1.2992\n",
      "Episode 163\n",
      "Number visited 384\n",
      "Episode 163 exploratrion 0.17826666666666668\n",
      "Episode 163 total reward=-1.23\n",
      "Episode 163 reward=-3228.0\n",
      "Episode 163 avg reward=-1.2912000000000001\n",
      "Episode 164\n",
      "Number visited 338\n",
      "Episode 164 exploratrion 0.17813333333333334\n",
      "Episode 164 total reward=-1.23\n",
      "Episode 164 reward=-3106.0\n",
      "Episode 164 avg reward=-1.2424\n",
      "Episode 165\n",
      "Number visited 384\n",
      "Episode 165 exploratrion 0.17800000000000002\n",
      "Episode 165 total reward=-1.23\n",
      "Episode 165 reward=-3196.0\n",
      "Episode 165 avg reward=-1.2784\n",
      "Episode 166\n",
      "Number visited 432\n",
      "Episode 166 exploratrion 0.17786666666666667\n",
      "Episode 166 total reward=-1.23\n",
      "Episode 166 reward=-3076.0\n",
      "Episode 166 avg reward=-1.2304000000000002\n",
      "Episode 167\n",
      "Number visited 292\n",
      "Episode 167 exploratrion 0.17773333333333335\n",
      "Episode 167 total reward=-1.24\n",
      "Episode 167 reward=-3224.0\n",
      "Episode 167 avg reward=-1.2896\n",
      "Episode 168\n",
      "Number visited 384\n",
      "Episode 168 exploratrion 0.1776\n",
      "Episode 168 total reward=-1.24\n",
      "Episode 168 reward=-3208.0\n",
      "Episode 168 avg reward=-1.2832\n",
      "Episode 169\n",
      "Number visited 292\n",
      "Episode 169 exploratrion 0.17746666666666666\n",
      "Episode 169 total reward=-1.25\n",
      "Episode 169 reward=-3344.0\n",
      "Episode 169 avg reward=-1.3376\n",
      "Episode 170\n",
      "Number visited 338\n",
      "Episode 170 exploratrion 0.17733333333333334\n",
      "Episode 170 total reward=-1.25\n",
      "Episode 170 reward=-3110.0\n",
      "Episode 170 avg reward=-1.244\n",
      "Episode 171\n",
      "Number visited 384\n",
      "Episode 171 exploratrion 0.17720000000000002\n",
      "Episode 171 total reward=-1.25\n",
      "Episode 171 reward=-3084.0\n",
      "Episode 171 avg reward=-1.2336\n",
      "Episode 172\n",
      "Number visited 384\n",
      "Episode 172 exploratrion 0.17706666666666668\n",
      "Episode 172 total reward=-1.25\n",
      "Episode 172 reward=-3108.0\n",
      "Episode 172 avg reward=-1.2431999999999999\n",
      "Episode 173\n",
      "Number visited 384\n",
      "Episode 173 exploratrion 0.17693333333333333\n",
      "Episode 173 total reward=-1.25\n",
      "Episode 173 reward=-3108.0\n",
      "Episode 173 avg reward=-1.2431999999999999\n",
      "Episode 174\n",
      "Number visited 384\n",
      "Episode 174 exploratrion 0.1768\n",
      "Episode 174 total reward=-1.22\n",
      "Episode 174 reward=-2456.0\n",
      "Episode 174 avg reward=-0.9823999999999999\n",
      "Episode 175\n",
      "Number visited 384\n",
      "Episode 175 exploratrion 0.17666666666666667\n",
      "Episode 175 total reward=-1.19\n",
      "Episode 175 reward=-2356.0\n",
      "Episode 175 avg reward=-0.9423999999999999\n",
      "Episode 176\n",
      "Number visited 384\n",
      "Episode 176 exploratrion 0.17653333333333335\n",
      "Episode 176 total reward=-1.20\n",
      "Episode 176 reward=-3080.0\n",
      "Episode 176 avg reward=-1.232\n",
      "Episode 177\n",
      "Number visited 384\n",
      "Episode 177 exploratrion 0.1764\n",
      "Episode 177 total reward=-1.18\n",
      "Episode 177 reward=-2456.0\n",
      "Episode 177 avg reward=-0.9823999999999999\n",
      "Episode 178\n",
      "Number visited 384\n",
      "Episode 178 exploratrion 0.17626666666666668\n",
      "Episode 178 total reward=-1.18\n",
      "Episode 178 reward=-3088.0\n",
      "Episode 178 avg reward=-1.2351999999999999\n",
      "Episode 179\n",
      "Number visited 412\n",
      "Episode 179 exploratrion 0.17613333333333334\n",
      "Episode 179 total reward=-1.19\n",
      "Episode 179 reward=-3040.0\n",
      "Episode 179 avg reward=-1.216\n",
      "Episode 180\n",
      "Number visited 384\n",
      "Episode 180 exploratrion 0.17600000000000002\n",
      "Episode 180 total reward=-1.19\n",
      "Episode 180 reward=-3100.0\n",
      "Episode 180 avg reward=-1.24\n",
      "Episode 181\n",
      "Number visited 384\n",
      "Episode 181 exploratrion 0.17586666666666667\n",
      "Episode 181 total reward=-1.19\n",
      "Episode 181 reward=-3056.0\n",
      "Episode 181 avg reward=-1.2224\n",
      "Episode 182\n",
      "Number visited 384\n",
      "Episode 182 exploratrion 0.17573333333333335\n",
      "Episode 182 total reward=-1.20\n",
      "Episode 182 reward=-3112.0\n",
      "Episode 182 avg reward=-1.2448000000000001\n",
      "Episode 183\n",
      "Number visited 384\n",
      "Episode 183 exploratrion 0.1756\n",
      "Episode 183 total reward=-1.19\n",
      "Episode 183 reward=-2824.0\n",
      "Episode 183 avg reward=-1.1296\n",
      "Episode 184\n",
      "Number visited 420\n",
      "Episode 184 exploratrion 0.1754666666666667\n",
      "Episode 184 total reward=-1.20\n",
      "Episode 184 reward=-3100.0\n",
      "Episode 184 avg reward=-1.24\n",
      "Episode 185\n",
      "Number visited 384\n",
      "Episode 185 exploratrion 0.17533333333333334\n",
      "Episode 185 total reward=-1.18\n",
      "Episode 185 reward=-2456.0\n",
      "Episode 185 avg reward=-0.9823999999999999\n",
      "Episode 186\n",
      "Number visited 384\n",
      "Episode 186 exploratrion 0.17520000000000002\n",
      "Episode 186 total reward=-1.19\n",
      "Episode 186 reward=-3188.0\n",
      "Episode 186 avg reward=-1.2752\n",
      "Episode 187\n",
      "Number visited 384\n",
      "Episode 187 exploratrion 0.17506666666666668\n",
      "Episode 187 total reward=-1.19\n",
      "Episode 187 reward=-3116.0\n",
      "Episode 187 avg reward=-1.2464\n",
      "Episode 188\n",
      "Number visited 384\n",
      "Episode 188 exploratrion 0.17493333333333333\n",
      "Episode 188 total reward=-1.20\n",
      "Episode 188 reward=-3108.0\n",
      "Episode 188 avg reward=-1.2431999999999999\n",
      "Episode 189\n",
      "Number visited 384\n",
      "Episode 189 exploratrion 0.1748\n",
      "Episode 189 total reward=-1.20\n",
      "Episode 189 reward=-3144.0\n",
      "Episode 189 avg reward=-1.2576\n",
      "Episode 190\n",
      "Number visited 384\n",
      "Episode 190 exploratrion 0.17466666666666666\n",
      "Episode 190 total reward=-1.21\n",
      "Episode 190 reward=-3196.0\n",
      "Episode 190 avg reward=-1.2784\n",
      "Episode 191\n",
      "Number visited 384\n",
      "Episode 191 exploratrion 0.17453333333333335\n",
      "Episode 191 total reward=-1.21\n",
      "Episode 191 reward=-3072.0\n",
      "Episode 191 avg reward=-1.2288\n",
      "Episode 192\n",
      "Number visited 384\n",
      "Episode 192 exploratrion 0.1744\n",
      "Episode 192 total reward=-1.22\n",
      "Episode 192 reward=-3104.0\n",
      "Episode 192 avg reward=-1.2416\n",
      "Episode 193\n",
      "Number visited 384\n",
      "Episode 193 exploratrion 0.17426666666666668\n",
      "Episode 193 total reward=-1.22\n",
      "Episode 193 reward=-3152.0\n",
      "Episode 193 avg reward=-1.2608\n",
      "Episode 194\n",
      "Number visited 384\n",
      "Episode 194 exploratrion 0.17413333333333333\n",
      "Episode 194 total reward=-1.22\n",
      "Episode 194 reward=-3148.0\n",
      "Episode 194 avg reward=-1.2592\n",
      "Episode 195\n",
      "Number visited 384\n",
      "Episode 195 exploratrion 0.17400000000000002\n",
      "Episode 195 total reward=-1.23\n",
      "Episode 195 reward=-3220.0\n",
      "Episode 195 avg reward=-1.288\n",
      "Episode 196\n",
      "Number visited 384\n",
      "Episode 196 exploratrion 0.17386666666666667\n",
      "Episode 196 total reward=-1.23\n",
      "Episode 196 reward=-3160.0\n",
      "Episode 196 avg reward=-1.264\n",
      "Episode 197\n",
      "Number visited 384\n",
      "Episode 197 exploratrion 0.17373333333333335\n",
      "Episode 197 total reward=-1.24\n",
      "Episode 197 reward=-3188.0\n",
      "Episode 197 avg reward=-1.2752\n",
      "Episode 198\n",
      "Number visited 338\n",
      "Episode 198 exploratrion 0.1736\n",
      "Episode 198 total reward=-1.25\n",
      "Episode 198 reward=-3302.0\n",
      "Episode 198 avg reward=-1.3208000000000002\n",
      "Episode 199\n",
      "Number visited 384\n",
      "Episode 199 exploratrion 0.17346666666666669\n",
      "Episode 199 total reward=-1.25\n",
      "Episode 199 reward=-3112.0\n",
      "Episode 199 avg reward=-1.2448000000000001\n",
      "Episode 200\n",
      "Number visited 384\n",
      "Episode 200 exploratrion 0.17333333333333334\n",
      "Episode 200 total reward=-1.25\n",
      "Episode 200 reward=-3124.0\n",
      "Episode 200 avg reward=-1.2496\n",
      "Episode 201\n",
      "Number visited 384\n",
      "Episode 201 exploratrion 0.17320000000000002\n",
      "Episode 201 total reward=-1.25\n",
      "Episode 201 reward=-3116.0\n",
      "Episode 201 avg reward=-1.2464\n",
      "Episode 202\n",
      "Number visited 384\n",
      "Episode 202 exploratrion 0.17306666666666667\n",
      "Episode 202 total reward=-1.25\n",
      "Episode 202 reward=-3196.0\n",
      "Episode 202 avg reward=-1.2784\n",
      "Episode 203\n",
      "Number visited 384\n",
      "Episode 203 exploratrion 0.17293333333333333\n",
      "Episode 203 total reward=-1.25\n",
      "Episode 203 reward=-3116.0\n",
      "Episode 203 avg reward=-1.2464\n",
      "Episode 204\n",
      "Number visited 338\n",
      "Episode 204 exploratrion 0.1728\n",
      "Episode 204 total reward=-1.25\n",
      "Episode 204 reward=-3110.0\n",
      "Episode 204 avg reward=-1.244\n",
      "Episode 205\n",
      "Number visited 384\n",
      "Episode 205 exploratrion 0.1726666666666667\n",
      "Episode 205 total reward=-1.25\n",
      "Episode 205 reward=-3164.0\n",
      "Episode 205 avg reward=-1.2656\n",
      "Episode 206\n",
      "Number visited 384\n",
      "Episode 206 exploratrion 0.17253333333333334\n",
      "Episode 206 total reward=-1.25\n",
      "Episode 206 reward=-3104.0\n",
      "Episode 206 avg reward=-1.2416\n",
      "Episode 207\n",
      "Number visited 384\n",
      "Episode 207 exploratrion 0.1724\n",
      "Episode 207 total reward=-1.25\n",
      "Episode 207 reward=-3100.0\n",
      "Episode 207 avg reward=-1.24\n",
      "Episode 208\n",
      "Number visited 384\n",
      "Episode 208 exploratrion 0.17226666666666668\n",
      "Episode 208 total reward=-1.25\n",
      "Episode 208 reward=-3176.0\n",
      "Episode 208 avg reward=-1.2704\n",
      "Episode 209\n",
      "Number visited 384\n",
      "Episode 209 exploratrion 0.17213333333333333\n",
      "Episode 209 total reward=-1.25\n",
      "Episode 209 reward=-3124.0\n",
      "Episode 209 avg reward=-1.2496\n",
      "Episode 210\n",
      "Number visited 384\n",
      "Episode 210 exploratrion 0.17200000000000001\n",
      "Episode 210 total reward=-1.25\n",
      "Episode 210 reward=-3140.0\n",
      "Episode 210 avg reward=-1.256\n",
      "Episode 211\n",
      "Number visited 384\n",
      "Episode 211 exploratrion 0.17186666666666667\n",
      "Episode 211 total reward=-1.25\n",
      "Episode 211 reward=-3184.0\n",
      "Episode 211 avg reward=-1.2736\n",
      "Episode 212\n",
      "Number visited 384\n",
      "Episode 212 exploratrion 0.17173333333333335\n",
      "Episode 212 total reward=-1.26\n",
      "Episode 212 reward=-3188.0\n",
      "Episode 212 avg reward=-1.2752\n",
      "Episode 213\n",
      "Number visited 384\n",
      "Episode 213 exploratrion 0.1716\n",
      "Episode 213 total reward=-1.26\n",
      "Episode 213 reward=-3228.0\n",
      "Episode 213 avg reward=-1.2912000000000001\n",
      "Episode 214\n",
      "Number visited 338\n",
      "Episode 214 exploratrion 0.17146666666666668\n",
      "Episode 214 total reward=-1.27\n",
      "Episode 214 reward=-3302.0\n",
      "Episode 214 avg reward=-1.3208000000000002\n",
      "Episode 215\n",
      "Number visited 384\n",
      "Episode 215 exploratrion 0.17133333333333334\n",
      "Episode 215 total reward=-1.26\n",
      "Episode 215 reward=-3100.0\n",
      "Episode 215 avg reward=-1.24\n",
      "Episode 216\n",
      "Number visited 384\n",
      "Episode 216 exploratrion 0.17120000000000002\n",
      "Episode 216 total reward=-1.26\n",
      "Episode 216 reward=-3096.0\n",
      "Episode 216 avg reward=-1.2384\n",
      "Episode 217\n",
      "Number visited 384\n",
      "Episode 217 exploratrion 0.17106666666666667\n",
      "Episode 217 total reward=-1.26\n",
      "Episode 217 reward=-3144.0\n",
      "Episode 217 avg reward=-1.2576\n",
      "Episode 218\n",
      "Number visited 384\n",
      "Episode 218 exploratrion 0.17093333333333333\n",
      "Episode 218 total reward=-1.26\n",
      "Episode 218 reward=-3096.0\n",
      "Episode 218 avg reward=-1.2384\n",
      "Episode 219\n",
      "Number visited 384\n",
      "Episode 219 exploratrion 0.1708\n",
      "Episode 219 total reward=-1.26\n",
      "Episode 219 reward=-3076.0\n",
      "Episode 219 avg reward=-1.2304000000000002\n",
      "Episode 220\n",
      "Number visited 384\n",
      "Episode 220 exploratrion 0.1706666666666667\n",
      "Episode 220 total reward=-1.26\n",
      "Episode 220 reward=-3140.0\n",
      "Episode 220 avg reward=-1.256\n",
      "Episode 221\n",
      "Number visited 384\n",
      "Episode 221 exploratrion 0.17053333333333334\n",
      "Episode 221 total reward=-1.26\n",
      "Episode 221 reward=-3228.0\n",
      "Episode 221 avg reward=-1.2912000000000001\n",
      "Episode 222\n",
      "Number visited 292\n",
      "Episode 222 exploratrion 0.1704\n",
      "Episode 222 total reward=-1.26\n",
      "Episode 222 reward=-3148.0\n",
      "Episode 222 avg reward=-1.2592\n",
      "Episode 223\n",
      "Number visited 384\n",
      "Episode 223 exploratrion 0.17026666666666668\n",
      "Episode 223 total reward=-1.26\n",
      "Episode 223 reward=-3244.0\n",
      "Episode 223 avg reward=-1.2975999999999999\n",
      "Episode 224\n",
      "Number visited 384\n",
      "Episode 224 exploratrion 0.17013333333333333\n",
      "Episode 224 total reward=-1.27\n",
      "Episode 224 reward=-3220.0\n",
      "Episode 224 avg reward=-1.288\n",
      "Episode 225\n",
      "Number visited 292\n",
      "Episode 225 exploratrion 0.17\n",
      "Episode 225 total reward=-1.27\n",
      "Episode 225 reward=-3248.0\n",
      "Episode 225 avg reward=-1.2992\n",
      "Episode 226\n",
      "Number visited 384\n",
      "Episode 226 exploratrion 0.16986666666666667\n",
      "Episode 226 total reward=-1.27\n",
      "Episode 226 reward=-3236.0\n",
      "Episode 226 avg reward=-1.2944\n",
      "Episode 227\n",
      "Number visited 384\n",
      "Episode 227 exploratrion 0.16973333333333335\n",
      "Episode 227 total reward=-1.27\n",
      "Episode 227 reward=-3120.0\n",
      "Episode 227 avg reward=-1.248\n",
      "Episode 228\n",
      "Number visited 384\n",
      "Episode 228 exploratrion 0.1696\n",
      "Episode 228 total reward=-1.27\n",
      "Episode 228 reward=-3152.0\n",
      "Episode 228 avg reward=-1.2608\n",
      "Episode 229\n",
      "Number visited 338\n",
      "Episode 229 exploratrion 0.16946666666666668\n",
      "Episode 229 total reward=-1.27\n",
      "Episode 229 reward=-3302.0\n",
      "Episode 229 avg reward=-1.3208000000000002\n",
      "Episode 230\n",
      "Number visited 384\n",
      "Episode 230 exploratrion 0.16933333333333334\n",
      "Episode 230 total reward=-1.27\n",
      "Episode 230 reward=-3148.0\n",
      "Episode 230 avg reward=-1.2592\n",
      "Episode 231\n",
      "Number visited 384\n",
      "Episode 231 exploratrion 0.16920000000000002\n",
      "Episode 231 total reward=-1.27\n",
      "Episode 231 reward=-3124.0\n",
      "Episode 231 avg reward=-1.2496\n",
      "Episode 232\n",
      "Number visited 384\n",
      "Episode 232 exploratrion 0.16906666666666667\n",
      "Episode 232 total reward=-1.27\n",
      "Episode 232 reward=-3184.0\n",
      "Episode 232 avg reward=-1.2736\n",
      "Episode 233\n",
      "Number visited 384\n",
      "Episode 233 exploratrion 0.16893333333333335\n",
      "Episode 233 total reward=-1.27\n",
      "Episode 233 reward=-3256.0\n",
      "Episode 233 avg reward=-1.3024\n",
      "Episode 234\n",
      "Number visited 338\n",
      "Episode 234 exploratrion 0.1688\n",
      "Episode 234 total reward=-1.27\n",
      "Episode 234 reward=-3110.0\n",
      "Episode 234 avg reward=-1.244\n",
      "Episode 235\n",
      "Number visited 384\n",
      "Episode 235 exploratrion 0.1686666666666667\n",
      "Episode 235 total reward=-1.27\n",
      "Episode 235 reward=-3240.0\n",
      "Episode 235 avg reward=-1.296\n",
      "Episode 236\n",
      "Number visited 384\n",
      "Episode 236 exploratrion 0.16853333333333334\n",
      "Episode 236 total reward=-1.27\n",
      "Episode 236 reward=-3144.0\n",
      "Episode 236 avg reward=-1.2576\n",
      "Episode 237\n",
      "Number visited 384\n",
      "Episode 237 exploratrion 0.1684\n",
      "Episode 237 total reward=-1.27\n",
      "Episode 237 reward=-3084.0\n",
      "Episode 237 avg reward=-1.2336\n",
      "Episode 238\n",
      "Number visited 384\n",
      "Episode 238 exploratrion 0.16826666666666668\n",
      "Episode 238 total reward=-1.27\n",
      "Episode 238 reward=-3104.0\n",
      "Episode 238 avg reward=-1.2416\n",
      "Episode 239\n",
      "Number visited 384\n",
      "Episode 239 exploratrion 0.16813333333333336\n",
      "Episode 239 total reward=-1.26\n",
      "Episode 239 reward=-3104.0\n",
      "Episode 239 avg reward=-1.2416\n",
      "Episode 240\n",
      "Number visited 384\n",
      "Episode 240 exploratrion 0.168\n",
      "Episode 240 total reward=-1.26\n",
      "Episode 240 reward=-3108.0\n",
      "Episode 240 avg reward=-1.2431999999999999\n",
      "Episode 241\n",
      "Number visited 384\n",
      "Episode 241 exploratrion 0.16786666666666666\n",
      "Episode 241 total reward=-1.26\n",
      "Episode 241 reward=-3160.0\n",
      "Episode 241 avg reward=-1.264\n",
      "Episode 242\n",
      "Number visited 384\n",
      "Episode 242 exploratrion 0.16773333333333335\n",
      "Episode 242 total reward=-1.26\n",
      "Episode 242 reward=-3108.0\n",
      "Episode 242 avg reward=-1.2431999999999999\n",
      "Episode 243\n",
      "Number visited 292\n",
      "Episode 243 exploratrion 0.1676\n",
      "Episode 243 total reward=-1.26\n",
      "Episode 243 reward=-3148.0\n",
      "Episode 243 avg reward=-1.2592\n",
      "Episode 244\n",
      "Number visited 384\n",
      "Episode 244 exploratrion 0.16746666666666668\n",
      "Episode 244 total reward=-1.26\n",
      "Episode 244 reward=-3188.0\n",
      "Episode 244 avg reward=-1.2752\n",
      "Episode 245\n",
      "Number visited 384\n",
      "Episode 245 exploratrion 0.16733333333333333\n",
      "Episode 245 total reward=-1.26\n",
      "Episode 245 reward=-3148.0\n",
      "Episode 245 avg reward=-1.2592\n",
      "Episode 246\n",
      "Number visited 384\n",
      "Episode 246 exploratrion 0.16720000000000002\n",
      "Episode 246 total reward=-1.26\n",
      "Episode 246 reward=-3084.0\n",
      "Episode 246 avg reward=-1.2336\n",
      "Episode 247\n",
      "Number visited 292\n",
      "Episode 247 exploratrion 0.16706666666666667\n",
      "Episode 247 total reward=-1.26\n",
      "Episode 247 reward=-3148.0\n",
      "Episode 247 avg reward=-1.2592\n",
      "Episode 248\n",
      "Number visited 338\n",
      "Episode 248 exploratrion 0.16693333333333335\n",
      "Episode 248 total reward=-1.26\n",
      "Episode 248 reward=-3110.0\n",
      "Episode 248 avg reward=-1.244\n",
      "Episode 249\n",
      "Number visited 384\n",
      "Episode 249 exploratrion 0.1668\n",
      "Episode 249 total reward=-1.26\n",
      "Episode 249 reward=-3144.0\n",
      "Episode 249 avg reward=-1.2576\n",
      "Episode 250\n",
      "Number visited 338\n",
      "Episode 250 exploratrion 0.16666666666666669\n",
      "Episode 250 total reward=-1.26\n",
      "Episode 250 reward=-3110.0\n",
      "Episode 250 avg reward=-1.244\n",
      "Episode 251\n",
      "Number visited 384\n",
      "Episode 251 exploratrion 0.16653333333333334\n",
      "Episode 251 total reward=-1.25\n",
      "Episode 251 reward=-3124.0\n",
      "Episode 251 avg reward=-1.2496\n",
      "Episode 252\n",
      "Number visited 384\n",
      "Episode 252 exploratrion 0.1664\n",
      "Episode 252 total reward=-1.26\n",
      "Episode 252 reward=-3252.0\n",
      "Episode 252 avg reward=-1.3008000000000002\n",
      "Episode 253\n",
      "Number visited 292\n",
      "Episode 253 exploratrion 0.16626666666666667\n",
      "Episode 253 total reward=-1.26\n",
      "Episode 253 reward=-3148.0\n",
      "Episode 253 avg reward=-1.2592\n",
      "Episode 254\n",
      "Number visited 384\n",
      "Episode 254 exploratrion 0.16613333333333336\n",
      "Episode 254 total reward=-1.26\n",
      "Episode 254 reward=-3168.0\n",
      "Episode 254 avg reward=-1.2671999999999999\n",
      "Episode 255\n",
      "Number visited 384\n",
      "Episode 255 exploratrion 0.166\n",
      "Episode 255 total reward=-1.26\n",
      "Episode 255 reward=-3096.0\n",
      "Episode 255 avg reward=-1.2384\n",
      "Episode 256\n",
      "Number visited 384\n",
      "Episode 256 exploratrion 0.16586666666666666\n",
      "Episode 256 total reward=-1.26\n",
      "Episode 256 reward=-3160.0\n",
      "Episode 256 avg reward=-1.264\n",
      "Episode 257\n",
      "Number visited 384\n",
      "Episode 257 exploratrion 0.16573333333333334\n",
      "Episode 257 total reward=-1.26\n",
      "Episode 257 reward=-3156.0\n",
      "Episode 257 avg reward=-1.2624\n",
      "Episode 258\n",
      "Number visited 384\n",
      "Episode 258 exploratrion 0.16560000000000002\n",
      "Episode 258 total reward=-1.26\n",
      "Episode 258 reward=-3132.0\n",
      "Episode 258 avg reward=-1.2528\n",
      "Episode 259\n",
      "Number visited 384\n",
      "Episode 259 exploratrion 0.16546666666666668\n",
      "Episode 259 total reward=-1.26\n",
      "Episode 259 reward=-3120.0\n",
      "Episode 259 avg reward=-1.248\n",
      "Episode 260\n",
      "Number visited 384\n",
      "Episode 260 exploratrion 0.16533333333333333\n",
      "Episode 260 total reward=-1.26\n",
      "Episode 260 reward=-3136.0\n",
      "Episode 260 avg reward=-1.2544\n",
      "Episode 261\n",
      "Number visited 384\n",
      "Episode 261 exploratrion 0.1652\n",
      "Episode 261 total reward=-1.26\n",
      "Episode 261 reward=-3152.0\n",
      "Episode 261 avg reward=-1.2608\n",
      "Episode 262\n",
      "Number visited 384\n",
      "Episode 262 exploratrion 0.16506666666666667\n",
      "Episode 262 total reward=-1.26\n",
      "Episode 262 reward=-3208.0\n",
      "Episode 262 avg reward=-1.2832\n",
      "Episode 263\n",
      "Number visited 384\n",
      "Episode 263 exploratrion 0.16493333333333335\n",
      "Episode 263 total reward=-1.26\n",
      "Episode 263 reward=-3160.0\n",
      "Episode 263 avg reward=-1.264\n",
      "Episode 264\n",
      "Number visited 384\n",
      "Episode 264 exploratrion 0.1648\n",
      "Episode 264 total reward=-1.26\n",
      "Episode 264 reward=-3188.0\n",
      "Episode 264 avg reward=-1.2752\n",
      "Episode 265\n",
      "Number visited 384\n",
      "Episode 265 exploratrion 0.16466666666666668\n",
      "Episode 265 total reward=-1.26\n",
      "Episode 265 reward=-3196.0\n",
      "Episode 265 avg reward=-1.2784\n",
      "Episode 266\n",
      "Number visited 384\n",
      "Episode 266 exploratrion 0.16453333333333334\n",
      "Episode 266 total reward=-1.26\n",
      "Episode 266 reward=-3100.0\n",
      "Episode 266 avg reward=-1.24\n",
      "Episode 267\n",
      "Number visited 384\n",
      "Episode 267 exploratrion 0.16440000000000002\n",
      "Episode 267 total reward=-1.26\n",
      "Episode 267 reward=-3220.0\n",
      "Episode 267 avg reward=-1.288\n",
      "Episode 268\n",
      "Number visited 292\n",
      "Episode 268 exploratrion 0.16426666666666667\n",
      "Episode 268 total reward=-1.26\n",
      "Episode 268 reward=-3148.0\n",
      "Episode 268 avg reward=-1.2592\n",
      "Episode 269\n",
      "Number visited 292\n",
      "Episode 269 exploratrion 0.16413333333333335\n",
      "Episode 269 total reward=-1.27\n",
      "Episode 269 reward=-3284.0\n",
      "Episode 269 avg reward=-1.3136\n",
      "Episode 270\n",
      "Number visited 384\n",
      "Episode 270 exploratrion 0.164\n",
      "Episode 270 total reward=-1.27\n",
      "Episode 270 reward=-3192.0\n",
      "Episode 270 avg reward=-1.2768000000000002\n",
      "Episode 271\n",
      "Number visited 384\n",
      "Episode 271 exploratrion 0.16386666666666666\n",
      "Episode 271 total reward=-1.27\n",
      "Episode 271 reward=-3120.0\n",
      "Episode 271 avg reward=-1.248\n",
      "Episode 272\n",
      "Number visited 384\n",
      "Episode 272 exploratrion 0.16373333333333334\n",
      "Episode 272 total reward=-1.27\n",
      "Episode 272 reward=-3196.0\n",
      "Episode 272 avg reward=-1.2784\n",
      "Episode 273\n",
      "Number visited 384\n",
      "Episode 273 exploratrion 0.16360000000000002\n",
      "Episode 273 total reward=-1.27\n",
      "Episode 273 reward=-3188.0\n",
      "Episode 273 avg reward=-1.2752\n",
      "Episode 274\n",
      "Number visited 384\n",
      "Episode 274 exploratrion 0.16346666666666668\n",
      "Episode 274 total reward=-1.27\n",
      "Episode 274 reward=-3076.0\n",
      "Episode 274 avg reward=-1.2304000000000002\n",
      "Episode 275\n",
      "Number visited 384\n",
      "Episode 275 exploratrion 0.16333333333333333\n",
      "Episode 275 total reward=-1.27\n",
      "Episode 275 reward=-3224.0\n",
      "Episode 275 avg reward=-1.2896\n",
      "Episode 276\n",
      "Number visited 384\n",
      "Episode 276 exploratrion 0.1632\n",
      "Episode 276 total reward=-1.27\n",
      "Episode 276 reward=-3180.0\n",
      "Episode 276 avg reward=-1.272\n",
      "Episode 277\n",
      "Number visited 384\n",
      "Episode 277 exploratrion 0.16306666666666667\n",
      "Episode 277 total reward=-1.27\n",
      "Episode 277 reward=-3120.0\n",
      "Episode 277 avg reward=-1.248\n",
      "Episode 278\n",
      "Number visited 387\n",
      "Episode 278 exploratrion 0.16293333333333335\n",
      "Episode 278 total reward=-1.27\n",
      "Episode 278 reward=-3193.0\n",
      "Episode 278 avg reward=-1.2772\n",
      "Episode 279\n",
      "Number visited 526\n",
      "Episode 279 exploratrion 0.1628\n",
      "Episode 279 total reward=-1.25\n",
      "Episode 279 reward=-2782.0\n",
      "Episode 279 avg reward=-1.1128\n",
      "Episode 280\n",
      "Number visited 628\n",
      "Episode 280 exploratrion 0.16266666666666668\n",
      "Episode 280 total reward=-1.24\n",
      "Episode 280 reward=-2752.0\n",
      "Episode 280 avg reward=-1.1008\n",
      "Episode 281\n",
      "Number visited 384\n",
      "Episode 281 exploratrion 0.16253333333333334\n",
      "Episode 281 total reward=-1.24\n",
      "Episode 281 reward=-3248.0\n",
      "Episode 281 avg reward=-1.2992\n",
      "Episode 282\n",
      "Number visited 384\n",
      "Episode 282 exploratrion 0.16240000000000002\n",
      "Episode 282 total reward=-1.25\n",
      "Episode 282 reward=-3168.0\n",
      "Episode 282 avg reward=-1.2671999999999999\n",
      "Episode 283\n",
      "Number visited 564\n",
      "Episode 283 exploratrion 0.16226666666666667\n",
      "Episode 283 total reward=-1.23\n",
      "Episode 283 reward=-2808.0\n",
      "Episode 283 avg reward=-1.1232\n",
      "Episode 284\n",
      "Number visited 384\n",
      "Episode 284 exploratrion 0.16213333333333335\n",
      "Episode 284 total reward=-1.24\n",
      "Episode 284 reward=-3152.0\n",
      "Episode 284 avg reward=-1.2608\n",
      "Episode 285\n",
      "Number visited 384\n",
      "Episode 285 exploratrion 0.162\n",
      "Episode 285 total reward=-1.24\n",
      "Episode 285 reward=-3100.0\n",
      "Episode 285 avg reward=-1.24\n",
      "Episode 286\n",
      "Number visited 500\n",
      "Episode 286 exploratrion 0.16186666666666666\n",
      "Episode 286 total reward=-1.23\n",
      "Episode 286 reward=-2916.0\n",
      "Episode 286 avg reward=-1.1664\n",
      "Episode 287\n",
      "Number visited 384\n",
      "Episode 287 exploratrion 0.16173333333333334\n",
      "Episode 287 total reward=-1.23\n",
      "Episode 287 reward=-3140.0\n",
      "Episode 287 avg reward=-1.256\n",
      "Episode 288\n",
      "Number visited 384\n",
      "Episode 288 exploratrion 0.16160000000000002\n",
      "Episode 288 total reward=-1.24\n",
      "Episode 288 reward=-3232.0\n",
      "Episode 288 avg reward=-1.2928\n",
      "Episode 289\n",
      "Number visited 600\n",
      "Episode 289 exploratrion 0.16146666666666668\n",
      "Episode 289 total reward=-1.23\n",
      "Episode 289 reward=-2788.0\n",
      "Episode 289 avg reward=-1.1152\n",
      "Episode 290\n",
      "Number visited 384\n",
      "Episode 290 exploratrion 0.16133333333333333\n",
      "Episode 290 total reward=-1.23\n",
      "Episode 290 reward=-3080.0\n",
      "Episode 290 avg reward=-1.232\n",
      "Episode 291\n",
      "Number visited 384\n",
      "Episode 291 exploratrion 0.1612\n",
      "Episode 291 total reward=-1.23\n",
      "Episode 291 reward=-3108.0\n",
      "Episode 291 avg reward=-1.2431999999999999\n",
      "Episode 292\n",
      "Number visited 384\n",
      "Episode 292 exploratrion 0.1610666666666667\n",
      "Episode 292 total reward=-1.23\n",
      "Episode 292 reward=-3168.0\n",
      "Episode 292 avg reward=-1.2671999999999999\n",
      "Episode 293\n",
      "Number visited 384\n",
      "Episode 293 exploratrion 0.16093333333333334\n",
      "Episode 293 total reward=-1.23\n",
      "Episode 293 reward=-3108.0\n",
      "Episode 293 avg reward=-1.2431999999999999\n",
      "Episode 294\n",
      "Number visited 384\n",
      "Episode 294 exploratrion 0.1608\n",
      "Episode 294 total reward=-1.23\n",
      "Episode 294 reward=-3096.0\n",
      "Episode 294 avg reward=-1.2384\n",
      "Episode 295\n",
      "Number visited 292\n",
      "Episode 295 exploratrion 0.16066666666666668\n",
      "Episode 295 total reward=-1.24\n",
      "Episode 295 reward=-3220.0\n",
      "Episode 295 avg reward=-1.288\n",
      "Episode 296\n",
      "Number visited 384\n",
      "Episode 296 exploratrion 0.16053333333333333\n",
      "Episode 296 total reward=-1.24\n",
      "Episode 296 reward=-3084.0\n",
      "Episode 296 avg reward=-1.2336\n",
      "Episode 297\n",
      "Number visited 384\n",
      "Episode 297 exploratrion 0.16040000000000001\n",
      "Episode 297 total reward=-1.24\n",
      "Episode 297 reward=-3148.0\n",
      "Episode 297 avg reward=-1.2592\n",
      "Episode 298\n",
      "Number visited 244\n",
      "Episode 298 exploratrion 0.16026666666666667\n",
      "Episode 298 total reward=-1.24\n",
      "Episode 298 reward=-3198.0\n",
      "Episode 298 avg reward=-1.2792000000000001\n",
      "Episode 299\n",
      "Number visited 384\n",
      "Episode 299 exploratrion 0.16013333333333335\n",
      "Episode 299 total reward=-1.24\n",
      "Episode 299 reward=-3104.0\n",
      "Episode 299 avg reward=-1.2416\n",
      "Episode 300\n",
      "Number visited 384\n",
      "Episode 300 exploratrion 0.16\n",
      "Episode 300 total reward=-1.25\n",
      "Episode 300 reward=-3136.0\n",
      "Episode 300 avg reward=-1.2544\n",
      "Episode 301\n",
      "Number visited 384\n",
      "Episode 301 exploratrion 0.15986666666666668\n",
      "Episode 301 total reward=-1.24\n",
      "Episode 301 reward=-3084.0\n",
      "Episode 301 avg reward=-1.2336\n",
      "Episode 302\n",
      "Number visited 384\n",
      "Episode 302 exploratrion 0.15973333333333334\n",
      "Episode 302 total reward=-1.25\n",
      "Episode 302 reward=-3172.0\n",
      "Episode 302 avg reward=-1.2688\n",
      "Episode 303\n",
      "Number visited 384\n",
      "Episode 303 exploratrion 0.15960000000000002\n",
      "Episode 303 total reward=-1.25\n",
      "Episode 303 reward=-3156.0\n",
      "Episode 303 avg reward=-1.2624\n",
      "Episode 304\n",
      "Number visited 384\n",
      "Episode 304 exploratrion 0.15946666666666667\n",
      "Episode 304 total reward=-1.25\n",
      "Episode 304 reward=-3252.0\n",
      "Episode 304 avg reward=-1.3008000000000002\n",
      "Episode 305\n",
      "Number visited 384\n",
      "Episode 305 exploratrion 0.15933333333333333\n",
      "Episode 305 total reward=-1.25\n",
      "Episode 305 reward=-3132.0\n",
      "Episode 305 avg reward=-1.2528\n",
      "Episode 306\n",
      "Number visited 384\n",
      "Episode 306 exploratrion 0.1592\n",
      "Episode 306 total reward=-1.25\n",
      "Episode 306 reward=-3156.0\n",
      "Episode 306 avg reward=-1.2624\n",
      "Episode 307\n",
      "Number visited 384\n",
      "Episode 307 exploratrion 0.1590666666666667\n",
      "Episode 307 total reward=-1.26\n",
      "Episode 307 reward=-3192.0\n",
      "Episode 307 avg reward=-1.2768000000000002\n",
      "Episode 308\n",
      "Number visited 384\n",
      "Episode 308 exploratrion 0.15893333333333334\n",
      "Episode 308 total reward=-1.26\n",
      "Episode 308 reward=-3172.0\n",
      "Episode 308 avg reward=-1.2688\n",
      "Episode 309\n",
      "Number visited 384\n",
      "Episode 309 exploratrion 0.1588\n",
      "Episode 309 total reward=-1.26\n",
      "Episode 309 reward=-3256.0\n",
      "Episode 309 avg reward=-1.3024\n",
      "Episode 310\n",
      "Number visited 384\n",
      "Episode 310 exploratrion 0.15866666666666668\n",
      "Episode 310 total reward=-1.27\n",
      "Episode 310 reward=-3240.0\n",
      "Episode 310 avg reward=-1.296\n",
      "Episode 311\n",
      "Number visited 384\n",
      "Episode 311 exploratrion 0.15853333333333333\n",
      "Episode 311 total reward=-1.26\n",
      "Episode 311 reward=-3088.0\n",
      "Episode 311 avg reward=-1.2351999999999999\n",
      "Episode 312\n",
      "Number visited 384\n",
      "Episode 312 exploratrion 0.1584\n",
      "Episode 312 total reward=-1.26\n",
      "Episode 312 reward=-3172.0\n",
      "Episode 312 avg reward=-1.2688\n",
      "Episode 313\n",
      "Number visited 384\n",
      "Episode 313 exploratrion 0.15826666666666667\n",
      "Episode 313 total reward=-1.26\n",
      "Episode 313 reward=-3144.0\n",
      "Episode 313 avg reward=-1.2576\n",
      "Episode 314\n",
      "Number visited 384\n",
      "Episode 314 exploratrion 0.15813333333333335\n",
      "Episode 314 total reward=-1.26\n",
      "Episode 314 reward=-3192.0\n",
      "Episode 314 avg reward=-1.2768000000000002\n",
      "Episode 315\n",
      "Number visited 384\n",
      "Episode 315 exploratrion 0.158\n",
      "Episode 315 total reward=-1.26\n",
      "Episode 315 reward=-3072.0\n",
      "Episode 315 avg reward=-1.2288\n",
      "Episode 316\n",
      "Number visited 384\n",
      "Episode 316 exploratrion 0.15786666666666668\n",
      "Episode 316 total reward=-1.26\n",
      "Episode 316 reward=-3084.0\n",
      "Episode 316 avg reward=-1.2336\n",
      "Episode 317\n",
      "Number visited 384\n",
      "Episode 317 exploratrion 0.15773333333333334\n",
      "Episode 317 total reward=-1.26\n",
      "Episode 317 reward=-3184.0\n",
      "Episode 317 avg reward=-1.2736\n",
      "Episode 318\n",
      "Number visited 384\n",
      "Episode 318 exploratrion 0.15760000000000002\n",
      "Episode 318 total reward=-1.26\n",
      "Episode 318 reward=-3080.0\n",
      "Episode 318 avg reward=-1.232\n",
      "Episode 319\n",
      "Number visited 384\n",
      "Episode 319 exploratrion 0.15746666666666667\n",
      "Episode 319 total reward=-1.26\n",
      "Episode 319 reward=-3196.0\n",
      "Episode 319 avg reward=-1.2784\n",
      "Episode 320\n",
      "Number visited 384\n",
      "Episode 320 exploratrion 0.15733333333333333\n",
      "Episode 320 total reward=-1.26\n",
      "Episode 320 reward=-3080.0\n",
      "Episode 320 avg reward=-1.232\n",
      "Episode 321\n",
      "Number visited 384\n",
      "Episode 321 exploratrion 0.1572\n",
      "Episode 321 total reward=-1.26\n",
      "Episode 321 reward=-3184.0\n",
      "Episode 321 avg reward=-1.2736\n",
      "Episode 322\n",
      "Number visited 384\n",
      "Episode 322 exploratrion 0.1570666666666667\n",
      "Episode 322 total reward=-1.26\n",
      "Episode 322 reward=-3176.0\n",
      "Episode 322 avg reward=-1.2704\n",
      "Episode 323\n",
      "Number visited 384\n",
      "Episode 323 exploratrion 0.15693333333333334\n",
      "Episode 323 total reward=-1.26\n",
      "Episode 323 reward=-3144.0\n",
      "Episode 323 avg reward=-1.2576\n",
      "Episode 324\n",
      "Number visited 384\n",
      "Episode 324 exploratrion 0.1568\n",
      "Episode 324 total reward=-1.26\n",
      "Episode 324 reward=-3112.0\n",
      "Episode 324 avg reward=-1.2448000000000001\n",
      "Episode 325\n",
      "Number visited 384\n",
      "Episode 325 exploratrion 0.15666666666666668\n",
      "Episode 325 total reward=-1.26\n",
      "Episode 325 reward=-3224.0\n",
      "Episode 325 avg reward=-1.2896\n",
      "Episode 326\n",
      "Number visited 384\n",
      "Episode 326 exploratrion 0.15653333333333336\n",
      "Episode 326 total reward=-1.26\n",
      "Episode 326 reward=-3224.0\n",
      "Episode 326 avg reward=-1.2896\n",
      "Episode 327\n",
      "Number visited 292\n",
      "Episode 327 exploratrion 0.1564\n",
      "Episode 327 total reward=-1.27\n",
      "Episode 327 reward=-3196.0\n",
      "Episode 327 avg reward=-1.2784\n",
      "Episode 328\n",
      "Number visited 384\n",
      "Episode 328 exploratrion 0.15626666666666666\n",
      "Episode 328 total reward=-1.27\n",
      "Episode 328 reward=-3160.0\n",
      "Episode 328 avg reward=-1.264\n",
      "Episode 329\n",
      "Number visited 384\n",
      "Episode 329 exploratrion 0.15613333333333335\n",
      "Episode 329 total reward=-1.27\n",
      "Episode 329 reward=-3240.0\n",
      "Episode 329 avg reward=-1.296\n",
      "Episode 330\n",
      "Number visited 384\n",
      "Episode 330 exploratrion 0.156\n",
      "Episode 330 total reward=-1.27\n",
      "Episode 330 reward=-3236.0\n",
      "Episode 330 avg reward=-1.2944\n",
      "Episode 331\n",
      "Number visited 384\n",
      "Episode 331 exploratrion 0.15586666666666668\n",
      "Episode 331 total reward=-1.27\n",
      "Episode 331 reward=-3184.0\n",
      "Episode 331 avg reward=-1.2736\n",
      "Episode 332\n",
      "Number visited 384\n",
      "Episode 332 exploratrion 0.15573333333333333\n",
      "Episode 332 total reward=-1.27\n",
      "Episode 332 reward=-3168.0\n",
      "Episode 332 avg reward=-1.2671999999999999\n",
      "Episode 333\n",
      "Number visited 384\n",
      "Episode 333 exploratrion 0.15560000000000002\n",
      "Episode 333 total reward=-1.27\n",
      "Episode 333 reward=-3136.0\n",
      "Episode 333 avg reward=-1.2544\n",
      "Episode 334\n",
      "Number visited 338\n",
      "Episode 334 exploratrion 0.15546666666666667\n",
      "Episode 334 total reward=-1.27\n",
      "Episode 334 reward=-3138.0\n",
      "Episode 334 avg reward=-1.2551999999999999\n",
      "Episode 335\n",
      "Number visited 384\n",
      "Episode 335 exploratrion 0.15533333333333335\n",
      "Episode 335 total reward=-1.27\n",
      "Episode 335 reward=-3176.0\n",
      "Episode 335 avg reward=-1.2704\n",
      "Episode 336\n",
      "Number visited 384\n",
      "Episode 336 exploratrion 0.1552\n",
      "Episode 336 total reward=-1.27\n",
      "Episode 336 reward=-3228.0\n",
      "Episode 336 avg reward=-1.2912000000000001\n",
      "Episode 337\n",
      "Number visited 292\n",
      "Episode 337 exploratrion 0.15506666666666669\n",
      "Episode 337 total reward=-1.27\n",
      "Episode 337 reward=-3148.0\n",
      "Episode 337 avg reward=-1.2592\n",
      "Episode 338\n",
      "Number visited 384\n",
      "Episode 338 exploratrion 0.15493333333333334\n",
      "Episode 338 total reward=-1.27\n",
      "Episode 338 reward=-3240.0\n",
      "Episode 338 avg reward=-1.296\n",
      "Episode 339\n",
      "Number visited 384\n",
      "Episode 339 exploratrion 0.1548\n",
      "Episode 339 total reward=-1.27\n",
      "Episode 339 reward=-3076.0\n",
      "Episode 339 avg reward=-1.2304000000000002\n",
      "Episode 340\n",
      "Number visited 338\n",
      "Episode 340 exploratrion 0.15466666666666667\n",
      "Episode 340 total reward=-1.27\n",
      "Episode 340 reward=-3166.0\n",
      "Episode 340 avg reward=-1.2664\n",
      "Episode 341\n",
      "Number visited 292\n",
      "Episode 341 exploratrion 0.15453333333333336\n",
      "Episode 341 total reward=-1.27\n",
      "Episode 341 reward=-3148.0\n",
      "Episode 341 avg reward=-1.2592\n",
      "Episode 342\n",
      "Number visited 384\n",
      "Episode 342 exploratrion 0.1544\n",
      "Episode 342 total reward=-1.27\n",
      "Episode 342 reward=-3236.0\n",
      "Episode 342 avg reward=-1.2944\n",
      "Episode 343\n",
      "Number visited 384\n",
      "Episode 343 exploratrion 0.15426666666666666\n",
      "Episode 343 total reward=-1.27\n",
      "Episode 343 reward=-3252.0\n",
      "Episode 343 avg reward=-1.3008000000000002\n",
      "Episode 344\n",
      "Number visited 292\n",
      "Episode 344 exploratrion 0.15413333333333334\n",
      "Episode 344 total reward=-1.27\n",
      "Episode 344 reward=-3224.0\n",
      "Episode 344 avg reward=-1.2896\n",
      "Episode 345\n",
      "Number visited 384\n",
      "Episode 345 exploratrion 0.154\n",
      "Episode 345 total reward=-1.27\n",
      "Episode 345 reward=-3116.0\n",
      "Episode 345 avg reward=-1.2464\n",
      "Episode 346\n",
      "Number visited 384\n",
      "Episode 346 exploratrion 0.15386666666666668\n",
      "Episode 346 total reward=-1.27\n",
      "Episode 346 reward=-3216.0\n",
      "Episode 346 avg reward=-1.2863999999999998\n",
      "Episode 347\n",
      "Number visited 384\n",
      "Episode 347 exploratrion 0.15373333333333333\n",
      "Episode 347 total reward=-1.27\n",
      "Episode 347 reward=-3096.0\n",
      "Episode 347 avg reward=-1.2384\n",
      "Episode 348\n",
      "Number visited 384\n",
      "Episode 348 exploratrion 0.15360000000000001\n",
      "Episode 348 total reward=-1.27\n",
      "Episode 348 reward=-3212.0\n",
      "Episode 348 avg reward=-1.2848\n",
      "Episode 349\n",
      "Number visited 384\n",
      "Episode 349 exploratrion 0.15346666666666667\n",
      "Episode 349 total reward=-1.27\n",
      "Episode 349 reward=-3136.0\n",
      "Episode 349 avg reward=-1.2544\n",
      "Episode 350\n",
      "Number visited 384\n",
      "Episode 350 exploratrion 0.15333333333333335\n",
      "Episode 350 total reward=-1.27\n",
      "Episode 350 reward=-3128.0\n",
      "Episode 350 avg reward=-1.2512\n",
      "Episode 351\n",
      "Number visited 384\n",
      "Episode 351 exploratrion 0.1532\n",
      "Episode 351 total reward=-1.27\n",
      "Episode 351 reward=-3180.0\n",
      "Episode 351 avg reward=-1.272\n",
      "Episode 352\n",
      "Number visited 384\n",
      "Episode 352 exploratrion 0.15306666666666668\n",
      "Episode 352 total reward=-1.27\n",
      "Episode 352 reward=-3132.0\n",
      "Episode 352 avg reward=-1.2528\n",
      "Episode 353\n",
      "Number visited 384\n",
      "Episode 353 exploratrion 0.15293333333333334\n",
      "Episode 353 total reward=-1.26\n",
      "Episode 353 reward=-3072.0\n",
      "Episode 353 avg reward=-1.2288\n",
      "Episode 354\n",
      "Number visited 384\n",
      "Episode 354 exploratrion 0.15280000000000002\n",
      "Episode 354 total reward=-1.26\n",
      "Episode 354 reward=-3076.0\n",
      "Episode 354 avg reward=-1.2304000000000002\n",
      "Episode 355\n",
      "Number visited 384\n",
      "Episode 355 exploratrion 0.15266666666666667\n",
      "Episode 355 total reward=-1.26\n",
      "Episode 355 reward=-3216.0\n",
      "Episode 355 avg reward=-1.2863999999999998\n",
      "Episode 356\n",
      "Number visited 384\n",
      "Episode 356 exploratrion 0.15253333333333335\n",
      "Episode 356 total reward=-1.26\n",
      "Episode 356 reward=-3184.0\n",
      "Episode 356 avg reward=-1.2736\n",
      "Episode 357\n",
      "Number visited 384\n",
      "Episode 357 exploratrion 0.1524\n",
      "Episode 357 total reward=-1.27\n",
      "Episode 357 reward=-3216.0\n",
      "Episode 357 avg reward=-1.2863999999999998\n",
      "Episode 358\n",
      "Number visited 384\n",
      "Episode 358 exploratrion 0.15226666666666666\n",
      "Episode 358 total reward=-1.27\n",
      "Episode 358 reward=-3224.0\n",
      "Episode 358 avg reward=-1.2896\n",
      "Episode 359\n",
      "Number visited 338\n",
      "Episode 359 exploratrion 0.15213333333333334\n",
      "Episode 359 total reward=-1.27\n",
      "Episode 359 reward=-3230.0\n",
      "Episode 359 avg reward=-1.2919999999999998\n",
      "Episode 360\n",
      "Number visited 384\n",
      "Episode 360 exploratrion 0.15200000000000002\n",
      "Episode 360 total reward=-1.27\n",
      "Episode 360 reward=-3080.0\n",
      "Episode 360 avg reward=-1.232\n",
      "Episode 361\n",
      "Number visited 384\n",
      "Episode 361 exploratrion 0.15186666666666668\n",
      "Episode 361 total reward=-1.27\n",
      "Episode 361 reward=-3236.0\n",
      "Episode 361 avg reward=-1.2944\n",
      "Episode 362\n",
      "Number visited 384\n",
      "Episode 362 exploratrion 0.15173333333333333\n",
      "Episode 362 total reward=-1.27\n",
      "Episode 362 reward=-3152.0\n",
      "Episode 362 avg reward=-1.2608\n",
      "Episode 363\n",
      "Number visited 384\n",
      "Episode 363 exploratrion 0.1516\n",
      "Episode 363 total reward=-1.27\n",
      "Episode 363 reward=-3136.0\n",
      "Episode 363 avg reward=-1.2544\n",
      "Episode 364\n",
      "Number visited 384\n",
      "Episode 364 exploratrion 0.15146666666666667\n",
      "Episode 364 total reward=-1.26\n",
      "Episode 364 reward=-3096.0\n",
      "Episode 364 avg reward=-1.2384\n",
      "Episode 365\n",
      "Number visited 384\n",
      "Episode 365 exploratrion 0.15133333333333335\n",
      "Episode 365 total reward=-1.26\n",
      "Episode 365 reward=-3124.0\n",
      "Episode 365 avg reward=-1.2496\n",
      "Episode 366\n",
      "Number visited 384\n",
      "Episode 366 exploratrion 0.1512\n",
      "Episode 366 total reward=-1.26\n",
      "Episode 366 reward=-3108.0\n",
      "Episode 366 avg reward=-1.2431999999999999\n",
      "Episode 367\n",
      "Number visited 384\n",
      "Episode 367 exploratrion 0.15106666666666668\n",
      "Episode 367 total reward=-1.26\n",
      "Episode 367 reward=-3140.0\n",
      "Episode 367 avg reward=-1.256\n",
      "Episode 368\n",
      "Number visited 384\n",
      "Episode 368 exploratrion 0.15093333333333334\n",
      "Episode 368 total reward=-1.26\n",
      "Episode 368 reward=-3148.0\n",
      "Episode 368 avg reward=-1.2592\n",
      "Episode 369\n",
      "Number visited 384\n",
      "Episode 369 exploratrion 0.15080000000000002\n",
      "Episode 369 total reward=-1.26\n",
      "Episode 369 reward=-3208.0\n",
      "Episode 369 avg reward=-1.2832\n",
      "Episode 370\n",
      "Number visited 384\n",
      "Episode 370 exploratrion 0.15066666666666667\n",
      "Episode 370 total reward=-1.26\n",
      "Episode 370 reward=-3176.0\n",
      "Episode 370 avg reward=-1.2704\n",
      "Episode 371\n",
      "Number visited 384\n",
      "Episode 371 exploratrion 0.15053333333333335\n",
      "Episode 371 total reward=-1.26\n",
      "Episode 371 reward=-3144.0\n",
      "Episode 371 avg reward=-1.2576\n",
      "Episode 372\n",
      "Number visited 384\n",
      "Episode 372 exploratrion 0.1504\n",
      "Episode 372 total reward=-1.26\n",
      "Episode 372 reward=-3204.0\n",
      "Episode 372 avg reward=-1.2816\n",
      "Episode 373\n",
      "Number visited 384\n",
      "Episode 373 exploratrion 0.15026666666666666\n",
      "Episode 373 total reward=-1.27\n",
      "Episode 373 reward=-3208.0\n",
      "Episode 373 avg reward=-1.2832\n",
      "Episode 374\n",
      "Number visited 384\n",
      "Episode 374 exploratrion 0.15013333333333334\n",
      "Episode 374 total reward=-1.26\n",
      "Episode 374 reward=-3084.0\n",
      "Episode 374 avg reward=-1.2336\n",
      "Episode 375\n",
      "Number visited 384\n",
      "Episode 375 exploratrion 0.15000000000000002\n",
      "Episode 375 total reward=-1.26\n",
      "Episode 375 reward=-3168.0\n",
      "Episode 375 avg reward=-1.2671999999999999\n",
      "Episode 376\n",
      "Number visited 384\n",
      "Episode 376 exploratrion 0.14986666666666668\n",
      "Episode 376 total reward=-1.27\n",
      "Episode 376 reward=-3252.0\n",
      "Episode 376 avg reward=-1.3008000000000002\n",
      "Episode 377\n",
      "Number visited 384\n",
      "Episode 377 exploratrion 0.14973333333333333\n",
      "Episode 377 total reward=-1.27\n",
      "Episode 377 reward=-3116.0\n",
      "Episode 377 avg reward=-1.2464\n",
      "Episode 378\n",
      "Number visited 384\n",
      "Episode 378 exploratrion 0.1496\n",
      "Episode 378 total reward=-1.26\n",
      "Episode 378 reward=-3076.0\n",
      "Episode 378 avg reward=-1.2304000000000002\n",
      "Episode 379\n",
      "Number visited 384\n",
      "Episode 379 exploratrion 0.1494666666666667\n",
      "Episode 379 total reward=-1.26\n",
      "Episode 379 reward=-3100.0\n",
      "Episode 379 avg reward=-1.24\n",
      "Episode 380\n",
      "Number visited 384\n",
      "Episode 380 exploratrion 0.14933333333333335\n",
      "Episode 380 total reward=-1.26\n",
      "Episode 380 reward=-3256.0\n",
      "Episode 380 avg reward=-1.3024\n",
      "Episode 381\n",
      "Number visited 384\n",
      "Episode 381 exploratrion 0.1492\n",
      "Episode 381 total reward=-1.27\n",
      "Episode 381 reward=-3252.0\n",
      "Episode 381 avg reward=-1.3008000000000002\n",
      "Episode 382\n",
      "Number visited 384\n",
      "Episode 382 exploratrion 0.14906666666666668\n",
      "Episode 382 total reward=-1.27\n",
      "Episode 382 reward=-3216.0\n",
      "Episode 382 avg reward=-1.2863999999999998\n",
      "Episode 383\n",
      "Number visited 384\n",
      "Episode 383 exploratrion 0.14893333333333333\n",
      "Episode 383 total reward=-1.27\n",
      "Episode 383 reward=-3180.0\n",
      "Episode 383 avg reward=-1.272\n",
      "Episode 384\n",
      "Number visited 384\n",
      "Episode 384 exploratrion 0.14880000000000002\n",
      "Episode 384 total reward=-1.27\n",
      "Episode 384 reward=-3208.0\n",
      "Episode 384 avg reward=-1.2832\n",
      "Episode 385\n",
      "Number visited 384\n",
      "Episode 385 exploratrion 0.14866666666666667\n",
      "Episode 385 total reward=-1.27\n",
      "Episode 385 reward=-3076.0\n",
      "Episode 385 avg reward=-1.2304000000000002\n",
      "Episode 386\n",
      "Number visited 384\n",
      "Episode 386 exploratrion 0.14853333333333335\n",
      "Episode 386 total reward=-1.26\n",
      "Episode 386 reward=-3072.0\n",
      "Episode 386 avg reward=-1.2288\n",
      "Episode 387\n",
      "Number visited 384\n",
      "Episode 387 exploratrion 0.1484\n",
      "Episode 387 total reward=-1.27\n",
      "Episode 387 reward=-3232.0\n",
      "Episode 387 avg reward=-1.2928\n",
      "Episode 388\n",
      "Number visited 384\n",
      "Episode 388 exploratrion 0.14826666666666669\n",
      "Episode 388 total reward=-1.27\n",
      "Episode 388 reward=-3196.0\n",
      "Episode 388 avg reward=-1.2784\n",
      "Episode 389\n",
      "Number visited 384\n",
      "Episode 389 exploratrion 0.14813333333333334\n",
      "Episode 389 total reward=-1.26\n",
      "Episode 389 reward=-3096.0\n",
      "Episode 389 avg reward=-1.2384\n",
      "Episode 390\n",
      "Number visited 384\n",
      "Episode 390 exploratrion 0.14800000000000002\n",
      "Episode 390 total reward=-1.26\n",
      "Episode 390 reward=-3088.0\n",
      "Episode 390 avg reward=-1.2351999999999999\n",
      "Episode 391\n",
      "Number visited 384\n",
      "Episode 391 exploratrion 0.14786666666666667\n",
      "Episode 391 total reward=-1.26\n",
      "Episode 391 reward=-3108.0\n",
      "Episode 391 avg reward=-1.2431999999999999\n",
      "Episode 392\n",
      "Number visited 384\n",
      "Episode 392 exploratrion 0.14773333333333336\n",
      "Episode 392 total reward=-1.26\n",
      "Episode 392 reward=-3244.0\n",
      "Episode 392 avg reward=-1.2975999999999999\n",
      "Episode 393\n",
      "Number visited 384\n",
      "Episode 393 exploratrion 0.1476\n",
      "Episode 393 total reward=-1.26\n",
      "Episode 393 reward=-3168.0\n",
      "Episode 393 avg reward=-1.2671999999999999\n",
      "Episode 394\n",
      "Number visited 338\n",
      "Episode 394 exploratrion 0.1474666666666667\n",
      "Episode 394 total reward=-1.26\n",
      "Episode 394 reward=-3110.0\n",
      "Episode 394 avg reward=-1.244\n",
      "Episode 395\n",
      "Number visited 384\n",
      "Episode 395 exploratrion 0.14733333333333334\n",
      "Episode 395 total reward=-1.26\n",
      "Episode 395 reward=-3200.0\n",
      "Episode 395 avg reward=-1.28\n",
      "Episode 396\n",
      "Number visited 384\n",
      "Episode 396 exploratrion 0.1472\n",
      "Episode 396 total reward=-1.26\n",
      "Episode 396 reward=-3080.0\n",
      "Episode 396 avg reward=-1.232\n",
      "Episode 397\n",
      "Number visited 384\n",
      "Episode 397 exploratrion 0.14706666666666668\n",
      "Episode 397 total reward=-1.26\n",
      "Episode 397 reward=-3176.0\n",
      "Episode 397 avg reward=-1.2704\n",
      "Episode 398\n",
      "Number visited 384\n",
      "Episode 398 exploratrion 0.14693333333333336\n",
      "Episode 398 total reward=-1.26\n",
      "Episode 398 reward=-3112.0\n",
      "Episode 398 avg reward=-1.2448000000000001\n",
      "Episode 399\n",
      "Number visited 384\n",
      "Episode 399 exploratrion 0.1468\n",
      "Episode 399 total reward=-1.26\n",
      "Episode 399 reward=-3124.0\n",
      "Episode 399 avg reward=-1.2496\n",
      "Episode 400\n",
      "Number visited 384\n",
      "Episode 400 exploratrion 0.14666666666666667\n",
      "Episode 400 total reward=-1.26\n",
      "Episode 400 reward=-3164.0\n",
      "Episode 400 avg reward=-1.2656\n",
      "Episode 401\n",
      "Number visited 384\n",
      "Episode 401 exploratrion 0.14653333333333335\n",
      "Episode 401 total reward=-1.26\n",
      "Episode 401 reward=-3188.0\n",
      "Episode 401 avg reward=-1.2752\n",
      "Episode 402\n",
      "Number visited 384\n",
      "Episode 402 exploratrion 0.1464\n",
      "Episode 402 total reward=-1.26\n",
      "Episode 402 reward=-3236.0\n",
      "Episode 402 avg reward=-1.2944\n",
      "Episode 403\n",
      "Number visited 384\n",
      "Episode 403 exploratrion 0.14626666666666668\n",
      "Episode 403 total reward=-1.26\n",
      "Episode 403 reward=-3148.0\n",
      "Episode 403 avg reward=-1.2592\n",
      "Episode 404\n",
      "Number visited 384\n",
      "Episode 404 exploratrion 0.14613333333333334\n",
      "Episode 404 total reward=-1.26\n",
      "Episode 404 reward=-3084.0\n",
      "Episode 404 avg reward=-1.2336\n",
      "Episode 405\n",
      "Number visited 384\n",
      "Episode 405 exploratrion 0.14600000000000002\n",
      "Episode 405 total reward=-1.26\n",
      "Episode 405 reward=-3188.0\n",
      "Episode 405 avg reward=-1.2752\n",
      "Episode 406\n",
      "Number visited 384\n",
      "Episode 406 exploratrion 0.14586666666666667\n",
      "Episode 406 total reward=-1.26\n",
      "Episode 406 reward=-3148.0\n",
      "Episode 406 avg reward=-1.2592\n",
      "Episode 407\n",
      "Number visited 384\n",
      "Episode 407 exploratrion 0.14573333333333335\n",
      "Episode 407 total reward=-1.27\n",
      "Episode 407 reward=-3232.0\n",
      "Episode 407 avg reward=-1.2928\n",
      "Episode 408\n",
      "Number visited 384\n",
      "Episode 408 exploratrion 0.1456\n",
      "Episode 408 total reward=-1.26\n",
      "Episode 408 reward=-3148.0\n",
      "Episode 408 avg reward=-1.2592\n",
      "Episode 409\n",
      "Number visited 384\n",
      "Episode 409 exploratrion 0.1454666666666667\n",
      "Episode 409 total reward=-1.26\n",
      "Episode 409 reward=-3104.0\n",
      "Episode 409 avg reward=-1.2416\n",
      "Episode 410\n",
      "Number visited 384\n",
      "Episode 410 exploratrion 0.14533333333333334\n",
      "Episode 410 total reward=-1.26\n",
      "Episode 410 reward=-3176.0\n",
      "Episode 410 avg reward=-1.2704\n",
      "Episode 411\n",
      "Number visited 384\n",
      "Episode 411 exploratrion 0.1452\n",
      "Episode 411 total reward=-1.26\n",
      "Episode 411 reward=-3136.0\n",
      "Episode 411 avg reward=-1.2544\n",
      "Episode 412\n",
      "Number visited 384\n",
      "Episode 412 exploratrion 0.14506666666666668\n",
      "Episode 412 total reward=-1.26\n",
      "Episode 412 reward=-3128.0\n",
      "Episode 412 avg reward=-1.2512\n",
      "Episode 413\n",
      "Number visited 384\n",
      "Episode 413 exploratrion 0.14493333333333336\n",
      "Episode 413 total reward=-1.26\n",
      "Episode 413 reward=-3176.0\n",
      "Episode 413 avg reward=-1.2704\n",
      "Episode 414\n",
      "Number visited 384\n",
      "Episode 414 exploratrion 0.1448\n",
      "Episode 414 total reward=-1.26\n",
      "Episode 414 reward=-3200.0\n",
      "Episode 414 avg reward=-1.28\n",
      "Episode 415\n",
      "Number visited 384\n",
      "Episode 415 exploratrion 0.14466666666666667\n",
      "Episode 415 total reward=-1.26\n",
      "Episode 415 reward=-3088.0\n",
      "Episode 415 avg reward=-1.2351999999999999\n",
      "Episode 416\n",
      "Number visited 384\n",
      "Episode 416 exploratrion 0.14453333333333335\n",
      "Episode 416 total reward=-1.27\n",
      "Episode 416 reward=-3256.0\n",
      "Episode 416 avg reward=-1.3024\n",
      "Episode 417\n",
      "Number visited 384\n",
      "Episode 417 exploratrion 0.1444\n",
      "Episode 417 total reward=-1.27\n",
      "Episode 417 reward=-3220.0\n",
      "Episode 417 avg reward=-1.288\n",
      "Episode 418\n",
      "Number visited 384\n",
      "Episode 418 exploratrion 0.14426666666666668\n",
      "Episode 418 total reward=-1.27\n",
      "Episode 418 reward=-3136.0\n",
      "Episode 418 avg reward=-1.2544\n",
      "Episode 419\n",
      "Number visited 384\n",
      "Episode 419 exploratrion 0.14413333333333334\n",
      "Episode 419 total reward=-1.26\n",
      "Episode 419 reward=-3116.0\n",
      "Episode 419 avg reward=-1.2464\n",
      "Episode 420\n",
      "Number visited 384\n",
      "Episode 420 exploratrion 0.14400000000000002\n",
      "Episode 420 total reward=-1.27\n",
      "Episode 420 reward=-3236.0\n",
      "Episode 420 avg reward=-1.2944\n",
      "Episode 421\n",
      "Number visited 384\n",
      "Episode 421 exploratrion 0.14386666666666667\n",
      "Episode 421 total reward=-1.26\n",
      "Episode 421 reward=-3080.0\n",
      "Episode 421 avg reward=-1.232\n",
      "Episode 422\n",
      "Number visited 338\n",
      "Episode 422 exploratrion 0.14373333333333335\n",
      "Episode 422 total reward=-1.27\n",
      "Episode 422 reward=-3202.0\n",
      "Episode 422 avg reward=-1.2808000000000002\n",
      "Episode 423\n",
      "Number visited 384\n",
      "Episode 423 exploratrion 0.1436\n",
      "Episode 423 total reward=-1.27\n",
      "Episode 423 reward=-3188.0\n",
      "Episode 423 avg reward=-1.2752\n",
      "Episode 424\n",
      "Number visited 384\n",
      "Episode 424 exploratrion 0.1434666666666667\n",
      "Episode 424 total reward=-1.26\n",
      "Episode 424 reward=-3132.0\n",
      "Episode 424 avg reward=-1.2528\n",
      "Episode 425\n",
      "Number visited 384\n",
      "Episode 425 exploratrion 0.14333333333333334\n",
      "Episode 425 total reward=-1.27\n",
      "Episode 425 reward=-3208.0\n",
      "Episode 425 avg reward=-1.2832\n",
      "Episode 426\n",
      "Number visited 384\n",
      "Episode 426 exploratrion 0.14320000000000002\n",
      "Episode 426 total reward=-1.27\n",
      "Episode 426 reward=-3164.0\n",
      "Episode 426 avg reward=-1.2656\n",
      "Episode 427\n",
      "Number visited 384\n",
      "Episode 427 exploratrion 0.14306666666666668\n",
      "Episode 427 total reward=-1.27\n",
      "Episode 427 reward=-3132.0\n",
      "Episode 427 avg reward=-1.2528\n",
      "Episode 428\n",
      "Number visited 384\n",
      "Episode 428 exploratrion 0.14293333333333336\n",
      "Episode 428 total reward=-1.27\n",
      "Episode 428 reward=-3212.0\n",
      "Episode 428 avg reward=-1.2848\n",
      "Episode 429\n",
      "Number visited 338\n",
      "Episode 429 exploratrion 0.1428\n",
      "Episode 429 total reward=-1.27\n",
      "Episode 429 reward=-3258.0\n",
      "Episode 429 avg reward=-1.3032\n",
      "Episode 430\n",
      "Number visited 384\n",
      "Episode 430 exploratrion 0.14266666666666666\n",
      "Episode 430 total reward=-1.27\n",
      "Episode 430 reward=-3152.0\n",
      "Episode 430 avg reward=-1.2608\n",
      "Episode 431\n",
      "Number visited 384\n",
      "Episode 431 exploratrion 0.14253333333333335\n",
      "Episode 431 total reward=-1.27\n",
      "Episode 431 reward=-3220.0\n",
      "Episode 431 avg reward=-1.288\n",
      "Episode 432\n",
      "Number visited 384\n",
      "Episode 432 exploratrion 0.14240000000000003\n",
      "Episode 432 total reward=-1.27\n",
      "Episode 432 reward=-3220.0\n",
      "Episode 432 avg reward=-1.288\n",
      "Episode 433\n",
      "Number visited 384\n",
      "Episode 433 exploratrion 0.14226666666666668\n",
      "Episode 433 total reward=-1.27\n",
      "Episode 433 reward=-3192.0\n",
      "Episode 433 avg reward=-1.2768000000000002\n",
      "Episode 434\n",
      "Number visited 384\n",
      "Episode 434 exploratrion 0.14213333333333333\n",
      "Episode 434 total reward=-1.27\n",
      "Episode 434 reward=-3100.0\n",
      "Episode 434 avg reward=-1.24\n",
      "Episode 435\n",
      "Number visited 384\n",
      "Episode 435 exploratrion 0.14200000000000002\n",
      "Episode 435 total reward=-1.27\n",
      "Episode 435 reward=-3148.0\n",
      "Episode 435 avg reward=-1.2592\n",
      "Episode 436\n",
      "Number visited 384\n",
      "Episode 436 exploratrion 0.14186666666666667\n",
      "Episode 436 total reward=-1.27\n",
      "Episode 436 reward=-3248.0\n",
      "Episode 436 avg reward=-1.2992\n",
      "Episode 437\n",
      "Number visited 384\n",
      "Episode 437 exploratrion 0.14173333333333335\n",
      "Episode 437 total reward=-1.27\n",
      "Episode 437 reward=-3096.0\n",
      "Episode 437 avg reward=-1.2384\n",
      "Episode 438\n",
      "Number visited 384\n",
      "Episode 438 exploratrion 0.1416\n",
      "Episode 438 total reward=-1.27\n",
      "Episode 438 reward=-3188.0\n",
      "Episode 438 avg reward=-1.2752\n",
      "Episode 439\n",
      "Number visited 384\n",
      "Episode 439 exploratrion 0.14146666666666668\n",
      "Episode 439 total reward=-1.27\n",
      "Episode 439 reward=-3176.0\n",
      "Episode 439 avg reward=-1.2704\n",
      "Episode 440\n",
      "Number visited 384\n",
      "Episode 440 exploratrion 0.14133333333333334\n",
      "Episode 440 total reward=-1.27\n",
      "Episode 440 reward=-3236.0\n",
      "Episode 440 avg reward=-1.2944\n",
      "Episode 441\n",
      "Number visited 384\n",
      "Episode 441 exploratrion 0.14120000000000002\n",
      "Episode 441 total reward=-1.27\n",
      "Episode 441 reward=-3076.0\n",
      "Episode 441 avg reward=-1.2304000000000002\n",
      "Episode 442\n",
      "Number visited 384\n",
      "Episode 442 exploratrion 0.14106666666666667\n",
      "Episode 442 total reward=-1.27\n",
      "Episode 442 reward=-3168.0\n",
      "Episode 442 avg reward=-1.2671999999999999\n",
      "Episode 443\n",
      "Number visited 384\n",
      "Episode 443 exploratrion 0.14093333333333335\n",
      "Episode 443 total reward=-1.27\n",
      "Episode 443 reward=-3116.0\n",
      "Episode 443 avg reward=-1.2464\n",
      "Episode 444\n",
      "Number visited 384\n",
      "Episode 444 exploratrion 0.1408\n",
      "Episode 444 total reward=-1.27\n",
      "Episode 444 reward=-3224.0\n",
      "Episode 444 avg reward=-1.2896\n",
      "Episode 445\n",
      "Number visited 384\n",
      "Episode 445 exploratrion 0.14066666666666666\n",
      "Episode 445 total reward=-1.27\n",
      "Episode 445 reward=-3112.0\n",
      "Episode 445 avg reward=-1.2448000000000001\n",
      "Episode 446\n",
      "Number visited 384\n",
      "Episode 446 exploratrion 0.14053333333333334\n",
      "Episode 446 total reward=-1.26\n",
      "Episode 446 reward=-3084.0\n",
      "Episode 446 avg reward=-1.2336\n",
      "Episode 447\n",
      "Number visited 338\n",
      "Episode 447 exploratrion 0.14040000000000002\n",
      "Episode 447 total reward=-1.26\n",
      "Episode 447 reward=-3194.0\n",
      "Episode 447 avg reward=-1.2776\n",
      "Episode 448\n",
      "Number visited 384\n",
      "Episode 448 exploratrion 0.14026666666666668\n",
      "Episode 448 total reward=-1.27\n",
      "Episode 448 reward=-3244.0\n",
      "Episode 448 avg reward=-1.2975999999999999\n",
      "Episode 449\n",
      "Number visited 384\n",
      "Episode 449 exploratrion 0.14013333333333333\n",
      "Episode 449 total reward=-1.27\n",
      "Episode 449 reward=-3164.0\n",
      "Episode 449 avg reward=-1.2656\n",
      "Episode 450\n",
      "Number visited 384\n",
      "Episode 450 exploratrion 0.14\n",
      "Episode 450 total reward=-1.27\n",
      "Episode 450 reward=-3240.0\n",
      "Episode 450 avg reward=-1.296\n",
      "Episode 451\n",
      "Number visited 384\n",
      "Episode 451 exploratrion 0.13986666666666667\n",
      "Episode 451 total reward=-1.27\n",
      "Episode 451 reward=-3088.0\n",
      "Episode 451 avg reward=-1.2351999999999999\n",
      "Episode 452\n",
      "Number visited 384\n",
      "Episode 452 exploratrion 0.13973333333333335\n",
      "Episode 452 total reward=-1.27\n",
      "Episode 452 reward=-3136.0\n",
      "Episode 452 avg reward=-1.2544\n",
      "Episode 453\n",
      "Number visited 384\n",
      "Episode 453 exploratrion 0.1396\n",
      "Episode 453 total reward=-1.27\n",
      "Episode 453 reward=-3216.0\n",
      "Episode 453 avg reward=-1.2863999999999998\n",
      "Episode 454\n",
      "Number visited 384\n",
      "Episode 454 exploratrion 0.13946666666666668\n",
      "Episode 454 total reward=-1.27\n",
      "Episode 454 reward=-3244.0\n",
      "Episode 454 avg reward=-1.2975999999999999\n",
      "Episode 455\n",
      "Number visited 384\n",
      "Episode 455 exploratrion 0.13933333333333334\n",
      "Episode 455 total reward=-1.27\n",
      "Episode 455 reward=-3224.0\n",
      "Episode 455 avg reward=-1.2896\n",
      "Episode 456\n",
      "Number visited 384\n",
      "Episode 456 exploratrion 0.13920000000000002\n",
      "Episode 456 total reward=-1.27\n",
      "Episode 456 reward=-3084.0\n",
      "Episode 456 avg reward=-1.2336\n",
      "Episode 457\n",
      "Number visited 384\n",
      "Episode 457 exploratrion 0.13906666666666667\n",
      "Episode 457 total reward=-1.27\n",
      "Episode 457 reward=-3084.0\n",
      "Episode 457 avg reward=-1.2336\n",
      "Episode 458\n",
      "Number visited 384\n",
      "Episode 458 exploratrion 0.13893333333333335\n",
      "Episode 458 total reward=-1.27\n",
      "Episode 458 reward=-3212.0\n",
      "Episode 458 avg reward=-1.2848\n",
      "Episode 459\n",
      "Number visited 384\n",
      "Episode 459 exploratrion 0.1388\n",
      "Episode 459 total reward=-1.27\n",
      "Episode 459 reward=-3224.0\n",
      "Episode 459 avg reward=-1.2896\n",
      "Episode 460\n",
      "Number visited 384\n",
      "Episode 460 exploratrion 0.1386666666666667\n",
      "Episode 460 total reward=-1.27\n",
      "Episode 460 reward=-3240.0\n",
      "Episode 460 avg reward=-1.296\n",
      "Episode 461\n",
      "Number visited 292\n",
      "Episode 461 exploratrion 0.13853333333333334\n",
      "Episode 461 total reward=-1.27\n",
      "Episode 461 reward=-3224.0\n",
      "Episode 461 avg reward=-1.2896\n",
      "Episode 462\n",
      "Number visited 384\n",
      "Episode 462 exploratrion 0.13840000000000002\n",
      "Episode 462 total reward=-1.27\n",
      "Episode 462 reward=-3204.0\n",
      "Episode 462 avg reward=-1.2816\n",
      "Episode 463\n",
      "Number visited 384\n",
      "Episode 463 exploratrion 0.13826666666666668\n",
      "Episode 463 total reward=-1.27\n",
      "Episode 463 reward=-3160.0\n",
      "Episode 463 avg reward=-1.264\n",
      "Episode 464\n",
      "Number visited 384\n",
      "Episode 464 exploratrion 0.13813333333333333\n",
      "Episode 464 total reward=-1.27\n",
      "Episode 464 reward=-3116.0\n",
      "Episode 464 avg reward=-1.2464\n",
      "Episode 465\n",
      "Number visited 338\n",
      "Episode 465 exploratrion 0.138\n",
      "Episode 465 total reward=-1.27\n",
      "Episode 465 reward=-3230.0\n",
      "Episode 465 avg reward=-1.2919999999999998\n",
      "Episode 466\n",
      "Number visited 384\n",
      "Episode 466 exploratrion 0.1378666666666667\n",
      "Episode 466 total reward=-1.27\n",
      "Episode 466 reward=-3156.0\n",
      "Episode 466 avg reward=-1.2624\n",
      "Episode 467\n",
      "Number visited 384\n",
      "Episode 467 exploratrion 0.13773333333333335\n",
      "Episode 467 total reward=-1.27\n",
      "Episode 467 reward=-3240.0\n",
      "Episode 467 avg reward=-1.296\n",
      "Episode 468\n",
      "Number visited 384\n",
      "Episode 468 exploratrion 0.1376\n",
      "Episode 468 total reward=-1.27\n",
      "Episode 468 reward=-3128.0\n",
      "Episode 468 avg reward=-1.2512\n",
      "Episode 469\n",
      "Number visited 384\n",
      "Episode 469 exploratrion 0.13746666666666668\n",
      "Episode 469 total reward=-1.27\n",
      "Episode 469 reward=-3076.0\n",
      "Episode 469 avg reward=-1.2304000000000002\n",
      "Episode 470\n",
      "Number visited 384\n",
      "Episode 470 exploratrion 0.13733333333333334\n",
      "Episode 470 total reward=-1.27\n",
      "Episode 470 reward=-3108.0\n",
      "Episode 470 avg reward=-1.2431999999999999\n",
      "Episode 471\n",
      "Number visited 384\n",
      "Episode 471 exploratrion 0.1372\n",
      "Episode 471 total reward=-1.27\n",
      "Episode 471 reward=-3244.0\n",
      "Episode 471 avg reward=-1.2975999999999999\n",
      "Episode 472\n",
      "Number visited 384\n",
      "Episode 472 exploratrion 0.13706666666666667\n",
      "Episode 472 total reward=-1.27\n",
      "Episode 472 reward=-3116.0\n",
      "Episode 472 avg reward=-1.2464\n",
      "Episode 473\n",
      "Number visited 384\n",
      "Episode 473 exploratrion 0.13693333333333335\n",
      "Episode 473 total reward=-1.26\n",
      "Episode 473 reward=-3092.0\n",
      "Episode 473 avg reward=-1.2368000000000001\n",
      "Episode 474\n",
      "Number visited 384\n",
      "Episode 474 exploratrion 0.1368\n",
      "Episode 474 total reward=-1.27\n",
      "Episode 474 reward=-3248.0\n",
      "Episode 474 avg reward=-1.2992\n",
      "Episode 475\n",
      "Number visited 384\n",
      "Episode 475 exploratrion 0.13666666666666666\n",
      "Episode 475 total reward=-1.27\n",
      "Episode 475 reward=-3184.0\n",
      "Episode 475 avg reward=-1.2736\n",
      "Episode 476\n",
      "Number visited 384\n",
      "Episode 476 exploratrion 0.13653333333333334\n",
      "Episode 476 total reward=-1.26\n",
      "Episode 476 reward=-3092.0\n",
      "Episode 476 avg reward=-1.2368000000000001\n",
      "Episode 477\n",
      "Number visited 384\n",
      "Episode 477 exploratrion 0.13640000000000002\n",
      "Episode 477 total reward=-1.27\n",
      "Episode 477 reward=-3204.0\n",
      "Episode 477 avg reward=-1.2816\n",
      "Episode 478\n",
      "Number visited 384\n",
      "Episode 478 exploratrion 0.13626666666666667\n",
      "Episode 478 total reward=-1.26\n",
      "Episode 478 reward=-3092.0\n",
      "Episode 478 avg reward=-1.2368000000000001\n",
      "Episode 479\n",
      "Number visited 384\n",
      "Episode 479 exploratrion 0.13613333333333333\n",
      "Episode 479 total reward=-1.27\n",
      "Episode 479 reward=-3224.0\n",
      "Episode 479 avg reward=-1.2896\n",
      "Episode 480\n",
      "Number visited 384\n",
      "Episode 480 exploratrion 0.136\n",
      "Episode 480 total reward=-1.26\n",
      "Episode 480 reward=-3136.0\n",
      "Episode 480 avg reward=-1.2544\n",
      "Episode 481\n",
      "Number visited 384\n",
      "Episode 481 exploratrion 0.1358666666666667\n",
      "Episode 481 total reward=-1.27\n",
      "Episode 481 reward=-3172.0\n",
      "Episode 481 avg reward=-1.2688\n",
      "Episode 482\n",
      "Number visited 384\n",
      "Episode 482 exploratrion 0.13573333333333332\n",
      "Episode 482 total reward=-1.27\n",
      "Episode 482 reward=-3204.0\n",
      "Episode 482 avg reward=-1.2816\n",
      "Episode 483\n",
      "Number visited 338\n",
      "Episode 483 exploratrion 0.1356\n",
      "Episode 483 total reward=-1.26\n",
      "Episode 483 reward=-3110.0\n",
      "Episode 483 avg reward=-1.244\n",
      "Episode 484\n",
      "Number visited 384\n",
      "Episode 484 exploratrion 0.13546666666666668\n",
      "Episode 484 total reward=-1.27\n",
      "Episode 484 reward=-3200.0\n",
      "Episode 484 avg reward=-1.28\n",
      "Episode 485\n",
      "Number visited 384\n",
      "Episode 485 exploratrion 0.13533333333333336\n",
      "Episode 485 total reward=-1.27\n",
      "Episode 485 reward=-3196.0\n",
      "Episode 485 avg reward=-1.2784\n",
      "Episode 486\n",
      "Number visited 338\n",
      "Episode 486 exploratrion 0.1352\n",
      "Episode 486 total reward=-1.27\n",
      "Episode 486 reward=-3174.0\n",
      "Episode 486 avg reward=-1.2695999999999998\n",
      "Episode 487\n",
      "Number visited 384\n",
      "Episode 487 exploratrion 0.13506666666666667\n",
      "Episode 487 total reward=-1.27\n",
      "Episode 487 reward=-3112.0\n",
      "Episode 487 avg reward=-1.2448000000000001\n",
      "Episode 488\n",
      "Number visited 384\n",
      "Episode 488 exploratrion 0.13493333333333335\n",
      "Episode 488 total reward=-1.26\n",
      "Episode 488 reward=-3128.0\n",
      "Episode 488 avg reward=-1.2512\n",
      "Episode 489\n",
      "Number visited 384\n",
      "Episode 489 exploratrion 0.1348\n",
      "Episode 489 total reward=-1.26\n",
      "Episode 489 reward=-3188.0\n",
      "Episode 489 avg reward=-1.2752\n",
      "Episode 490\n",
      "Number visited 384\n",
      "Episode 490 exploratrion 0.13466666666666666\n",
      "Episode 490 total reward=-1.27\n",
      "Episode 490 reward=-3232.0\n",
      "Episode 490 avg reward=-1.2928\n",
      "Episode 491\n",
      "Number visited 384\n",
      "Episode 491 exploratrion 0.13453333333333334\n",
      "Episode 491 total reward=-1.27\n",
      "Episode 491 reward=-3224.0\n",
      "Episode 491 avg reward=-1.2896\n",
      "Episode 492\n",
      "Number visited 384\n",
      "Episode 492 exploratrion 0.13440000000000002\n",
      "Episode 492 total reward=-1.27\n",
      "Episode 492 reward=-3204.0\n",
      "Episode 492 avg reward=-1.2816\n",
      "Episode 493\n",
      "Number visited 292\n",
      "Episode 493 exploratrion 0.13426666666666667\n",
      "Episode 493 total reward=-1.27\n",
      "Episode 493 reward=-3164.0\n",
      "Episode 493 avg reward=-1.2656\n",
      "Episode 494\n",
      "Number visited 384\n",
      "Episode 494 exploratrion 0.13413333333333333\n",
      "Episode 494 total reward=-1.27\n",
      "Episode 494 reward=-3184.0\n",
      "Episode 494 avg reward=-1.2736\n",
      "Episode 495\n",
      "Number visited 384\n",
      "Episode 495 exploratrion 0.134\n",
      "Episode 495 total reward=-1.27\n",
      "Episode 495 reward=-3104.0\n",
      "Episode 495 avg reward=-1.2416\n",
      "Episode 496\n",
      "Number visited 384\n",
      "Episode 496 exploratrion 0.1338666666666667\n",
      "Episode 496 total reward=-1.27\n",
      "Episode 496 reward=-3124.0\n",
      "Episode 496 avg reward=-1.2496\n",
      "Episode 497\n",
      "Number visited 384\n",
      "Episode 497 exploratrion 0.13373333333333334\n",
      "Episode 497 total reward=-1.27\n",
      "Episode 497 reward=-3148.0\n",
      "Episode 497 avg reward=-1.2592\n",
      "Episode 498\n",
      "Number visited 384\n",
      "Episode 498 exploratrion 0.1336\n",
      "Episode 498 total reward=-1.27\n",
      "Episode 498 reward=-3248.0\n",
      "Episode 498 avg reward=-1.2992\n",
      "Episode 499\n",
      "Number visited 384\n",
      "Episode 499 exploratrion 0.13346666666666668\n",
      "Episode 499 total reward=-1.27\n",
      "Episode 499 reward=-3220.0\n",
      "Episode 499 avg reward=-1.288\n",
      "Episode 500\n",
      "Number visited 384\n",
      "Episode 500 exploratrion 0.13333333333333336\n",
      "Episode 500 total reward=-1.27\n",
      "Episode 500 reward=-3080.0\n",
      "Episode 500 avg reward=-1.232\n",
      "Episode 501\n",
      "Number visited 384\n",
      "Episode 501 exploratrion 0.13319999999999999\n",
      "Episode 501 total reward=-1.27\n",
      "Episode 501 reward=-3200.0\n",
      "Episode 501 avg reward=-1.28\n",
      "Episode 502\n",
      "Number visited 384\n",
      "Episode 502 exploratrion 0.13306666666666667\n",
      "Episode 502 total reward=-1.27\n",
      "Episode 502 reward=-3136.0\n",
      "Episode 502 avg reward=-1.2544\n",
      "Episode 503\n",
      "Number visited 384\n",
      "Episode 503 exploratrion 0.13293333333333335\n",
      "Episode 503 total reward=-1.27\n",
      "Episode 503 reward=-3176.0\n",
      "Episode 503 avg reward=-1.2704\n",
      "Episode 504\n",
      "Number visited 384\n",
      "Episode 504 exploratrion 0.1328\n",
      "Episode 504 total reward=-1.26\n",
      "Episode 504 reward=-3080.0\n",
      "Episode 504 avg reward=-1.232\n",
      "Episode 505\n",
      "Number visited 384\n",
      "Episode 505 exploratrion 0.13266666666666665\n",
      "Episode 505 total reward=-1.27\n",
      "Episode 505 reward=-3244.0\n",
      "Episode 505 avg reward=-1.2975999999999999\n",
      "Episode 506\n",
      "Number visited 384\n",
      "Episode 506 exploratrion 0.13253333333333334\n",
      "Episode 506 total reward=-1.27\n",
      "Episode 506 reward=-3252.0\n",
      "Episode 506 avg reward=-1.3008000000000002\n",
      "Episode 507\n",
      "Number visited 384\n",
      "Episode 507 exploratrion 0.13240000000000002\n",
      "Episode 507 total reward=-1.27\n",
      "Episode 507 reward=-3072.0\n",
      "Episode 507 avg reward=-1.2288\n",
      "Episode 508\n",
      "Number visited 384\n",
      "Episode 508 exploratrion 0.13226666666666667\n",
      "Episode 508 total reward=-1.27\n",
      "Episode 508 reward=-3204.0\n",
      "Episode 508 avg reward=-1.2816\n",
      "Episode 509\n",
      "Number visited 384\n",
      "Episode 509 exploratrion 0.13213333333333332\n",
      "Episode 509 total reward=-1.27\n",
      "Episode 509 reward=-3248.0\n",
      "Episode 509 avg reward=-1.2992\n",
      "Episode 510\n",
      "Number visited 384\n",
      "Episode 510 exploratrion 0.132\n",
      "Episode 510 total reward=-1.27\n",
      "Episode 510 reward=-3192.0\n",
      "Episode 510 avg reward=-1.2768000000000002\n",
      "Episode 511\n",
      "Number visited 384\n",
      "Episode 511 exploratrion 0.1318666666666667\n",
      "Episode 511 total reward=-1.27\n",
      "Episode 511 reward=-3132.0\n",
      "Episode 511 avg reward=-1.2528\n",
      "Episode 512\n",
      "Number visited 384\n",
      "Episode 512 exploratrion 0.13173333333333334\n",
      "Episode 512 total reward=-1.27\n",
      "Episode 512 reward=-3088.0\n",
      "Episode 512 avg reward=-1.2351999999999999\n",
      "Episode 513\n",
      "Number visited 384\n",
      "Episode 513 exploratrion 0.1316\n",
      "Episode 513 total reward=-1.27\n",
      "Episode 513 reward=-3204.0\n",
      "Episode 513 avg reward=-1.2816\n",
      "Episode 514\n",
      "Number visited 384\n",
      "Episode 514 exploratrion 0.13146666666666668\n",
      "Episode 514 total reward=-1.27\n",
      "Episode 514 reward=-3248.0\n",
      "Episode 514 avg reward=-1.2992\n",
      "Episode 515\n",
      "Number visited 384\n",
      "Episode 515 exploratrion 0.13133333333333336\n",
      "Episode 515 total reward=-1.27\n",
      "Episode 515 reward=-3152.0\n",
      "Episode 515 avg reward=-1.2608\n",
      "Episode 516\n",
      "Number visited 384\n",
      "Episode 516 exploratrion 0.1312\n",
      "Episode 516 total reward=-1.27\n",
      "Episode 516 reward=-3156.0\n",
      "Episode 516 avg reward=-1.2624\n",
      "Episode 517\n",
      "Number visited 384\n",
      "Episode 517 exploratrion 0.13106666666666666\n",
      "Episode 517 total reward=-1.27\n",
      "Episode 517 reward=-3112.0\n",
      "Episode 517 avg reward=-1.2448000000000001\n",
      "Episode 518\n",
      "Number visited 384\n",
      "Episode 518 exploratrion 0.13093333333333335\n",
      "Episode 518 total reward=-1.27\n",
      "Episode 518 reward=-3220.0\n",
      "Episode 518 avg reward=-1.288\n",
      "Episode 519\n",
      "Number visited 384\n",
      "Episode 519 exploratrion 0.13080000000000003\n",
      "Episode 519 total reward=-1.27\n",
      "Episode 519 reward=-3168.0\n",
      "Episode 519 avg reward=-1.2671999999999999\n",
      "Episode 520\n",
      "Number visited 384\n",
      "Episode 520 exploratrion 0.13066666666666665\n",
      "Episode 520 total reward=-1.27\n",
      "Episode 520 reward=-3248.0\n",
      "Episode 520 avg reward=-1.2992\n",
      "Episode 521\n",
      "Number visited 292\n",
      "Episode 521 exploratrion 0.13053333333333333\n",
      "Episode 521 total reward=-1.27\n",
      "Episode 521 reward=-3196.0\n",
      "Episode 521 avg reward=-1.2784\n",
      "Episode 522\n",
      "Number visited 384\n",
      "Episode 522 exploratrion 0.13040000000000002\n",
      "Episode 522 total reward=-1.27\n",
      "Episode 522 reward=-3188.0\n",
      "Episode 522 avg reward=-1.2752\n",
      "Episode 523\n",
      "Number visited 384\n",
      "Episode 523 exploratrion 0.13026666666666667\n",
      "Episode 523 total reward=-1.27\n",
      "Episode 523 reward=-3148.0\n",
      "Episode 523 avg reward=-1.2592\n",
      "Episode 524\n",
      "Number visited 384\n",
      "Episode 524 exploratrion 0.13013333333333332\n",
      "Episode 524 total reward=-1.27\n",
      "Episode 524 reward=-3084.0\n",
      "Episode 524 avg reward=-1.2336\n",
      "Episode 525\n",
      "Number visited 384\n",
      "Episode 525 exploratrion 0.13\n",
      "Episode 525 total reward=-1.26\n",
      "Episode 525 reward=-3072.0\n",
      "Episode 525 avg reward=-1.2288\n",
      "Episode 526\n",
      "Number visited 384\n",
      "Episode 526 exploratrion 0.12986666666666669\n",
      "Episode 526 total reward=-1.26\n",
      "Episode 526 reward=-3088.0\n",
      "Episode 526 avg reward=-1.2351999999999999\n",
      "Episode 527\n",
      "Number visited 338\n",
      "Episode 527 exploratrion 0.12973333333333334\n",
      "Episode 527 total reward=-1.26\n",
      "Episode 527 reward=-3110.0\n",
      "Episode 527 avg reward=-1.244\n",
      "Episode 528\n",
      "Number visited 384\n",
      "Episode 528 exploratrion 0.1296\n",
      "Episode 528 total reward=-1.26\n",
      "Episode 528 reward=-3164.0\n",
      "Episode 528 avg reward=-1.2656\n",
      "Episode 529\n",
      "Number visited 384\n",
      "Episode 529 exploratrion 0.12946666666666667\n",
      "Episode 529 total reward=-1.26\n",
      "Episode 529 reward=-3172.0\n",
      "Episode 529 avg reward=-1.2688\n",
      "Episode 530\n",
      "Number visited 384\n",
      "Episode 530 exploratrion 0.12933333333333336\n",
      "Episode 530 total reward=-1.26\n",
      "Episode 530 reward=-3152.0\n",
      "Episode 530 avg reward=-1.2608\n",
      "Episode 531\n",
      "Number visited 384\n",
      "Episode 531 exploratrion 0.1292\n",
      "Episode 531 total reward=-1.26\n",
      "Episode 531 reward=-3160.0\n",
      "Episode 531 avg reward=-1.264\n",
      "Episode 532\n",
      "Number visited 292\n",
      "Episode 532 exploratrion 0.12906666666666666\n",
      "Episode 532 total reward=-1.27\n",
      "Episode 532 reward=-3300.0\n",
      "Episode 532 avg reward=-1.32\n",
      "Episode 533\n",
      "Number visited 384\n",
      "Episode 533 exploratrion 0.12893333333333334\n",
      "Episode 533 total reward=-1.27\n",
      "Episode 533 reward=-3140.0\n",
      "Episode 533 avg reward=-1.256\n",
      "Episode 534\n",
      "Number visited 384\n",
      "Episode 534 exploratrion 0.12880000000000003\n",
      "Episode 534 total reward=-1.27\n",
      "Episode 534 reward=-3188.0\n",
      "Episode 534 avg reward=-1.2752\n",
      "Episode 535\n",
      "Number visited 384\n",
      "Episode 535 exploratrion 0.12866666666666665\n",
      "Episode 535 total reward=-1.27\n",
      "Episode 535 reward=-3220.0\n",
      "Episode 535 avg reward=-1.288\n",
      "Episode 536\n",
      "Number visited 384\n",
      "Episode 536 exploratrion 0.12853333333333333\n",
      "Episode 536 total reward=-1.27\n",
      "Episode 536 reward=-3236.0\n",
      "Episode 536 avg reward=-1.2944\n",
      "Episode 537\n",
      "Number visited 384\n",
      "Episode 537 exploratrion 0.12840000000000001\n",
      "Episode 537 total reward=-1.27\n",
      "Episode 537 reward=-3184.0\n",
      "Episode 537 avg reward=-1.2736\n",
      "Episode 538\n",
      "Number visited 384\n",
      "Episode 538 exploratrion 0.12826666666666667\n",
      "Episode 538 total reward=-1.27\n",
      "Episode 538 reward=-3228.0\n",
      "Episode 538 avg reward=-1.2912000000000001\n",
      "Episode 539\n",
      "Number visited 384\n",
      "Episode 539 exploratrion 0.12813333333333332\n",
      "Episode 539 total reward=-1.27\n",
      "Episode 539 reward=-3200.0\n",
      "Episode 539 avg reward=-1.28\n",
      "Episode 540\n",
      "Number visited 292\n",
      "Episode 540 exploratrion 0.128\n",
      "Episode 540 total reward=-1.28\n",
      "Episode 540 reward=-3312.0\n",
      "Episode 540 avg reward=-1.3248\n",
      "Episode 541\n",
      "Number visited 384\n",
      "Episode 541 exploratrion 0.12786666666666668\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jacob\\Desktop\\nbavy\\navy research.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000002?line=239'>240</a>\u001b[0m \u001b[39mif\u001b[39;00m episode \u001b[39m>\u001b[39m \u001b[39m100\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000002?line=240'>241</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(step):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000002?line=241'>242</a>\u001b[0m         maddpg\u001b[39m.\u001b[39;49mupdate()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000002?line=243'>244</a>\u001b[0m     \u001b[39m# show reward\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000002?line=244'>245</a>\u001b[0m smoothed_total_reward \u001b[39m=\u001b[39m smoothed_total_reward \u001b[39m*\u001b[39m \u001b[39m0.9\u001b[39m \u001b[39m+\u001b[39m totalAvgReward \u001b[39m*\u001b[39m \u001b[39m0.1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\frame\\algorithms\\maddpg.py:570\u001b[0m, in \u001b[0;36mMADDPG.update\u001b[1;34m(self, update_value, update_policy, update_target, concatenate_samples)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=567'>568</a>\u001b[0m ensemble_batch \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=568'>569</a>\u001b[0m \u001b[39mfor\u001b[39;00m a_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactors)):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=569'>570</a>\u001b[0m     batch_size_, batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffers[a_idx]\u001b[39m.\u001b[39;49msample_batch(\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=570'>571</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=571'>572</a>\u001b[0m         concatenate_samples,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=572'>573</a>\u001b[0m         sample_method\u001b[39m=\u001b[39;49msample_methods[e_idx],\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=573'>574</a>\u001b[0m         sample_attrs\u001b[39m=\u001b[39;49m[\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=574'>575</a>\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mstate\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=575'>576</a>\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39maction\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=576'>577</a>\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mreward\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=577'>578</a>\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mnext_state\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=578'>579</a>\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mterminal\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=579'>580</a>\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=580'>581</a>\u001b[0m         ],\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=581'>582</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=582'>583</a>\u001b[0m     ensemble_batch\u001b[39m.\u001b[39mappend(batch)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=583'>584</a>\u001b[0m     \u001b[39massert\u001b[39;00m batch_size_ \u001b[39m==\u001b[39m batch_size\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\frame\\buffers\\buffer.py:221\u001b[0m, in \u001b[0;36mBuffer.sample_batch\u001b[1;34m(self, batch_size, concatenate, device, sample_method, sample_attrs, additional_concat_attrs, *_, **__)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=215'>216</a>\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=216'>217</a>\u001b[0m     device \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_device\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=218'>219</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=219'>220</a>\u001b[0m     batch_size,\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=220'>221</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpost_process_batch(\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=221'>222</a>\u001b[0m         batch, device, concatenate, sample_attrs, additional_concat_attrs\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=222'>223</a>\u001b[0m     ),\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=223'>224</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\frame\\buffers\\buffer.py:264\u001b[0m, in \u001b[0;36mBuffer.post_process_batch\u001b[1;34m(cls, batch, device, concatenate, sample_attrs, additional_concat_attrs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=260'>261</a>\u001b[0m     used_keys\u001b[39m.\u001b[39mappend(attr)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=261'>262</a>\u001b[0m \u001b[39melif\u001b[39;00m attr \u001b[39min\u001b[39;00m sub_attr:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=262'>263</a>\u001b[0m     result\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=263'>264</a>\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmake_tensor_from_batch(\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=264'>265</a>\u001b[0m             [item[attr] \u001b[39mfor\u001b[39;49;00m item \u001b[39min\u001b[39;49;00m batch], device, concatenate\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=265'>266</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=266'>267</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=267'>268</a>\u001b[0m     used_keys\u001b[39m.\u001b[39mappend(attr)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=268'>269</a>\u001b[0m \u001b[39melif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/buffers/buffer.py?line=269'>270</a>\u001b[0m     \u001b[39m# select custom keys\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\machin\\frame\\algorithms\\maddpg.py:30\u001b[0m, in \u001b[0;36mSHMBuffer.make_tensor_from_batch\u001b[1;34m(batch, device, concatenate)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=27'>28</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=28'>29</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=29'>30</a>\u001b[0m         result \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mtensor(batch, device\u001b[39m=\u001b[39;49mdevice)\u001b[39m.\u001b[39;49mview(batch_size, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=30'>31</a>\u001b[0m         result\u001b[39m.\u001b[39mshare_memory_()\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/machin/frame/algorithms/maddpg.py?line=31'>32</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from machin.frame.algorithms import MADDPG \n",
    "\n",
    "from machin.frame.algorithms import MADDPG\n",
    "from machin.utils.logging import default_logger as logger\n",
    "from copy import deepcopy\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import machin.model.nets as net\n",
    "#https://github.com/instadeepai/Mava\n",
    "#https://github.com/PHRABAL/Tennis-MADDPG-PER/blob/master/MADDPG_PER.ipynb\n",
    "#Same, playing around with the initialization, parameters, optimizers and normalization really helped Here is the article how I fought it:\n",
    "\n",
    "#TL,DR: critic init sould match the reward distro. Minmax values should be meaningful. Delayed update for actor is good, so is gradient clipping and weight decay. \\\n",
    "# Use Adamw/RAdam/Ranger as an optimizer.\n",
    "\n",
    "#https://towardsdatascience.com/reinforcement-learning-ddpg-and-td3-for-news-recommendation-d3cddec26011?source=activity---post_recommended\n",
    "\n",
    "# Important note:\n",
    "# In order to successfully run the environment, please git clone the project\n",
    "# then run:\n",
    "#    pip install -e ./test_lib/multiagent-particle-envs/\n",
    "# in project root directory\n",
    "\n",
    "\n",
    "def create_env(env_name):\n",
    "    from multiagent.environment import MultiAgentEnv\n",
    "    import multiagent.scenarios as scenarios\n",
    "\n",
    "    # load scenario from script\n",
    "    scenario = scenarios.load(env_name + \".py\").Scenario()\n",
    "    # create world\n",
    "    world = scenario.make_world()\n",
    "    # create multiagent environment\n",
    "    env = MultiAgentEnv(\n",
    "        world,\n",
    "        scenario.reset_world,\n",
    "        scenario.reward,\n",
    "        scenario.observation,\n",
    "        info_callback=None,\n",
    "        shared_viewer=False,\n",
    "    )\n",
    "    return env\n",
    "\n",
    "\n",
    "# configurations\n",
    "#env = create_env(\"simple_spread\")\n",
    "env = Sea(50,50)\n",
    "env.discrete_action_input = True\n",
    "\n",
    "import gym.spaces as spaces\n",
    "obs = spaces.Box(low=-2, high=2, shape=(50,50), dtype=np.int32)\n",
    "action_space = spaces.Box(low=-1, high=1, shape= (2,), dtype=np.int32)\n",
    "\n",
    "observe_dim = 50*50#env.observation_space[0].shape[0]\n",
    "action_num = 4#action_space[0].n\n",
    "max_episodes = 1500\n",
    "max_steps = 200\n",
    "# number of agents in env, fixed, do not change\n",
    "agent_num = 5\n",
    "solved_reward = -15\n",
    "solved_repeat = 5\n",
    "exploration = 0.2\n",
    "\n",
    "\n",
    "print(observe_dim)\n",
    "print(action_num)\n",
    "\n",
    "\n",
    "class weightConstraint(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self,module):\n",
    "        if hasattr(module,'weight'):\n",
    "            w=module.weight.data\n",
    "            w=w.clamp(0.5,0.7)\n",
    "            module.weight.data=w\n",
    "\n",
    "# model definition\n",
    "class ActorDiscrete(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(state_dim, 1024).to(device=\"cuda\")\n",
    "        self.fc2 = nn.Linear(1024, 1024).to(device=\"cuda\")\n",
    "        self.fc3 = nn.Linear(1024, 512).to(device=\"cuda\")\n",
    "        self.fc4 = nn.Linear(512, 128).to(device=\"cuda\")\n",
    "        self.fc5 = nn.Linear(128, 64).to(device=\"cuda\")\n",
    "        self.fc6 = nn.Linear(64, 32).to(device=\"cuda\")\n",
    "        \n",
    "        temp = nn.Linear(32, action_dim)\n",
    "        temp.weight.data.fill_(3e-1)\n",
    "        self.fc7 =  temp.to(device=\"cuda\")\n",
    "\n",
    "    def forward(self, state):\n",
    "        #state.to(device=\"cuda\")\n",
    "        a = t.relu(self.fc1(state))\n",
    "        a = t.relu(self.fc2(a))\n",
    "        a = t.relu(self.fc3(a))\n",
    "        a = t.relu(self.fc4(a))\n",
    "        a = t.relu(self.fc5(a))\n",
    "        a = t.relu(self.fc6(a))\n",
    "        a = t.softmax(self.fc7(a), dim=1)\n",
    "        return a\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        # This critic implementation is shared by the prey(DDPG) and\n",
    "        # predators(MADDPG)\n",
    "        # Note: For MADDPG\n",
    "        #       state_dim is the dimension of all states from all agents.\n",
    "        #       action_dim is the dimension of all actions from all agents.\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(state_dim + action_dim, 1024).to(device=\"cuda\")\n",
    "        self.fc2 = nn.Linear(1024, 1024).to(device=\"cuda\")\n",
    "        self.fc3 = nn.Linear(1024, 512).to(device=\"cuda\")\n",
    "        self.fc4 = nn.Linear(512, 128).to(device=\"cuda\")\n",
    "        self.fc5 = nn.Linear(128, 64).to(device=\"cuda\")\n",
    "        self.fc6 = nn.Linear(64, 32).to(device=\"cuda\")\n",
    "        temp = nn.Linear(32, 1)\n",
    "        temp.weight.data.fill_(3e-5)\n",
    "        self.fc7 =  temp.to(device=\"cuda\")\n",
    "\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        state_action = t.cat([state, action], 1)\n",
    "        #state_action = state_action.cuda()\n",
    "        q = t.relu(self.fc1(state_action))\n",
    "        q = t.relu(self.fc2(q))\n",
    "        q = t.relu(self.fc3(q))\n",
    "        q = t.relu(self.fc4(q))\n",
    "        q = t.relu(self.fc5(q))\n",
    "        q = t.relu(self.fc6(q))\n",
    "        q = self.fc7(q)\n",
    "        #try clamping the reward\n",
    "        #q = t.clamp(q, -200, 200)\n",
    "        return q\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    actor = ActorDiscrete(observe_dim, action_num)\n",
    "    critic = Critic(observe_dim * agent_num, action_num * agent_num)\n",
    "\n",
    "    print(critic.fc3.weight)\n",
    "    \n",
    "    net.static_module_wrapper(actor, \"cuda\", \"cuda\")\n",
    "    net.static_module_wrapper(critic, \"cuda\", \"cuda\")\n",
    "    maddpg = MADDPG(\n",
    "        [deepcopy(actor) for _ in range(agent_num)],\n",
    "        [deepcopy(actor) for _ in range(agent_num)],\n",
    "        [deepcopy(critic) for _ in range(agent_num)],\n",
    "        [deepcopy(critic) for _ in range(agent_num)],\n",
    "        t.optim.Adam,\n",
    "        #t.optim.RAdam,\n",
    "        #t.optim.NAdam,\n",
    "        nn.MSELoss(reduction=\"mean\"),\n",
    "        critic_visible_actors=[list(range(agent_num))] * agent_num,\n",
    "        #replay_device=\"cuda\",\n",
    "        discount = 0.99,\n",
    "        replay_size=20000,\n",
    "        #actor_learning_rate=0.00005,\n",
    "        #critic_learning_rate=0.0005,\n",
    "        #update_rate=0.0005\n",
    "    )\n",
    "    \n",
    "\n",
    "    episode, step, reward_fulfilled = 0, 0, 0\n",
    "    smoothed_total_reward = 0\n",
    "\n",
    "    while episode < max_episodes:\n",
    "        episode += 1\n",
    "        total_reward = 0\n",
    "        terminal = False\n",
    "        step = 0\n",
    "        states = [\n",
    "            t.tensor(st, dtype=t.float32).view(1, observe_dim) for st in env.reset()\n",
    "        ]\n",
    "        tmp_observations_list = [[] for _ in range(agent_num)]\n",
    "\n",
    "        while not terminal and step <= max_steps:\n",
    "            step += 1\n",
    "            with t.no_grad():\n",
    "                old_states = states\n",
    "                # agent model inference\n",
    "                results = maddpg.act_with_noise(\n",
    "                    [{\"state\": st} for st in states], mode = \"uniform\", noise_param=(0, exploration)\n",
    "                )\n",
    "                #actions = [int(r[0]) for r in results]\n",
    "                result = []\n",
    "                for action, *others in results:\n",
    "                    action = t.reshape(action, (1, 4))\n",
    "                    batch_size = action.shape[0]\n",
    "                    action_disc = t.argmax(action, dim=1).view(batch_size, 1)\n",
    "                    result.append((action_disc, action, *others))\n",
    "\n",
    "\n",
    "                actions = [int(r[0]) for r in result]\n",
    "\n",
    "                action_probs = [r[1] for r in result]\n",
    "                states, rewards, terminals, _ = env.step(actions)\n",
    "                states = [\n",
    "                    t.tensor(st, dtype=t.float32).view(1, observe_dim) for st in states\n",
    "                ]\n",
    "                total_reward += float(sum(rewards))# / agent_num\n",
    "\n",
    "                for tmp_observations, ost, act, st, rew, term in zip(\n",
    "                    tmp_observations_list,\n",
    "                    old_states,\n",
    "                    action_probs,\n",
    "                    states,\n",
    "                    rewards,\n",
    "                    terminals,\n",
    "                ):\n",
    "                    tmp_observations.append(\n",
    "                        {\n",
    "                            \"state\": {\"state\": ost},\n",
    "                            \"action\": {\"action\": act},\n",
    "                            \"next_state\": {\"state\": st},\n",
    "                            \"reward\": float(rew),\n",
    "                            \"terminal\": term or step == max_steps,\n",
    "                        }\n",
    "                    )\n",
    "        maddpg.store_episodes(tmp_observations_list)\n",
    "        # total reward is divided by steps here, since:\n",
    "        # \"Agents are rewarded based on minimum agent distance\n",
    "        #  to each landmark, penalized for collisions\"\n",
    "        #total_reward /= \n",
    "        totalAvgReward = total_reward / 50 / 50#step\n",
    "        totalSpaceVisited = np.sum(env.seen)\n",
    "        exploration = -episode / max_episodes * 0.2 + 0.2\n",
    "        #maddpg.discount = episode / max_episodes *0.29 + 0.7\n",
    "        print(f\"Episode {episode}\")\n",
    "        print(f\"Number visited {totalSpaceVisited}\")\n",
    "        print(f\"Episode {episode} exploratrion {exploration}\")\n",
    "        # update, update more if episode is longer, else less\n",
    "        if episode > 100:\n",
    "            for _ in range(step):\n",
    "                maddpg.update()\n",
    "\n",
    "            # show reward\n",
    "        smoothed_total_reward = smoothed_total_reward * 0.9 + totalAvgReward * 0.1\n",
    "        print(f\"Episode {episode} total reward={smoothed_total_reward:.2f}\")\n",
    "        print(f\"Episode {episode} reward={total_reward}\")\n",
    "        print(f\"Episode {episode} avg reward={totalAvgReward}\")\n",
    "        \n",
    "        #if smoothed_total_reward > solved_reward and episode > 100:\n",
    "        #    reward_fulfilled += 1\n",
    "        #    if reward_fulfilled >= solved_repeat:\n",
    "        #        logger.info(\"Environment solved!\")\n",
    "        #        exit(0)\n",
    "        #else:\n",
    "        #    reward_fulfilled = 0\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "Episode 1 total reward=-1.27\n",
      "Episode 1 reward=-3096.0\n",
      "Episode 1 avg reward=-1.2384\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MAPPO https://github.com/marlbenchmark/on-policy\n",
    "\n",
    "episode = 0\n",
    "while episode < 1:\n",
    "    episode += 1\n",
    "    total_reward = 0\n",
    "    terminal = False\n",
    "    step = 0\n",
    "    states = [\n",
    "        t.tensor(st, dtype=t.float32).view(1, observe_dim) for st in env.reset()\n",
    "    ]\n",
    "    tmp_observations_list = [[] for _ in range(agent_num)]\n",
    "\n",
    "    while not terminal and step <= max_steps:\n",
    "        step += 1\n",
    "        with t.no_grad():\n",
    "            old_states = states\n",
    "            # agent model inference\n",
    "            results = maddpg.act_discrete(\n",
    "                [{\"state\": st} for st in states]\n",
    "            )\n",
    "            actions = [int(r[0]) for r in results]\n",
    "            action_probs = [r[1] for r in results]\n",
    "            states, rewards, terminals, _ = env.step(actions)\n",
    "            states = [\n",
    "                t.tensor(st, dtype=t.float32).view(1, observe_dim) for st in states\n",
    "            ]\n",
    "            total_reward += float(sum(rewards))# / agent_num\n",
    "            #plt.matshow(np.reshape(states[0], (50,50)) )\n",
    "            for tmp_observations, ost, act, st, rew, term in zip(\n",
    "                tmp_observations_list,\n",
    "                old_states,\n",
    "                action_probs,\n",
    "                states,\n",
    "                rewards,\n",
    "                terminals,\n",
    "            ):\n",
    "                tmp_observations.append(\n",
    "                    {\n",
    "                        \"state\": {\"state\": ost},\n",
    "                        \"action\": {\"action\": act},\n",
    "                        \"next_state\": {\"state\": st},\n",
    "                        \"reward\": float(rew),\n",
    "                        \"terminal\": term or step == max_steps,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    #maddpg.store_episodes(tmp_observations_list)\n",
    "    env.display()\n",
    "    plt.matshow(env.seen)\n",
    "    # total reward is divided by steps here, since:\n",
    "    # \"Agents are rewarded based on minimum agent distance\n",
    "    #  to each landmark, penalized for collisions\"\n",
    "    #total_reward /= \n",
    "    totalAvgReward = total_reward / 50 / 50#step\n",
    "    maddpg.discount = 0.99#episode / max_episodes *0.7 + 0.3\n",
    "    print(f\"Episode {episode}\")\n",
    "    # update, update more if episode is longer, else less\n",
    "    #if episode > 100:\n",
    "    #    for _ in range(step):\n",
    "    #        maddpg.update()\n",
    "\n",
    "        # show reward\n",
    "    smoothed_total_reward = smoothed_total_reward * 0.9 + totalAvgReward * 0.1\n",
    "    print(f\"Episode {episode} total reward={smoothed_total_reward:.2f}\")\n",
    "    print(f\"Episode {episode} reward={total_reward}\")\n",
    "    print(f\"Episode {episode} avg reward={totalAvgReward}\")\n",
    "    \n",
    "    #if smoothed_total_reward > solved_reward and episode > 100:\n",
    "    #    reward_fulfilled += 1\n",
    "    #    if reward_fulfilled >= solved_repeat:\n",
    "    #        logger.info(\"Environment solved!\")\n",
    "    #        exit(0)\n",
    "    #else:\n",
    "    #    reward_fulfilled = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from elegantrl.agents.AgentBase import AgentBase\n",
    "from elegantrl.agents.net import Actor, Critic\n",
    "from elegantrl.agents.AgentDDPG import AgentDDPG\n",
    "\n",
    "class AgentMADDPG(AgentBase):\n",
    "    \"\"\"\n",
    "    Bases: ``AgentBase``\n",
    "    Multi-Agent DDPG algorithm. “Multi-Agent Actor-Critic for Mixed Cooperative-Competitive”. R Lowe. et al.. 2017.\n",
    "    :param net_dim[int]: the dimension of networks (the width of neural networks)\n",
    "    :param state_dim[int]: the dimension of state (the number of state vector)\n",
    "    :param action_dim[int]: the dimension of action (the number of discrete action)\n",
    "    :param learning_rate[float]: learning rate of optimizer\n",
    "    :param gamma[float]: learning rate of optimizer\n",
    "    :param n_agents[int]: number of agents\n",
    "    :param if_per_or_gae[bool]: PER (off-policy) or GAE (on-policy) for sparse reward\n",
    "    :param env_num[int]: the env number of VectorEnv. env_num == 1 means don't use VectorEnv\n",
    "    :param agent_id[int]: if the visible_gpu is '1,9,3,4', agent_id=1 means (1,9,4,3)[agent_id] == 9\n",
    "    \"\"\"\n",
    "\n",
    "    #def __init__(self):\n",
    "        \n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        net_dim,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        learning_rate=1e-4,\n",
    "        gamma=0.95,\n",
    "        n_agents=1,\n",
    "        if_use_per=False,\n",
    "        env_num=1,\n",
    "        agent_id=0,\n",
    "        gpu_id\n",
    "    ):\n",
    "        #self.ClassAct = Actor\n",
    "        #self.ClassCri = Critic\n",
    "        #self.if_use_cri_target = True\n",
    "        #self.if_use_act_target = True\n",
    "        #super().__init__(net_dim=net_dim, state_dim=state_dim, action_dim=action_dim)\n",
    "        \n",
    "        self.__name__ = \"MADDPG\"\n",
    "        self.agents = [AgentDDPG(net_dim=net_dim, state_dim=state_dim,action_dim=action_dim, gpu_id=gpu_id) for i in range(n_agents)]\n",
    "        self.explore_env = self.explore_one_env\n",
    "        self.if_off_policy = True\n",
    "        self.n_agents = n_agents\n",
    "\n",
    "        #for i in range(self.n_agents):\n",
    "        #    self.agents[i].init(\n",
    "        #        net_dim,\n",
    "        #        state_dim,\n",
    "        #        action_dim,\n",
    "        #        learning_rate=1e-4,\n",
    "        #        n_agents=self.n_agents,\n",
    "        #        if_use_per=False,\n",
    "        #        env_num=1,\n",
    "        #        agent_id=0,\n",
    "        #    )\n",
    "        self.n_states = state_dim\n",
    "        self.n_actions = action_dim\n",
    "\n",
    "        self.batch_size = net_dim\n",
    "        self.gamma = gamma\n",
    "        self.update_tau = 0\n",
    "        self.device = torch.device(\n",
    "            f\"cuda:{agent_id}\"\n",
    "            if (torch.cuda.is_available() and (agent_id >= 0))\n",
    "            else \"cpu\"\n",
    "        )\n",
    "\n",
    "    def update_agent(self, rewards, dones, actions, observations, next_obs, index):\n",
    "        \"\"\"\n",
    "        Update the single agent neural networks, called by update_net.\n",
    "        :param rewards: reward list of the sampled buffer\n",
    "        :param dones: done list of the sampled buffer\n",
    "        :param actions: action list of the sampled buffer\n",
    "        :param observations: observation list of the sampled buffer\n",
    "        :param next_obs: next_observation list of the sample buffer\n",
    "        :param index: ID of the agent\n",
    "        \"\"\"\n",
    "        curr_agent = self.agents[index]\n",
    "        curr_agent.cri_optim.zero_grad()\n",
    "        all_target_actions = []\n",
    "        for i in range(self.n_agents):\n",
    "            if i == index:\n",
    "                all_target_actions.append(curr_agent.act_target(next_obs[:, index]))\n",
    "            if i != index:\n",
    "                action = self.agents[i].act_target(next_obs[:, i])\n",
    "                all_target_actions.append(action)\n",
    "        action_target_all = (\n",
    "            torch.cat(all_target_actions, dim=1)\n",
    "            .to(self.device)\n",
    "            .reshape(actions.shape[0], actions.shape[1] * actions.shape[2])\n",
    "        )\n",
    "\n",
    "        target_value = rewards[:, index] + self.gamma * curr_agent.cri_target(\n",
    "            next_obs.reshape(next_obs.shape[0], next_obs.shape[1] * next_obs.shape[2]),\n",
    "            action_target_all,\n",
    "        ).detach().squeeze(dim=1)\n",
    "        actual_value = curr_agent.cri(\n",
    "            observations.reshape(\n",
    "                next_obs.shape[0], next_obs.shape[1] * next_obs.shape[2]\n",
    "            ),\n",
    "            actions.reshape(actions.shape[0], actions.shape[1] * actions.shape[2]),\n",
    "        ).squeeze(dim=1)\n",
    "        vf_loss = curr_agent.loss_td(actual_value, target_value.detach())\n",
    "        curr_agent.act_optim.zero_grad()\n",
    "        curr_pol_out = curr_agent.act(observations[:, index])\n",
    "        curr_pol_vf_in = curr_pol_out\n",
    "        all_pol_acs = []\n",
    "        for i in range(self.n_agents):\n",
    "            if i == index:\n",
    "                all_pol_acs.append(curr_pol_vf_in)\n",
    "            else:\n",
    "                all_pol_acs.append(actions[:, i])\n",
    "        pol_loss = -torch.mean(\n",
    "            curr_agent.cri(\n",
    "                observations.reshape(\n",
    "                    observations.shape[0], observations.shape[1] * observations.shape[2]\n",
    "                ),\n",
    "                torch.cat(all_pol_acs, dim=1)\n",
    "                .to(self.device)\n",
    "                .reshape(actions.shape[0], actions.shape[1] * actions.shape[2]),\n",
    "            )\n",
    "        )\n",
    "        curr_agent.act_optim.zero_grad()\n",
    "        pol_loss.backward()\n",
    "        curr_agent.act_optim.step()\n",
    "        curr_agent.cri_optim.zero_grad()\n",
    "        vf_loss.backward()\n",
    "        curr_agent.cri_optim.step()\n",
    "\n",
    "    def update_net(self, buffer, batch_size, repeat_times, soft_update_tau):\n",
    "        \"\"\"\n",
    "        Update the neural networks by sampling batch data from ``ReplayBuffer``.\n",
    "        :param buffer: the ReplayBuffer instance that stores the trajectories.\n",
    "        :param batch_size: the size of batch data for Stochastic Gradient Descent (SGD).\n",
    "        :param repeat_times: the re-using times of each trajectory.\n",
    "        :param soft_update_tau: the soft update parameter.\n",
    "        \"\"\"\n",
    "        buffer.update_now_len()\n",
    "        self.batch_size = batch_size\n",
    "        self.update_tau = soft_update_tau\n",
    "        rewards, dones, actions, observations, next_obs = buffer.sample_batch(\n",
    "            self.batch_size\n",
    "        )\n",
    "        for index in range(self.n_agents):\n",
    "            self.update_agent(rewards, dones, actions, observations, next_obs, index)\n",
    "\n",
    "        for agent in self.agents:\n",
    "            self.soft_update(agent.cri_target, agent.cri, self.update_tau)\n",
    "            self.soft_update(agent.act_target, agent.act, self.update_tau)\n",
    "\n",
    "        return\n",
    "\n",
    "    def explore_one_env(self, env, target_step) -> list:\n",
    "        \"\"\"\n",
    "        Exploring the environment for target_step.\n",
    "        param env: the Environment instance to be explored.\n",
    "        param target_step: target steps to explore.\n",
    "        \"\"\"\n",
    "        traj_temp = []\n",
    "        k = 0\n",
    "        for _ in range(target_step):\n",
    "            k += 1\n",
    "            actions = []\n",
    "            for i in range(self.n_agents):\n",
    "                action = self.agents[i].select_actions(self.states[i])\n",
    "                actions.append(action)\n",
    "            # print(actions)\n",
    "            next_s, reward, done, _ = env.step(actions)\n",
    "            traj_temp.append((self.states, reward, done, actions))\n",
    "            global_done = all(done[i] is True for i in range(self.n_agents))\n",
    "            if global_done or k > 100:\n",
    "                state = env.reset()\n",
    "                k = 0\n",
    "            else:\n",
    "                state = next_s\n",
    "        self.states = state\n",
    "        return traj_temp\n",
    "\n",
    "    def select_actions(self, states):\n",
    "        \"\"\"\n",
    "        Select continuous actions for exploration\n",
    "        :param state: states.shape==(n_agents,batch_size, state_dim, )\n",
    "        :return: actions.shape==(n_agents,batch_size, action_dim, ),  -1 < action < +1\n",
    "        \"\"\"\n",
    "        actions = []\n",
    "        for i in range(self.n_agents):\n",
    "            action = self.agents[i].select_actions(states[i])\n",
    "            actions.append(action)\n",
    "        return actions\n",
    "\n",
    "    def save_or_load_agent(self, cwd, if_save):\n",
    "        \"\"\"\n",
    "        save or load training files for Agent\n",
    "        :param cwd: Current Working Directory. ElegantRL save training files in CWD.\n",
    "        :param if_save: True: save files. False: load files.\n",
    "        \"\"\"\n",
    "        for i in range(self.n_agents):\n",
    "            self.agents[i].save_or_load_agent(cwd + \"/\" + str(i), if_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Arguments Remove cwd: ./Sea_MADDPG_0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AgentMADDPG.__init__() got an unexpected keyword argument 'gpu_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jacob\\Desktop\\nbavy\\navy research.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000004?line=40'>41</a>\u001b[0m args\u001b[39m.\u001b[39mlearner_gpus \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000004?line=42'>43</a>\u001b[0m \u001b[39m#train_agent(args)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000004?line=43'>44</a>\u001b[0m \u001b[39m#evaluate_agent(args)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jacob/Desktop/nbavy/navy%20research.ipynb#ch0000004?line=45'>46</a>\u001b[0m train_and_evaluate(args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\elegantrl\\train\\run.py:22\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=18'>19</a>\u001b[0m \u001b[39m\"\"\"init\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=19'>20</a>\u001b[0m env \u001b[39m=\u001b[39m build_env(args\u001b[39m.\u001b[39menv, args\u001b[39m.\u001b[39menv_func, args\u001b[39m.\u001b[39menv_args)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=21'>22</a>\u001b[0m agent \u001b[39m=\u001b[39m init_agent(args, gpu_id, env)\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=22'>23</a>\u001b[0m buffer \u001b[39m=\u001b[39m init_buffer(args, gpu_id)\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=23'>24</a>\u001b[0m evaluator \u001b[39m=\u001b[39m init_evaluator(args, gpu_id)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\elegantrl\\train\\run.py:64\u001b[0m, in \u001b[0;36minit_agent\u001b[1;34m(args, gpu_id, env)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=62'>63</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit_agent\u001b[39m(args, gpu_id, env\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=63'>64</a>\u001b[0m     agent \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39;49magent(\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=64'>65</a>\u001b[0m         args\u001b[39m.\u001b[39;49mnet_dim, args\u001b[39m.\u001b[39;49mstate_dim, args\u001b[39m.\u001b[39;49maction_dim, gpu_id\u001b[39m=\u001b[39;49mgpu_id, args\u001b[39m=\u001b[39;49margs\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=65'>66</a>\u001b[0m     )\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=66'>67</a>\u001b[0m     agent\u001b[39m.\u001b[39msave_or_load_agent(args\u001b[39m.\u001b[39mcwd, if_save\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Jacob/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/elegantrl/train/run.py?line=68'>69</a>\u001b[0m     \u001b[39mif\u001b[39;00m env \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: AgentMADDPG.__init__() got an unexpected keyword argument 'gpu_id'"
     ]
    }
   ],
   "source": [
    "#from elegantrl_helloworld.config import Arguments\n",
    "#from elegantrl_helloworld.run import train_agent, evaluate_agent\n",
    "#from elegantrl_helloworld.env import get_gym_env_args\n",
    "#from elegantrl.agents import AgentMADDPG\n",
    "\n",
    "\n",
    "from elegantrl.train.run import train_and_evaluate\n",
    "\n",
    "from elegantrl.train.config import Arguments\n",
    "from elegantrl.train.run import *\n",
    "\n",
    "agent = AgentMADDPG#AgentMADDPG(net_dim = 2**7, state_dim=50*50, action_dim=4, n_agents=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env = Sea()#50,50)\n",
    "\n",
    "env_func = Sea\n",
    "\n",
    "#env_args = get_gym_env_args(env, if_print=True)\n",
    "args = Arguments(agent, env=env)\n",
    "\n",
    "args.if_discrete = True\n",
    "\n",
    "'''reward shaping'''\n",
    "args.reward_scale = 2 ** 0\n",
    "args.gamma = 0.99\n",
    "\n",
    "'''network update'''\n",
    "args.target_step = args.max_step // 2\n",
    "args.net_dim = 2 ** 7\n",
    "args.batch_size = 2 ** 7\n",
    "args.repeat_times = 2 ** 0\n",
    "args.explore_noise = 0.1\n",
    "\n",
    "'''evaluate'''\n",
    "args.eval_gap = 2 ** 7\n",
    "args.eval_times = 2 ** 4\n",
    "args.break_step = int(4e5)\n",
    "args.learner_gpus = 0\n",
    "\n",
    "#train_agent(args)\n",
    "#evaluate_agent(args)\n",
    "\n",
    "train_and_evaluate(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2022-05-30 19:33:56,991] <WARNING>:default_logger:Save name for module \"{r}\" is not specified, module name is used.\u001b[0m\n",
      "\u001b[33m[2022-05-30 19:33:57,163] <WARNING>:default_logger:Save name for module \"{r}\" is not specified, module name is used.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "maddpg.save(\"ModelCheckpoints\", version = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.display()\n",
    "for i in range(len(states)):\n",
    "    plt.matshow( np.reshape(states[i], (50,50)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c7f822a9fda7ffd10530ef71b8007e75e5e59461c46d04a19e3026085bccd1b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
